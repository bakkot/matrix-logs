[
{"content":{"body":"ljharb: ping on https://github.com/tc39/ecma262/pull/1519","msgtype":"m.text"},"ts":1590716767000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"i was kind of waiting for shu on that one","msgtype":"m.text"},"ts":1590726637000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"that's grammar-ish","msgtype":"m.text"},"ts":1590726641000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"k, 2020 candidate is updated, both in \"releases\" and the reflector, with a pdf","msgtype":"m.text"},"ts":1590734703000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"iâ€™ll take a look today","msgtype":"m.text"},"ts":1590763901000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"Bakkot: let me check my understanding of 1519","msgtype":"m.text"},"ts":1590768134000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"1) it is currently dead code","msgtype":"m.text"},"ts":1590768137000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"2) i kinda like waldemar's suggestions. do you think they're needed?","msgtype":"m.text"},"ts":1590768283000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"3) i don't quite grok the concern about the lexical-syntactic grammar boundary","msgtype":"m.text"},"ts":1590768720000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"yeah, it's dead (in the sense of, the \"true\" cases of those branches are never taken","msgtype":"m.text"},"ts":1590768801000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"the concern about the lexical-syntactic boundary is, for e.g. `LiteralPropertyName : IdentifierName` that's a _syntactic_ production, as evidenced by the single `:`","msgtype":"m.text"},"ts":1590768829000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"but if you took Waldear's suggestion, we would be defining Contains for `IdentifierName :: IdentifierStart` and `IdentifierName :: IdentifierName IdentifierPart`, which are _lexical_ productions","msgtype":"m.text"},"ts":1590768888000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"currently I don't think any of the SDOs descend into lexical productions, though I could be wrong","msgtype":"m.text"},"ts":1590768966000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"and, yeah, that would require rewording some stuff","msgtype":"m.text"},"ts":1590769035000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"I think","msgtype":"m.text"},"ts":1590769039000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"because \"The syntactic grammar for ECMAScript is given in clauses 11, 12, 13, 14, and 15. This grammar has ECMAScript tokens defined by the lexical grammar as its terminal symbols\"","msgtype":"m.text"},"ts":1590769046000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"that is, per this definition, IdentiferName is a _terminal_ symbol of the syntactic grammar","msgtype":"m.text"},"ts":1590769087000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"and Contains is defined to only recurse into _nonterminals_","msgtype":"m.text"},"ts":1590769115000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"okay","msgtype":"m.text"},"ts":1590769293000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"them simple removal lgtm","msgtype":"m.text"},"ts":1590769296000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"as for #2019","msgtype":"m.text"},"ts":1590769302000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"yikes","msgtype":"m.text"},"ts":1590769303000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"commented the above on #1519","msgtype":"m.text"},"ts":1590769634000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"and yeah #2019 is :(","msgtype":"m.text"},"ts":1590769638000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"I've actually encountered that before","msgtype":"m.text"},"ts":1590769645000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"didn't bring it up because I didn't want to think about it","msgtype":"m.text"},"ts":1590769653000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"i'm trying to understand why we've all implemented this wrong","msgtype":"m.text"},"ts":1590769814000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"arai _does_ seem correct","msgtype":"m.text"},"ts":1590769822000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"okay, i see...","msgtype":"m.text"},"ts":1590770284000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"Bakkot: i commented in #2019","msgtype":"m.text"},"ts":1590771256000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"do you think this is worth fixing?","msgtype":"m.text"},"ts":1590771260000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"define \"fixing\"","msgtype":"m.text"},"ts":1590771293000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"changing the spec, or changing implementations?","msgtype":"m.text"},"ts":1590771305000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"changing implementations","msgtype":"m.text"},"ts":1590771309000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"as long as I'm allocating other people's time, sure :P","msgtype":"m.text"},"ts":1590771319000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"realistically, not really","msgtype":"m.text"},"ts":1590771325000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"that is, I don't see this being the highest-priority thing to work on for the foreseeable future","msgtype":"m.text"},"ts":1590771341000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"could get an intern to do it I guess","msgtype":"m.text"},"ts":1590771349000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"(the joke is, I spent much of my internship at google fixing B.3.3 bugs)","msgtype":"m.text"},"ts":1590771357000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"indeed","msgtype":"m.text"},"ts":1590771372000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"cue vesti la giubba","msgtype":"m.text"},"ts":1590771410000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"okay i think this is actually *hard* to fix in implementations","msgtype":"m.text"},"ts":1590771775000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"async and defer scripts means parallel parser threads that need to reconcile their top-level binding tables","msgtype":"m.text"},"ts":1590771813000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"so at parse time, you can't actually make the correct annex b.3.3 applicability decision","msgtype":"m.text"},"ts":1590771835000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"oof","msgtype":"m.text"},"ts":1590771997000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"but you want to resolve the bindings at parse time","msgtype":"m.text"},"ts":1590772002000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"I wish we had not made the top-level lexical contour shared across scripts","msgtype":"m.text"},"ts":1590772037000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"it is a weird decision","msgtype":"m.text"},"ts":1590772041000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"+1","msgtype":"m.text"},"ts":1590773384000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"right, you *want* to resolve it at parse time so you can emit the assignment to the synthetic var if needed","msgtype":"m.text"},"ts":1590773587000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"and... to also declare the synthetic var so it has effect on future \"if replacing this function with a var statement would not result in an early error\" clauses","msgtype":"m.text"},"ts":1590773642000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"but if you _can't_... i don't really know how to think about this so far","msgtype":"m.text"},"ts":1590773652000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"i still have no idea why this is a hard thing to fix, but you don't have to explain it to me :-p","msgtype":"m.text"},"ts":1590775360000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"ljharb: it's basically like, when the parser sees `{ function f() {} }`, it wants to know, at that point, if we need to do the wacky annex b semantics","msgtype":"m.text"},"ts":1590775676000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"ljharb: but! on the web there may be multiple parses in parallel because of async scripts, so when parser thread A seems `{ function f() {} }`, it doesn't actually know if annex b semantics applies","msgtype":"m.text"},"ts":1590775720000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"hm","msgtype":"m.text"},"ts":1590775734000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"why doesn't it know that?","msgtype":"m.text"},"ts":1590775737000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"ljharb: maybe parser thread B has a top-level `let f`, but it hasn't finished parsing and \"merging\" back into the main thread state yet","msgtype":"m.text"},"ts":1590775742000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"ahhh ok","msgtype":"m.text"},"ts":1590775754000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"so it always technically applies but doesn't really do anything unless there's an overlap","msgtype":"m.text"},"ts":1590775769000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"but because the parsing is parallelized, you can't know there's an overlap til the join?","msgtype":"m.text"},"ts":1590775778000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"no, it doesn't always apply","msgtype":"m.text"},"ts":1590775782000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"it only applies if \"it wouldn't have caused an early error\"","msgtype":"m.text"},"ts":1590775794000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"but you don't even know if it would cause an early error until threads join, yep","msgtype":"m.text"},"ts":1590775801000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"(i'm sure i don't grok the wacky annex b semantics either, fwiw)","msgtype":"m.text"},"ts":1590775802000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"gotcha","msgtype":"m.text"},"ts":1590775804000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"whatever the criteria is, i get the race condition","msgtype":"m.text"},"ts":1590775809000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"is there a possible spec improvement that would obviate the need for implementations to fix anything?","msgtype":"m.text"},"ts":1590775854000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"like Bakkot said, this is all because we decided the global lexical scope is shared among all scripts","msgtype":"m.text"},"ts":1590775871000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"there is but that's also pretty gnarly for the spec","msgtype":"m.text"},"ts":1590775882000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"and presumably we couldn't undecide that?","msgtype":"m.text"},"ts":1590775893000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"i don't know how we should proceed yet","msgtype":"m.text"},"ts":1590775897000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"undecide a possible spec fix?","msgtype":"m.text"},"ts":1590775901000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"sorry i meant \"the global lexical scope is shared among all scripts\"","msgtype":"m.text"},"ts":1590775917000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"it would almost certainly not be web compat to change that, unfortunately","msgtype":"m.text"},"ts":1590775927000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"i'm assuming that not sharing it would break other things","msgtype":"m.text"},"ts":1590775928000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"right","msgtype":"m.text"},"ts":1590775930000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"yeah","msgtype":"m.text"},"ts":1590775996000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"it's certainly a funny definition of \"lexical\" that's for sure","msgtype":"m.text"},"ts":1590776028000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"if that's lexical then we're all in the same room right now","msgtype":"m.text"},"ts":1590776123000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"maybe it was done out of fear of the SM legacy let/const semantics, where they were actually vars?","msgtype":"m.text"},"ts":1590776165000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"i don't have the history here","msgtype":"m.text"},"ts":1590776171000,"senderName":"shu","senderId":"shu@irc"},
{"content":{"body":"re https://github.com/tc39/ecma262/pull/2007#issuecomment-634985074: should we maybe prefer writing bigints as *0n*, rather than *0*<sub>Z</sub>?","msgtype":"m.text"},"ts":1590793031000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"i am super on board with that. but, doesn't that then suggest that Numbers should be written as digits, forcing math values to have a marker?","msgtype":"m.text"},"ts":1590793119000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"I don't think it suggests numbers should be written as digits","msgtype":"m.text"},"ts":1590793156000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"*Numbers","msgtype":"m.text"},"ts":1590793160000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"`0n` says to me \"it's written like you'd write it in JS\"","msgtype":"m.text"},"ts":1590793173000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"yeah, I mean, strings are too","msgtype":"m.text"},"ts":1590793194000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"but for Numbers that would be ambiguous, so we can't do it there","msgtype":"m.text"},"ts":1590793204000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"right - ambiguous unless math values weren't used as digits","msgtype":"m.text"},"ts":1590793233000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"No, ambiguous anyway","msgtype":"m.text"},"ts":1590793242000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"Just because we can give something a definition doesn't mean all readers will have that definition in mind at all times","msgtype":"m.text"},"ts":1590793259000,"senderName":"Bakkot","senderId":"Bakkot@irc"},
{"content":{"body":"hm","msgtype":"m.text"},"ts":1590793317000,"senderName":"ljharb","senderId":"ljharb@irc"},
{"content":{"body":"i guess it'd confuse me if i saw multiple things in the spec written like it was in JS, but then found numbers weren't","msgtype":"m.text"},"ts":1590793331000,"senderName":"ljharb","senderId":"ljharb@irc"}
]