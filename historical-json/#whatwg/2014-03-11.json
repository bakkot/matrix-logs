[
{"content":{"body":"zewt: fwiw, about the problem you mentioned the other day about the validator reporting errors about URLs with non-default ports -- the underlying problem will be going away soon, because I'm switching the URL checker in the validator away from the old Jena IRI checker we were usin","msgtype":"m.text"},"ts":1394504142000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"switching to using smola_'s Galimatias instead https://github.com/smola/galimatias","msgtype":"m.text"},"ts":1394504194000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"which implementes the whatwg URL spec","msgtype":"m.text"},"ts":1394504205000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"so if you have objections to any of the error messages after that, you can blame either smola_ for his code or AnneVK for his spec :-)","msgtype":"m.text"},"ts":1394504273000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"is anybody other than anne familiar with https://raw.github.com/w3c/web-platform-tests/master/url/urltestdata.txt?","msgtype":"m.text"},"ts":1394522403000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"oh that came from webkit","msgtype":"m.text"},"ts":1394522431000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"hmm is the fragment part of a URL allowed to contain spaces?","msgtype":"m.text"},"ts":1394526238000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"not allowed but it appears that the parsing algorithm results in the fragment of the parsed URL retain ingthe space as-is","msgtype":"m.text"},"ts":1394526427000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"or maybe not, and smola_ parse has a bug[D[D[D[D[D[D[D[D[D[Dr","msgtype":"m.text"},"ts":1394526510000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"ok, http://url.spec.whatwg.org/#fragment-state : \"3. utf-8 percent encode c using the simple encode set, and append the result to url's fragment.\", where \"The simple encode set are all code points less than U+0020 (i.e. excluding U+0020) and all code points greater than U+007E.\", which doesn't include U+0032 SPACE so that behavior is expected","msgtype":"m.text"},"ts":1394527511000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"Nono","msgtype":"m.text"},"ts":1394527713000,"senderName":"Ms2ger","senderId":"Ms2ger@irc"},
{"content":{"body":"Space is 32 decimal, so U+0020","msgtype":"m.text"},"ts":1394527725000,"senderName":"Ms2ger","senderId":"Ms2ger@irc"},
{"content":{"body":"poofs","msgtype":"m.emote"},"ts":1394527742000,"senderName":"Ms2ger","senderId":"Ms2ger@irc"},
{"content":{"body":"oh","msgtype":"m.text"},"ts":1394527747000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"weird then","msgtype":"m.text"},"ts":1394527775000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"looks back at smola_ code","msgtype":"m.emote"},"ts":1394527783000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"nm","msgtype":"m.text"},"ts":1394529612000,"senderName":"MikeSmith","senderId":"MikeSmith@irc"},
{"content":{"body":"MikeSmith: I think anne subsumed urltestdata.txt into his tests","msgtype":"m.text"},"ts":1394532976000,"senderName":"jgraham","senderId":"jgraham@irc"},
{"content":{"body":"abarth: ping","msgtype":"m.text"},"ts":1394556884000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"hi","msgtype":"m.text"},"ts":1394556892000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"abarth: saw your comment about deprecating \"bigger\" features in the showModalDialog thread","msgtype":"m.text"},"ts":1394556917000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: something we're unsurprisingly interested in too :)","msgtype":"m.text"},"ts":1394556927000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"that's mostly a reference to XSLT","msgtype":"m.text"},"ts":1394556936000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"abarth: by \"bigger\", do you mean \"used more often\"?","msgtype":"m.text"},"ts":1394556939000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: hah","msgtype":"m.text"},"ts":1394556947000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"the current approach we're pursuing for XSLT is to make a JS polyfill using asm.js","msgtype":"m.text"},"ts":1394556953000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"XSLT was my baby","msgtype":"m.text"},"ts":1394556955000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"oh, sorry :(","msgtype":"m.text"},"ts":1394556962000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"it's ok, she had a good run","msgtype":"m.text"},"ts":1394556971000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"in principle, the polyfill should work in Firefox too","msgtype":"m.text"},"ts":1394556995000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"\"it seemed like a good idea at the time\"","msgtype":"m.text"},"ts":1394556997000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yeah, it made sense in the past when JavaScript was slow","msgtype":"m.text"},"ts":1394557006000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"yeah","msgtype":"m.text"},"ts":1394557031000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"why polyfill with asm.js? Would you compile all of libxml?","msgtype":"m.text"},"ts":1394557058000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"are there specific things you're interested in deprecating?  these sorts of thing are more likely to stick if we coordinate","msgtype":"m.text"},"ts":1394557061000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"yes","msgtype":"m.text"},"ts":1394557065000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"libxml + libxslt","msgtype":"m.text"},"ts":1394557070000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"wow!","msgtype":"m.text"},"ts":1394557073000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"then an extension to expose the API to web pages","msgtype":"m.text"},"ts":1394557080000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"why not just use the DOM?","msgtype":"m.text"},"ts":1394557083000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"and do a DOM->DOM transformation","msgtype":"m.text"},"ts":1394557100000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"I don't want to re-implement XSLT in JavaScript","msgtype":"m.text"},"ts":1394557100000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"ok","msgtype":"m.text"},"ts":1394557107000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"there are several people who've tried that","msgtype":"m.text"},"ts":1394557109000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"and their things sort of, kind of work","msgtype":"m.text"},"ts":1394557116000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"I also tried a Java one","msgtype":"m.text"},"ts":1394557128000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"compiled it to JS using GWT","msgtype":"m.text"},"ts":1394557133000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"disable-output-escaping is the big thing you'd lose","msgtype":"m.text"},"ts":1394557135000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"and that worked for about half the sites","msgtype":"m.text"},"ts":1394557141000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"but it had some bugs","msgtype":"m.text"},"ts":1394557152000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"i fixed some of the bugs, but there were more bugs","msgtype":"m.text"},"ts":1394557161000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"so I got sad and decided we needed to use the libxslt implementation","msgtype":"m.text"},"ts":1394557170000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"heh","msgtype":"m.text"},"ts":1394557176000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"makes sense","msgtype":"m.text"},"ts":1394557180000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: showModalDialog is definitely the big one that would be exiting to get rid of. XSLT is an interesting one too, though if we polyfill it's not really \"getting rid of\"","msgtype":"m.text"},"ts":1394557219000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"the idea is that we would put the polyfill in the extension gallery","msgtype":"m.text"},"ts":1394557240000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"and not ship it with the browser","msgtype":"m.text"},"ts":1394557246000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"(also, my heart does cry a little getting rid of XSLT)","msgtype":"m.text"},"ts":1394557252000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"if people wanted to use it, they could install the extension","msgtype":"m.text"},"ts":1394557260000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"also, people who were passionate about XSLT could fork our version and improve it","msgtype":"m.text"},"ts":1394557272000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"Hmm","msgtype":"m.text"},"ts":1394557277000,"senderName":"jgraham","senderId":"jgraham@irc"},
{"content":{"body":"i see","msgtype":"m.text"},"ts":1394557282000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"interesting","msgtype":"m.text"},"ts":1394557286000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"I thought there was enough of the public internet using XSLT that wasn't viable","msgtype":"m.text"},"ts":1394557298000,"senderName":"jgraham","senderId":"jgraham@irc"},
{"content":{"body":"i'm hopeful we can solve that problem by making the extension discoverable","msgtype":"m.text"},"ts":1394557327000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"jgraham: the numbers that chrome is collecting looks really low","msgtype":"m.text"},"ts":1394557329000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"jgraham: much lower than showmodaldialog","msgtype":"m.text"},"ts":1394557340000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"A few years ago it was enough that Opera felt the need to implement it at least","msgtype":"m.text"},"ts":1394557352000,"senderName":"jgraham","senderId":"jgraham@irc"},
{"content":{"body":"e.g., an infobar that says \"this page is using an old API, click here to install a compatibility shim\"","msgtype":"m.text"},"ts":1394557360000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"Maybe usage has declined","msgtype":"m.text"},"ts":1394557361000,"senderName":"jgraham","senderId":"jgraham@irc"},
{"content":{"body":"don't know","msgtype":"m.text"},"ts":1394557368000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i'd definitely want to get Gecko specific stats","msgtype":"m.text"},"ts":1394557379000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"anyhow","msgtype":"m.text"},"ts":1394557381000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: there's a lot of interesting APIs on the Chrome usage stats page","msgtype":"m.text"},"ts":1394557399000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"http://www.chromestatus.com/metrics/feature/timeline/popularity/79","msgtype":"m.text"},"ts":1394557400000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"http://www.chromestatus.com/metrics/feature/timeline/popularity/78","msgtype":"m.text"},"ts":1394557405000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"the XSLT thing is a bit of a dream still.  we're still working on the technical part","msgtype":"m.text"},"ts":1394557423000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"sicking: those are just whatever people happened to add metrics for","msgtype":"m.text"},"ts":1394557438000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"sicking: I wouldn't read into it too much","msgtype":"m.text"},"ts":1394557444000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"abarth: <isindex> for example. And document.all()","msgtype":"m.text"},"ts":1394557445000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"we've removed <isindex>","msgtype":"m.text"},"ts":1394557452000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"abarth: oh? Also <input name=isindex>?","msgtype":"m.text"},"ts":1394557477000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"data:text/html,<input name=isindex>","msgtype":"m.text"},"ts":1394557502000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"yep","msgtype":"m.text"},"ts":1394557503000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"abarth: neat","msgtype":"m.text"},"ts":1394557577000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: when you say \"don't read too much into it\", does that mean you don't think the numbers are accurate?","msgtype":"m.text"},"ts":1394557616000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: or does it mean that there's many more things that might have low usage but you don't gather stats on it","msgtype":"m.text"},"ts":1394557636000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"I expected the latter, not the former","msgtype":"m.text"},"ts":1394557652000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"the latter","msgtype":"m.text"},"ts":1394557688000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"ok","msgtype":"m.text"},"ts":1394557692000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"cool","msgtype":"m.text"},"ts":1394557694000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: other things that I'd love to see stats on (we're building the same thing for gecko, so i can get it myself soon) is document.domain-setter and namespaced attributes (modulo the SVG ones)","msgtype":"m.text"},"ts":1394557738000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yeah, those would be interesting","msgtype":"m.text"},"ts":1394557815000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"in part, getting rid of document.domain setting could allow a more narrow process infrastructure","msgtype":"m.text"},"ts":1394557894000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i.e. process-per-origin rather than process-per-eTLD+1","msgtype":"m.text"},"ts":1394557907000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"process separation in particular is something we have to figure out to make webapps happen I think","msgtype":"m.text"},"ts":1394557962000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Pretty sure that document.domain setting is used every-f—ing-where","msgtype":"m.text"},"ts":1394557968000,"senderName":"jgraham","senderId":"jgraham@irc"},
{"content":{"body":"jgraham: it used to be used by facebook.  not sure if they still use it","msgtype":"m.text"},"ts":1394558003000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"yeah","msgtype":"m.text"},"ts":1394558004000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Also Yahoo","msgtype":"m.text"},"ts":1394558010000,"senderName":"jgraham","senderId":"jgraham@irc"},
{"content":{"body":"if it's just a couple of sites that use it a lot, then that gives some hope of getting rid of it","msgtype":"m.text"},"ts":1394558255000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"by evangelizing said sites","msgtype":"m.text"},"ts":1394558269000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"That is a very optimistic view","msgtype":"m.text"},"ts":1394558282000,"senderName":"jgraham","senderId":"jgraham@irc"},
{"content":{"body":"or even by whitelisting them and removing it elsewhere, then evangelizing","msgtype":"m.text"},"ts":1394558283000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":":)","msgtype":"m.text"},"ts":1394558284000,"senderName":"jgraham","senderId":"jgraham@irc"},
{"content":{"body":"i try to be :)","msgtype":"m.text"},"ts":1394558296000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"wow, SVG is used on over 9 percent of the web","msgtype":"m.text"},"ts":1394558370000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"that's amazing","msgtype":"m.text"},"ts":1394558374000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"hmm.. though \"SVGSVGElementInDocument\" says only 0.1%. I'm not sure what that means","msgtype":"m.text"},"ts":1394558416000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Maybe inline vs <img>?","msgtype":"m.text"},"ts":1394558438000,"senderName":"Ms2ger","senderId":"Ms2ger@irc"},
{"content":{"body":"ooh","msgtype":"m.text"},"ts":1394558495000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"both inline and <img> counts as \"in document\". But Modernizr (presumably feature detection) doesn't","msgtype":"m.text"},"ts":1394558524000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: yes, we've tried a couple times to quantify SVG usage","msgtype":"m.text"},"ts":1394558543000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"i think modernizr was causing tricking us a few times","msgtype":"m.text"},"ts":1394558557000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"so i guess pages use libraries that check if svg is supported, but then never actually use svg in any form?","msgtype":"m.text"},"ts":1394558570000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yes","msgtype":"m.text"},"ts":1394558586000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"makes sense","msgtype":"m.text"},"ts":1394558591000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"we can check with pdr to be sure","msgtype":"m.text"},"ts":1394558601000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"we had the same trouble with webkitNotifications","msgtype":"m.text"},"ts":1394558617000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"where people would touch the property but not actually use it","msgtype":"m.text"},"ts":1394558630000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"abarth: i'm surprised that some of the properties see such big changes in use of such short period of time. Makes me worried about trusting the data","msgtype":"m.text"},"ts":1394558734000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"for example http://www.chromestatus.com/metrics/feature/timeline/popularity/211","msgtype":"m.text"},"ts":1394558749000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"which properties?","msgtype":"m.text"},"ts":1394558753000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"http://www.chromestatus.com/metrics/feature/timeline/popularity/211","msgtype":"m.text"},"ts":1394558765000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"that's probably the metric rolling out into the stable channel","msgtype":"m.text"},"ts":1394558772000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"aah","msgtype":"m.text"},"ts":1394558778000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"the graphics aren't well normalized","msgtype":"m.text"},"ts":1394558793000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"we have more detailed graphics internally that slice and dice by version and platform","msgtype":"m.text"},"ts":1394558819000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"if you have specific questions, I can dig into those for you","msgtype":"m.text"},"ts":1394558831000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"does those internal graphs allow you to get stats per website?","msgtype":"m.text"},"ts":1394558887000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i.e. could you see if document.domain is only used by facebook/yahoo for example?","msgtype":"m.text"},"ts":1394558899000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"(i'm not really hoping that we can get rid of document.domain anytime soon)","msgtype":"m.text"},"ts":1394558915000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"no, we don't have per-site data","msgtype":"m.text"},"ts":1394558957000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"its aggregated by page views","msgtype":"m.text"},"ts":1394558983000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"ok","msgtype":"m.text"},"ts":1394559005000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"another thing that would be lovely to get rid of is GlobalScopePolluter. But I think we'd only have a chance to do so on non-quirks pages. Or in ES6 strict mode or some such","msgtype":"m.text"},"ts":1394559060000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Remember how we only supported it in quirks and Chrome's demos pushed us to enable it everywhere?","msgtype":"m.text"},"ts":1394559175000,"senderName":"Ms2ger","senderId":"Ms2ger@irc"},
{"content":{"body":"that was IE's demos right?","msgtype":"m.text"},"ts":1394559301000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Ms2ger: Right, that was MS's demos. And it wasn't intentional I bet","msgtype":"m.text"},"ts":1394559321000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"it seemed intentional... trying to create something that failed in other browsers...","msgtype":"m.text"},"ts":1394559336000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: i don't think it was. They just didn't care about testing in other browsers","msgtype":"m.text"},"ts":1394559362000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"which arguably is equivalent to making it not work in other browsers","msgtype":"m.text"},"ts":1394559381000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"but I don't think they were intentional about breaking in other browsers","msgtype":"m.text"},"ts":1394559395000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"anyhow, that's just guessing","msgtype":"m.text"},"ts":1394559414000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"it was a sad time, i am still somewhat bitter","msgtype":"m.text"},"ts":1394559465000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Ms2ger: and just because we couldn't get consensus to do something good about GlobalScopePolluter back then, doesn't mean that we can't get it now","msgtype":"m.text"},"ts":1394559474000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Oh, sure","msgtype":"m.text"},"ts":1394559486000,"senderName":"Ms2ger","senderId":"Ms2ger@irc"},
{"content":{"body":"Domenic_: actually, since I have you here...","msgtype":"m.text"},"ts":1394559511000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: I had one more thought on binary Streams","msgtype":"m.text"},"ts":1394559522000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: yes?","msgtype":"m.text"},"ts":1394559578000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: have you thought about performance around Streams that shuffle lots of data? In particular about how many times an implementation will have to copy data between buffers?","msgtype":"m.text"},"ts":1394559579000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: that is our primary concern :P","msgtype":"m.text"},"ts":1394559589000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"there should be no copying in any in-process use cases","msgtype":"m.text"},"ts":1394559612000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: I don't think that is possible in the current API","msgtype":"m.text"},"ts":1394559635000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: it is possible, as shown by the implementation that does so","msgtype":"m.text"},"ts":1394559651000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"hmm...","msgtype":"m.text"},"ts":1394559651000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"the buffers can be implemented as queues (i.e. with pointers)","msgtype":"m.text"},"ts":1394559717000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"so the location of the data chunks (e.g. ArrayBuffer backing stores) can stay the same all the time","msgtype":"m.text"},"ts":1394559745000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: So say that I have a Stream representing reading from a file","msgtype":"m.text"},"ts":1394559748000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: well.. if you just keep pointers to ArrayBuffers, then that means that you'll end up with an array of ArrayBuffers when the data is asked for. Not a single ArrayBuffer","msgtype":"m.text"},"ts":1394559810000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yes","msgtype":"m.text"},"ts":1394559837000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"you ask for one chunk at a time","msgtype":"m.text"},"ts":1394559840000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"read() returns a single chunk, in whatever format---object, arraybuffer, string, etc.","msgtype":"m.text"},"ts":1394559855000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"(whatever the stream wants to give you)","msgtype":"m.text"},"ts":1394559869000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"if you want to concatenate them for some reason (you should never need to do this really...) then you'd do so yourself, and pay the cost.","msgtype":"m.text"},"ts":1394559900000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: So read() doesn't return all data read so far? It just returns the first buffer of all data read so far (API-wise that's the same, but implementation and performance-wise they are different)","msgtype":"m.text"},"ts":1394559921000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"while the stream is readable, read() returns the oldest unread chunk","msgtype":"m.text"},"ts":1394559939000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"you call read() repeatedly until the stream is no longer readable","msgtype":"m.text"},"ts":1394559950000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: so that's a \"yes\"?","msgtype":"m.text"},"ts":1394559976000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: I don't know what \"first buffer\" means, but \"probably\"?","msgtype":"m.text"},"ts":1394559995000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"sicking: https://github.com/whatwg/streams/blob/master/Examples.md#usage","msgtype":"m.text"},"ts":1394560035000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: well.. if I have a Stream that represents reading from a file. The way I'd probably implement that is by having some background thread allocate buffers, then issue a read() call into that buffer and then send the buffer to the JS thread. And then do that in a loop until I've read the whole file.","msgtype":"m.text"},"ts":1394560091000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: how fast I'd be sending buffers is a function of the OS IO performance at the time","msgtype":"m.text"},"ts":1394560109000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: i.e. i might be creating buffers faster than JS is consuming them","msgtype":"m.text"},"ts":1394560129000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: ok, by buffers here you mean \"ArrayBuffers\" (or their C++ backing stores), not \"stream buffers\". I guess that's confusing.","msgtype":"m.text"},"ts":1394560131000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: I mean their C++ backing stores","msgtype":"m.text"},"ts":1394560150000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: which is essentially the same as an ArrayBuffer yes","msgtype":"m.text"},"ts":1394560163000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"streams each have a single buffer containing the chunks available for reading, so that's the confusion","msgtype":"m.text"},"ts":1394560165000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"but ok makes sense","msgtype":"m.text"},"ts":1394560175000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: so when the call comes to read(), I might be sitting on a long list of ArrayBuffers","msgtype":"m.text"},"ts":1394560206000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"you shouldn't be, if you are respecting the backpressure","msgtype":"m.text"},"ts":1394560221000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"the stream asks the underlying source (i.e. your C++) for a certain number of bytes","msgtype":"m.text"},"ts":1394560262000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"up to a high water mark","msgtype":"m.text"},"ts":1394560266000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"e.g. 16 KB","msgtype":"m.text"},"ts":1394560270000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"so that is supposed to be the maximum stored in memory at any given time","msgtype":"m.text"},"ts":1394560288000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: We want to enable paralell IO and processing, no?","msgtype":"m.text"},"ts":1394560305000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"then it waits for the consumer to start draining that before asking you to fill back up to the HWM","msgtype":"m.text"},"ts":1394560306000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"sure, but the point of streams is to limit the memory used","msgtype":"m.text"},"ts":1394560320000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"so say 16 KB at a time","msgtype":"m.text"},"ts":1394560330000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: sure, I'm not saying that we'd consume unlimited amounts of space.","msgtype":"m.text"},"ts":1394560338000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"ok","msgtype":"m.text"},"ts":1394560342000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"abarth: didn't realise you'd gotten rid of name=isindex, on the thread it was only the parser thing that people were talking about","msgtype":"m.text"},"ts":1394560360000,"senderName":"Hixie","senderId":"Hixie@irc"},
{"content":{"body":"Domenic_: but reading 16KB into a single buffer, and then stop IO until that buffer has been requested by the page doesn't seem good performance-wise","msgtype":"m.text"},"ts":1394560369000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Hixie: maybe I don't understand what name=isindex does","msgtype":"m.text"},"ts":1394560381000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"Hixie: i think we only changed the parser","msgtype":"m.text"},"ts":1394560388000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"sicking: i was told the most natural (backing-)buffer size for most OSes was 1KB","msgtype":"m.text"},"ts":1394560389000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"abarth: no, looks like you got rod of more than the parser","msgtype":"m.text"},"ts":1394560403000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: does look like name=isindex is gone too","msgtype":"m.text"},"ts":1394560404000,"senderName":"Hixie","senderId":"Hixie@irc"},
{"content":{"body":"ok, i didn't review the actual code change","msgtype":"m.text"},"ts":1394560422000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"sicking: well, what if you are uploading that to a server over a slow connection?","msgtype":"m.text"},"ts":1394560431000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: that might be true","msgtype":"m.text"},"ts":1394560434000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: maybe in browsers a higher default HWM makes sense. In node by default each stream should take only 16 KB max of memory","msgtype":"m.text"},"ts":1394560452000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"sicking: but maybe in browsers we anticipate fewer streams open at a given time so it should be higher","msgtype":"m.text"},"ts":1394560469000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: i agree that backpressure is an important topic. But it also seems important to support reading from a file at maximum speed, no?","msgtype":"m.text"},"ts":1394560475000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: you should read from the file exactly as fast as the consumer is able to process data","msgtype":"m.text"},"ts":1394560492000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: that's impossible","msgtype":"m.text"},"ts":1394560505000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: if the consumer processes data synchronously, then there will be no difference between a HWM of 16KB and a HWM of 0 KB","msgtype":"m.text"},"ts":1394560508000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"because in both cases the data never accumulates","msgtype":"m.text"},"ts":1394560517000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"so the limit is never hit","msgtype":"m.text"},"ts":1394560526000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"abarth: hey while you're here, quick TLS question unrelated to HTML. If I have two servers who talk to each other over TLS, can the \"client\" authenticate with a server certificate to prove its host name to the \"server\"?","msgtype":"m.text"},"ts":1394560535000,"senderName":"Hixie","senderId":"Hixie@irc"},
{"content":{"body":"Domenic_: i'm still not understanding how you envison an implementation should work","msgtype":"m.text"},"ts":1394560549000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: exactly like the one we already have does work :)","msgtype":"m.text"},"ts":1394560557000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Hixie: I think the client and server certs are different, but I'm not sure","msgtype":"m.text"},"ts":1394560572000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"Domenic_: then I don't understand how the one you already has does work","msgtype":"m.text"},"ts":1394560575000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: ah, bummer","msgtype":"m.text"},"ts":1394560591000,"senderName":"Hixie","senderId":"Hixie@irc"},
{"content":{"body":"sicking: OK, I will find the source code for you","msgtype":"m.text"},"ts":1394560595000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Hixie: you should check with someone who is sure though","msgtype":"m.text"},"ts":1394560611000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"abarth: who would know better than you?","msgtype":"m.text"},"ts":1394560623000,"senderName":"Hixie","senderId":"Hixie@irc"},
{"content":{"body":"I'd ask agl","msgtype":"m.text"},"ts":1394560627000,"senderName":"abarth","senderId":"abarth@irc"},
{"content":{"body":"Domenic_: do you know how it works?","msgtype":"m.text"},"ts":1394560630000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"abarth: k, thanks","msgtype":"m.text"},"ts":1394560634000,"senderName":"Hixie","senderId":"Hixie@irc"},
{"content":{"body":"sicking: yes, but it's easier to point to code","msgtype":"m.text"},"ts":1394560640000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"sicking: https://github.com/joyent/node/blob/master/lib/fs.js#L1518","msgtype":"m.text"},"ts":1394560652000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"when the consumer asks for data, you read it and give it back to them","msgtype":"m.text"},"ts":1394560663000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"_read is called by the stream implementation when the stream's buffer is below the HWM.","msgtype":"m.text"},"ts":1394560736000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: so you don't issue a filesystem read until someone calls read()?","msgtype":"m.text"},"ts":1394560747000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"so this ensures the stream's buffer is always full up to the HWM","msgtype":"m.text"},"ts":1394560749000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"sicking: you preemtively fill the buffer up to the HWM, but once the HWM is reached you stop filling until they call read() to make space in the buffer.","msgtype":"m.text"},"ts":1394560774000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: so when you issue a filesystem read, you issue it for the full HWM size?","msgtype":"m.text"},"ts":1394560805000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: you should issue it for the amount of space in the buffer. Initially that will be full HWM size; after a single read() it will be [full HWM size - size of returned chunk]","msgtype":"m.text"},"ts":1394560871000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"after five reads it will be [full HWM size - 5 * size of returned chunk]","msgtype":"m.text"},"ts":1394560890000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: why wouldn't you return the full chunk?","msgtype":"m.text"},"ts":1394560905000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: wait","msgtype":"m.text"},"ts":1394560922000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"let's say the buffer has room for 16 chunks before hitting HWM","msgtype":"m.text"},"ts":1394560933000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: before we go further, lets be more explicit about what buffers we are talking about","msgtype":"m.text"},"ts":1394560936000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yes, i am talking about the stream's buffer","msgtype":"m.text"},"ts":1394560944000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"which has room for e.g. 16 KB of data","msgtype":"m.text"},"ts":1394560953000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"is a \"buffer\" a continuous piece of memory?","msgtype":"m.text"},"ts":1394560955000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i use \"chunk\" for a 1 KB chunk of data from the file","msgtype":"m.text"},"ts":1394560967000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"is a \"chunk\" a continuous piece of memory?","msgtype":"m.text"},"ts":1394560989000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yes","msgtype":"m.text"},"ts":1394560992000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"so chunk is continous but buffer is not?","msgtype":"m.text"},"ts":1394561004000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"the stream's buffer is just a queue","msgtype":"m.text"},"ts":1394561020000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"a buffer is an array of up to 16 chunks?","msgtype":"m.text"},"ts":1394561020000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yeah","msgtype":"m.text"},"ts":1394561024000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"conceptually","msgtype":"m.text"},"ts":1394561026000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"ok, cool","msgtype":"m.text"},"ts":1394561029000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"in node it looks like they use a contiguous chunk as a \"pool\" for the stream's buffer","msgtype":"m.text"},"ts":1394561043000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"ok, so the first thing you do is that you issue a 1KB read to the OS to read into the first chunk","msgtype":"m.text"},"ts":1394561097000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"and then you do that in a loop until you have 16 chunks","msgtype":"m.text"},"ts":1394561107000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"if i am understanding my sources correctly, yes :)","msgtype":"m.text"},"ts":1394561113000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"these sources who tell me reading 1 KB at a time is best","msgtype":"m.text"},"ts":1394561120000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"meanwhile, if read() is called, you return the first chunk and the first chunk only","msgtype":"m.text"},"ts":1394561126000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yup","msgtype":"m.text"},"ts":1394561164000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"?","msgtype":"m.text"},"ts":1394561165000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"ok, so that's what I was asking for earlier. No matter how many chunks (sorry, i used \"buffer\" earlier) has been read, you just return the first one","msgtype":"m.text"},"ts":1394561208000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"ok, heh, sorry it took us so long to get there","msgtype":"m.text"},"ts":1394561227000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"yeah the buffer thing is confusing...","msgtype":"m.text"},"ts":1394561233000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"it's about \"buffering\" data, so i'm hesitant to rename it to \"queue,\" but that might be less confusing...","msgtype":"m.text"},"ts":1394561248000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"often times \"memory buffer\" is used to describe a continuous block of memory that has been allocated","msgtype":"m.text"},"ts":1394561289000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"which is what got me confused","msgtype":"m.text"},"ts":1394561296000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"obviously there are many other types of buffers though","msgtype":"m.text"},"ts":1394561303000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i will open an issue, if other people agree that it is confusing i am happy to rename","msgtype":"m.text"},"ts":1394561355000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"i don't really care, just explaining the terminology i'm used to","msgtype":"m.text"},"ts":1394561382000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"if these terms appear in the spec, then it'd be good to explain them","msgtype":"m.text"},"ts":1394561405000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"For sure","msgtype":"m.text"},"ts":1394561460000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"ok, i'll have to chat up some other people that know IO performance better than me to know if this is a good strategy","msgtype":"m.text"},"ts":1394561469000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sounds good! feel free to put them in touch or open issues or whatnot.","msgtype":"m.text"},"ts":1394561513000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"one thing that is not possible in the current API, but that I think might be too non-JSy to worry about, is being able to reuse ArrayBuffer objects","msgtype":"m.text"},"ts":1394561555000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"so you end up with a bunch of churn","msgtype":"m.text"},"ts":1394561564000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"allocator churn","msgtype":"m.text"},"ts":1394561573000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"but i suspect that's fine","msgtype":"m.text"},"ts":1394561578000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"s/ArrayBuffer objects/Arraybuffer backing store objects/","msgtype":"m.text"},"ts":1394561613000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"hmm yeah i had requests for that from a node person actually","msgtype":"m.text"},"ts":1394561619000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":".readInto(ab)","msgtype":"m.text"},"ts":1394561625000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"the tricky part is that you don't want to allow the page to have a reference to an ArrayBuffer that you are writing into on a background thread","msgtype":"m.text"},"ts":1394561678000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"so you have to mess around with transferring ArrayBuffers back and forth","msgtype":"m.text"},"ts":1394561697000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"which is messy","msgtype":"m.text"},"ts":1394561703000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"ah yeah makes sense","msgtype":"m.text"},"ts":1394561734000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"cf. web audio api?","msgtype":"m.text"},"ts":1394561740000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"But the API might be as simple as Stream.releaseBuffer(ab) after you're done with it","msgtype":"m.text"},"ts":1394561748000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i haven't looked at webaudio","msgtype":"m.text"},"ts":1394561781000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"not sure what they do","msgtype":"m.text"},"ts":1394561788000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"well there was a whole issue with data races","msgtype":"m.text"},"ts":1394561823000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"which iirc was exactly that \"writing into it on a background thread\" thing","msgtype":"m.text"},"ts":1394561836000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"ah, right","msgtype":"m.text"},"ts":1394561853000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"ok, gotta head into office","msgtype":"m.text"},"ts":1394561881000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i'll try to get some perf guys to look at this. Not sure if i'll be able to, but i'll try","msgtype":"m.text"},"ts":1394561906000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"awesome, thank you","msgtype":"m.text"},"ts":1394561959000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: oooh, now i see what I was looking for. Is it expected that readBytes() will cause memory copying?","msgtype":"m.text"},"ts":1394561996000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"if so, that makes sense","msgtype":"m.text"},"ts":1394562009000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: er, i think you are looking at the wrong spec?","msgtype":"m.text"},"ts":1394562148000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"sicking: https://github.com/whatwg/streams","msgtype":"m.text"},"ts":1394562164000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: oooh! This looks so much better!","msgtype":"m.text"},"ts":1394563390000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: ahaha yay! :D","msgtype":"m.text"},"ts":1394563404000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: does read() return a promise?","msgtype":"m.text"},"ts":1394563443000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: nope, it's synchronous","msgtype":"m.text"},"ts":1394563452000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: how do you know if you can read from it?","msgtype":"m.text"},"ts":1394563478000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":".state?","msgtype":"m.text"},"ts":1394563489000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yeah exactly, state === \"readable\"","msgtype":"m.text"},"ts":1394563496000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"do you got a callback when state changes?","msgtype":"m.text"},"ts":1394563511000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"oh, wait()?","msgtype":"m.text"},"ts":1394563518000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yeah, exactly","msgtype":"m.text"},"ts":1394563520000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"so you do while(state === readable) process(read()) ?","msgtype":"m.text"},"ts":1394563549000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i bet with this in hand the examples at https://github.com/whatwg/streams/blob/master/Examples.md#readable-streams make more sense","msgtype":"m.text"},"ts":1394563553000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"man, i'm so happy all the encoding stuff is dropped","msgtype":"m.text"},"ts":1394563585000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"hahaha me too man","msgtype":"m.text"},"ts":1394563591000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"i wasn't looking forward to having that argument :)","msgtype":"m.text"},"ts":1394563599000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: so it feels like you need a lot of boilerplate to implement streamToConsole. I.e. something that essentially pipes the stream into a process() function","msgtype":"m.text"},"ts":1394563923000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: somewhat agreed. the idea is it's a lower-level primitive and there will be lots of user-land stream-utils packages, or writable streams","msgtype":"m.text"},"ts":1394564078000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"interestingly in node it's not popular to simply stream something to a process function","msgtype":"m.text"},"ts":1394564095000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"normally it would be a writable or transform stream","msgtype":"m.text"},"ts":1394564103000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: interesting","msgtype":"m.text"},"ts":1394564127000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: a TransformStream which pipes all data through a mapping function might address the use cases","msgtype":"m.text"},"ts":1394564187000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yeah, I think it's part of the non-minimal subset to have easy ways of creating properly-behaved transform streams.","msgtype":"m.text"},"ts":1394564220000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: though honesly, the cases I've needed the most are simply piping the data to disk or to a network connection","msgtype":"m.text"},"ts":1394564259000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"so no processing needed","msgtype":"m.text"},"ts":1394564266000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"right, in that case, writable streams :)","msgtype":"m.text"},"ts":1394564267000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"right","msgtype":"m.text"},"ts":1394564273000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"or simply allowing XHR.send() to take a ReadableStream","msgtype":"m.text"},"ts":1394564302000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: any thoughts on putBack(ab)? It's something that we've somewhat needed internally in Gecko","msgtype":"m.text"},"ts":1394564426000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: I am almost sure it is needed actually.","msgtype":"m.text"},"ts":1394564437000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"i was trying to get away with not needing it but it seems likely.","msgtype":"m.text"},"ts":1394564454000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"https://github.com/whatwg/streams/issues/3 the minimalists are arguing \"do it yourself\" but I think giving you the ability to push onto the stream's buffer, instead of maintaining your own, is much better.","msgtype":"m.text"},"ts":1394564524000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"More unclear is https://github.com/whatwg/streams/issues/74","msgtype":"m.text"},"ts":1394564534000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"the case we had was wanting to peek at the beginning of a stream and decide what to do with it (display or save-to-disk). Once we had determined that we wanted to do either, it was really annoying to have to deal with sending a <data we've pulled out of stream to peek, remaining stream> tuple to the chosen consumer, rather than just a simple stream","msgtype":"m.text"},"ts":1394564539000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"(which is related)","msgtype":"m.text"},"ts":1394564540000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"yeah, \"do it yourself\" has performance implications","msgtype":"m.text"},"ts":1394564564000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i wonder about putBack vs. peek","msgtype":"m.text"},"ts":1394564575000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"that i don't know though","msgtype":"m.text"},"ts":1394564582000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"either might work","msgtype":"m.text"},"ts":1394564589000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"the tricky thing with peek is how to deal with a consumer that doesn't know how many bytes it needs to peek","msgtype":"m.text"},"ts":1394564620000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"you don't want it to have to do peek(10), then if that wasn't enough data peek(20) etc","msgtype":"m.text"},"ts":1394564644000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"but how do you create an API that allows you to \"peek a little more, on top of what i previously peeked\"","msgtype":"m.text"},"ts":1394564670000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"hmm yeah","msgtype":"m.text"},"ts":1394564677000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"potentially you could use a tee","msgtype":"m.text"},"ts":1394564680000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"is putBack better in that regard?","msgtype":"m.text"},"ts":1394564681000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"putback would let you do read() until you've got enough data, then do a putBack(array-of-all-data-I-read)","msgtype":"m.text"},"ts":1394564714000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"ah ok i see","msgtype":"m.text"},"ts":1394564731000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"that's a fairly solid argument","msgtype":"m.text"},"ts":1394564746000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"but potentially you could also do a tee, and then read from the tee","msgtype":"m.text"},"ts":1394564766000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"that leaves the original stream unchanged","msgtype":"m.text"},"ts":1394564773000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i.e. you'd implement peek by tee-ing the stream","msgtype":"m.text"},"ts":1394564782000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"a tee might have performance overhead though. Depending on how it handles chunks and buffers","msgtype":"m.text"},"ts":1394564816000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"arbuably, read-then-putback is also going to affect buffers to some extent","msgtype":"m.text"},"ts":1394564858000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i am tempted to avoid tees if possible; they seem annoying and complex","msgtype":"m.text"},"ts":1394564886000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"(but of course necessary in some cases)","msgtype":"m.text"},"ts":1394564897000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"yeah","msgtype":"m.text"},"ts":1394564918000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"btw, if you go the putBack route, then it'd be great if you could transfer buffers into the stream when putting them back. Otherwise the stream has to copy them","msgtype":"m.text"},"ts":1394564966000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"why would it have to copy them?","msgtype":"m.text"},"ts":1394564988000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"it wouldn't need to modify them after they're put back","msgtype":"m.text"},"ts":1394565006000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"it would just keep it around for the next read() call","msgtype":"m.text"},"ts":1394565013000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"since ArrayBuffers are mutable. And you don't want whoever putBack the data to be able to mutate the data once it's semantically \"in the stream\"","msgtype":"m.text"},"ts":1394565027000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"mmm :-/","msgtype":"m.text"},"ts":1394565038000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"well but streams are not just ArrayBuffers. This is a general issue with any mutable objects you put back in the stream","msgtype":"m.text"},"ts":1394565060000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"yup","msgtype":"m.text"},"ts":1394565073000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"this is also an issue for peek","msgtype":"m.text"},"ts":1394565078000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"you don't want to enable someone to peek the start of the stream and then mutate the contents of the un-read() data","msgtype":"m.text"},"ts":1394565107000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"it's arguably (though yehuda might not agree) somewhat different with ArrayBuffers","msgtype":"m.text"},"ts":1394565146000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"I don't think of a Stream as a objectstream of ArrayBuffer objects","msgtype":"m.text"},"ts":1394565160000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"I think of it as a stream of bytes","msgtype":"m.text"},"ts":1394565164000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"it seems surprising that you could mutate those bytes inside the stream","msgtype":"m.text"},"ts":1394565178000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"with a stream of objects you can't mutate which objects the stream if containing","msgtype":"m.text"},"ts":1394565194000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"but you can mutate the objects","msgtype":"m.text"},"ts":1394565202000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"it seems pretty awkward to think of it as a stream of bytes","msgtype":"m.text"},"ts":1394565204000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"really?","msgtype":"m.text"},"ts":1394565215000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"read() would then return a single byte","msgtype":"m.text"},"ts":1394565223000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"well, we do chunks for performance","msgtype":"m.text"},"ts":1394565234000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"but really what we're semantically representing is a stream of bytes","msgtype":"m.text"},"ts":1394565249000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"but that's not what the API is communicating :-S","msgtype":"m.text"},"ts":1394565262000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"besides, why bytes and not words or bits or disk sectors? :P","msgtype":"m.text"},"ts":1394565293000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"well.. there's the whole platform endianness debacle","msgtype":"m.text"},"ts":1394565371000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"but if we agree that it's unfortunate that ArrayBufferViews expose CPU endianness","msgtype":"m.text"},"ts":1394565392000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"then an ArrayBuffer contains bytes and not words","msgtype":"m.text"},"ts":1394565392000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"but yes, you can think of it as a stream of bits too","msgtype":"m.text"},"ts":1394565409000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"a stream of bits and a stream of bytes seem equivalent","msgtype":"m.text"},"ts":1394565415000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i guess i am more concerned about how consumers interact with the API than what is semantically being represented","msgtype":"m.text"},"ts":1394565448000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"sure, but it'll affect API behavior","msgtype":"m.text"},"ts":1394565480000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"if you create a WritableStream/ReadableStream pair (can you?), would you expect that object identity of ArrayBuffer objects would remain?","msgtype":"m.text"},"ts":1394565558000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"what do you mean by a pair in this case?","msgtype":"m.text"},"ts":1394565621000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"can you create a WriableStream/ReadableStream pair such that anything that's written into the WriableStream appears in the ReadableStream?","msgtype":"m.text"},"ts":1394565663000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sure, that's an identity transform stream","msgtype":"m.text"},"ts":1394565677000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"do you have to write JS code which pumps data between the two? Or can you create a pair of platform objects where that happens automatically?","msgtype":"m.text"},"ts":1394565759000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"you could create platform objects implement in JS... but the JS code to pump data between the two would just be something like `new TransformStream(function (in) { return this.addToOutput(in); })` (non-final API)","msgtype":"m.text"},"ts":1394565879000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"is a TransformStream both a readablestream and a writablestream in one object?","msgtype":"m.text"},"ts":1394565975000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"it is an { input: WritableStream, output: WritableStream } object literal","msgtype":"m.text"},"ts":1394565992000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"not nominally type-checked, of course","msgtype":"m.text"},"ts":1394566017000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"do you mean { input: WritableStream, output: ReadableStream }?","msgtype":"m.text"},"ts":1394566038000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yes, sorry","msgtype":"m.text"},"ts":1394566059000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"wait, i stil don't get it. What does the 'this' map to in your code example?","msgtype":"m.text"},"ts":1394566080000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"not that object literal obviously","msgtype":"m.text"},"ts":1394566087000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"nah, it was a perhaps overly-simplified example. the idea is that the TransformStream helper produces such objects. Perhaps a better constructor would be `new SyncTransformStream(function (in) { return in; })` or `new AsyncTransformStream(function (in, push, done) { push(in); push(in); done(); })` or something","msgtype":"m.text"},"ts":1394566154000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"this area is largely under-developed","msgtype":"m.text"},"ts":1394566165000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"as long as SyncTransformStream and AsyncTransformStream objects have { input, output } properties everything will work.","msgtype":"m.text"},"ts":1394566197000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"ok, let me ask the question this way then. If I have a ReadableStream, that I got from say XHR, can I pass that to Worker?","msgtype":"m.text"},"ts":1394566241000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"that goes outside my area of expertise... doesn't that have to be transferrable then?","msgtype":"m.text"},"ts":1394566261000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"transferrable or structured-clonable. For streams transferrable is indeed what you likely want","msgtype":"m.text"},"ts":1394566299000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i assume that would have to apply to all objects it holds a reference too","msgtype":"m.text"},"ts":1394566328000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"otherwise you have to tee the stream","msgtype":"m.text"},"ts":1394566332000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"which would include arbitrary objects in general","msgtype":"m.text"},"ts":1394566338000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"since you can create a stream of arbitrary objects","msgtype":"m.text"},"ts":1394566343000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"this is a stream i got from an XHR","msgtype":"m.text"},"ts":1394566355000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"...if that makes a difference","msgtype":"m.text"},"ts":1394566368000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"ok","msgtype":"m.text"},"ts":1394566387000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"so can you transfer that to a worker?","msgtype":"m.text"},"ts":1394566397000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"so i think i see what you're getting at","msgtype":"m.text"},"ts":1394566399000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"you would like certain platform-created streams to only hold references to transferable objects","msgtype":"m.text"},"ts":1394566411000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"so that they could be tranfserred to workers","msgtype":"m.text"},"ts":1394566415000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"but putBack would defeat this","msgtype":"m.text"},"ts":1394566418000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"not neccesarily","msgtype":"m.text"},"ts":1394566428000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"and i don't think i just want it for \"certain platform created streams\"","msgtype":"m.text"},"ts":1394566449000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"well user-created streams can be streams of functions, which IIRC are not transferable","msgtype":"m.text"},"ts":1394566473000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"or streams where most of the time it's a string and then every 1000th element is a function","msgtype":"m.text"},"ts":1394566485000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"right","msgtype":"m.text"},"ts":1394566492000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"so my qustion remains. Do you think you should be able to take a stream that comes from an XHR and pass that to a worker?","msgtype":"m.text"},"ts":1394566532000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"*I* want that to be possible, but I realize that might not be something that everyone thinks is a priority","msgtype":"m.text"},"ts":1394566564000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i don't know enough about use cases to answer decisively. my gut is that the worker itself should have input and output streams you can pipe through","msgtype":"m.text"},"ts":1394566579000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"it would be nice if piping arraybuffers or other transferables into a worker did a transfer instead of a copy","msgtype":"m.text"},"ts":1394566613000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"similarly, should you be able to take a ReadableStream and write it to disk using the filesystem API?","msgtype":"m.text"},"ts":1394566629000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i feel like these are all use cases streams were meant to obsolete","msgtype":"m.text"},"ts":1394566652000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"you pipe a readable stream to the disk","msgtype":"m.text"},"ts":1394566662000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"you don't store the stream itself on the disk","msgtype":"m.text"},"ts":1394566670000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"you pipe a stream to a web worker","msgtype":"m.text"},"ts":1394566681000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"sure, s/write/pipe/","msgtype":"m.text"},"ts":1394566686000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"you don't transfer  the stream itself to the web worker","msgtype":"m.text"},"ts":1394566691000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"ok","msgtype":"m.text"},"ts":1394566691000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"but in that case the disk is a writable stream","msgtype":"m.text"},"ts":1394566697000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"and you're just piping the readable stream to it","msgtype":"m.text"},"ts":1394566703000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"which operates through the well-known public API","msgtype":"m.text"},"ts":1394566708000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"well","msgtype":"m.text"},"ts":1394566715000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"if I get a readable stream from an XHR, and then pipe that to a writablestream that goes to disk, I don't think we want to hit the main thread for each chunk of data, right?","msgtype":"m.text"},"ts":1394566750000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"fair, but that's an optimization","msgtype":"m.text"},"ts":1394566761000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"you can e.g. only make that optimization if nobody's done `diskStream.write = function (chunk) { console.log(chunk); oldDiskStreamWrite.apply(this, arguments); }`","msgtype":"m.text"},"ts":1394566787000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"is that an optimization that's possible if we always go through the public API?","msgtype":"m.text"},"ts":1394566796000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"the optimization would be skipping the public API where possible","msgtype":"m.text"},"ts":1394566806000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"i'm not sure if that's a good idea. I've never thought about it that way","msgtype":"m.text"},"ts":1394566848000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"seems like it potentially is a big performance hit","msgtype":"m.text"},"ts":1394566862000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"hmm. from what i understand many JS engine optimizations work that way","msgtype":"m.text"},"ts":1394566867000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"what happens if no-one had touched diskStream.write, but after 2 minutes they suddenly set diskStream.write?","msgtype":"m.text"},"ts":1394566901000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"like if you do Object.defineProperty(Array.prototype, \"0\", { set: function () { console.log(\"haha!\"); }) you skip the fast-path on setting array elements in memory","msgtype":"m.text"},"ts":1394566904000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"hmm","msgtype":"m.text"},"ts":1394566910000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"should we detect that and reroute the traffic at that point?","msgtype":"m.text"},"ts":1394566914000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"we could spec pipe to cache the value of the write function at the time the pipe initiates","msgtype":"m.text"},"ts":1394566924000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"it's not impossible. But it likely will mean we won't do it for a long time","msgtype":"m.text"},"ts":1394566932000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i'm not sure what the right fix is. But I think it needs to be relatively easily possible for an implementation to not have to go through any thread that the data has been piped through at some point","msgtype":"m.text"},"ts":1394567009000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i agree that should be a high high priority","msgtype":"m.text"},"ts":1394567018000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"probably the highest","msgtype":"m.text"},"ts":1394567026000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"cool","msgtype":"m.text"},"ts":1394567052000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"the way we do this in the DOM is that we don't operate through the public API at all times. Rather we usually operate through internal operations. Which I realize might break use cases that you have in mind","msgtype":"m.text"},"ts":1394567102000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"so not saying this as a recommendation, but rather as a \"that's how we solve it elsewhere\"","msgtype":"m.text"},"ts":1394567122000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"caching write (and any function it calls, if any?) might actually work too","msgtype":"m.text"},"ts":1394567179000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"and I do think that we need to be able to hand off consuming a stream from one thread to another. If that means \"pass to worker\" or \"pipe to worker\" I'm not sure. But I don't know what \"pipe to worker\" would look like.","msgtype":"m.text"},"ts":1394567290000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"yeah, it is generally better to have fewer internal ops if possible, to allow users the same level of power and access as the platform. So if we can do that without hurting perf that's ideal. But obviously a large part of the point of streams is perf, so we have to be extra careful not to hurt ourselves in that way.","msgtype":"m.text"},"ts":1394567291000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"I am hoping pipe to worker looks like `myStream.pipeTo(myWorker.input)`","msgtype":"m.text"},"ts":1394567310000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"what's myworker.input?","msgtype":"m.text"},"ts":1394567320000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"a WritableStream","msgtype":"m.text"},"ts":1394567335000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"where does the data go?","msgtype":"m.text"},"ts":1394567352000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"which probably manifests as self....something... inside the worker","msgtype":"m.text"},"ts":1394567361000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"where ...something... is a readable stream","msgtype":"m.text"},"ts":1394567373000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"so you can only pipe one stream to a worker ever?","msgtype":"m.text"},"ts":1394567389000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"node has this in its child process API, but granted that's processes, not heavyweight threads","msgtype":"m.text"},"ts":1394567390000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"nah, you can always multiplex","msgtype":"m.text"},"ts":1394567397000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"or we could do messageport-style ports","msgtype":"m.text"},"ts":1394567405000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"MessageChannel I mean. I suppose the fact that MessageChannel exists in the face of postMessage implies people want easy multiplexing","msgtype":"m.text"},"ts":1394567457000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"yeah, Gecko's lack of MessageChannel has been a thorn in yehuda's side","msgtype":"m.text"},"ts":1394567493000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"so would each messageport have a .input (ReadableStream) and a .output (WritableStream) property?","msgtype":"m.text"},"ts":1394567647000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"other way around, you write to inputs and and read from outputs, but yes","msgtype":"m.text"},"ts":1394567778000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"\"thorn in yehuda's side\" was the name of *whose* high school band?","msgtype":"m.text"},"ts":1394567792000,"senderName":"hober","senderId":"hober@irc"},
{"content":{"body":"Mine","msgtype":"m.text"},"ts":1394567802000,"senderName":"Ms2ger","senderId":"Ms2ger@irc"},
{"content":{"body":"hober: haha","msgtype":"m.text"},"ts":1394567809000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: seems like a somewhat clunky way to get a stream transferred to a worker. You first have to create a message channel, then transfer one of the ports to the worker, then pipe your readablestream into the other port's input","msgtype":"m.text"},"ts":1394567895000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: is that how message channels work now? wow that is clunky","msgtype":"m.text"},"ts":1394568004000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"better APIs welcome certainly","msgtype":"m.text"},"ts":1394568039000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: only when you want to establish a new channel. If you already have a channel open then you can just postMessage","msgtype":"m.text"},"ts":1394568065000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: but if you have a channel open and you want to tell it \"here, process this stream\", then you need a way to do that. For other things we just transfer them","msgtype":"m.text"},"ts":1394568115000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"Domenic_: but if you can't transfer streams then a simple postMessage doesn't work","msgtype":"m.text"},"ts":1394568151000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"ok, but if you already have the channel open, then it's just stream.pipeTo(channel.input). Seems similar effort to postMessage","msgtype":"m.text"},"ts":1394568156000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: but you can only do that once. If you later want to say \"here, process this stream too\" then you'd have to multiplex over the same channel","msgtype":"m.text"},"ts":1394568213000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"err.. over the same stream","msgtype":"m.text"},"ts":1394568221000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"ah, i see","msgtype":"m.text"},"ts":1394568227000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"i guess i am assuming you would want multiple streams just as often as you would want multiple channels","msgtype":"m.text"},"ts":1394568248000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"what do people open multiple channels for anyway?","msgtype":"m.text"},"ts":1394568253000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: i'm not entirely sure. Ask Yehuda.","msgtype":"m.text"},"ts":1394568446000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"sicking: will do!","msgtype":"m.text"},"ts":1394568456000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"Domenic_: but here it's more \"multiple work items\" rather than \"multiple channels\"","msgtype":"m.text"},"ts":1394568464000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"i.e. a stream can represent a work item","msgtype":"m.text"},"ts":1394568475000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"anyhow, gotta join a call, sorry","msgtype":"m.text"},"ts":1394568483000,"senderName":"sicking","senderId":"sicking@irc"},
{"content":{"body":"np, i should probably do my day job","msgtype":"m.text"},"ts":1394568578000,"senderName":"Domenic_","senderId":"Domenic_@irc"},
{"content":{"body":"hello everyone","msgtype":"m.text"},"ts":1394568978000,"senderName":"Rahul21","senderId":"Rahul21@irc"},
{"content":{"body":"is it possible to customize the <audio> tag, to set cue points in the seekbar?","msgtype":"m.text"},"ts":1394569021000,"senderName":"Rahul21","senderId":"Rahul21@irc"},
{"content":{"body":"Nope.","msgtype":"m.text"},"ts":1394569107000,"senderName":"TabAtkins","senderId":"TabAtkins@irc"},
{"content":{"body":"TabAtkins: http://imgur.com/onhyHYR","msgtype":"m.text"},"ts":1394569131000,"senderName":"Rahul21","senderId":"Rahul21@irc"},
{"content":{"body":"TabAtkins: something like that, any alternatives to do it?","msgtype":"m.text"},"ts":1394569154000,"senderName":"Rahul21","senderId":"Rahul21@irc"},
{"content":{"body":"Not with the <audio> tag, no.","msgtype":"m.text"},"ts":1394569163000,"senderName":"TabAtkins","senderId":"TabAtkins@irc"},
{"content":{"body":"Rahul21: what you can do is have an invisible <audio> element (without controls) and implement your own controls based on the JS API","msgtype":"m.text"},"ts":1394570150000,"senderName":"SimonSapin","senderId":"SimonSapin@irc"},
{"content":{"body":"… maybe","msgtype":"m.text"},"ts":1394570162000,"senderName":"SimonSapin","senderId":"SimonSapin@irc"},
{"content":{"body":"(I haven’t actually tried anything like this)","msgtype":"m.text"},"ts":1394570172000,"senderName":"SimonSapin","senderId":"SimonSapin@irc"},
{"content":{"body":"SimonSapin: any demos or links would be very helpful","msgtype":"m.text"},"ts":1394570313000,"senderName":"Rahul21","senderId":"Rahul21@irc"},
{"content":{"body":"resources anything","msgtype":"m.text"},"ts":1394570322000,"senderName":"Rahul21","senderId":"Rahul21@irc"},
{"content":{"body":"I don’t any right now, sorry","msgtype":"m.text"},"ts":1394570361000,"senderName":"SimonSapin","senderId":"SimonSapin@irc"},
{"content":{"body":"anyone know that status of cross-origin font loading in the various browsers?","msgtype":"m.text"},"ts":1394578800000,"senderName":"Hixie","senderId":"Hixie@irc"},
{"content":{"body":"Firefox blocks, Webkit doesn't, Blink doesn't but is considering switching to blocking, IE I dunno.","msgtype":"m.text"},"ts":1394578830000,"senderName":"TabAtkins","senderId":"TabAtkins@irc"},
{"content":{"body":"thanks","msgtype":"m.text"},"ts":1394578919000,"senderName":"Hixie","senderId":"Hixie@irc"}
]