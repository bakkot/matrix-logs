[
{"content":{"body":"When writing a lexer for ECMAScript how do you decide when to change between the goal symbols? https://tc39.es/ecma262/#sec-ecmascript-language-lexical-grammar I naively converted them to regex to toy with an idea. https://gist.github.com/sirisian/5c3402ca51a2440f0bc4e5d297269195 (Ignore any mistakes, I plan to redo it). Like I get that you'd start with InputElementHashbangOrRegExp https://regex101.com/r/YYgu1i/1 So the lexer would take tokens until it ran into a TemplateMiddle or TemplateTail. So in that example it takes the \"a\" then can't consume the \"}\". Where does one get the context, whether a RegularExpressionLiteral or TemplateMiddle/Tail is permitted? Is this based on the previous tokens? Do you have to like parse as you run the lexer so you'd potentially parse TemplateSpans -> TemplateMiddleList -> TemplateMiddle and this that would mean that's permitted. (And then you'd do the same to see if RegularExpressionLiteral is permitted)?","m.mentions":{},"msgtype":"m.text"},"ts":1717131222479,"senderName":"sirisian","senderId":"@sirisian:matrix.org","id":"$idvKGi0P3uJP-Ju8NWxNmEk7_CbTGNVsjkbg_1Yr5IY"},
{"content":{"body":"yes, you have to parse as you run the lexer","m.mentions":{},"msgtype":"m.text"},"ts":1717134560446,"senderName":"bakkot","senderId":"@bakkot:matrix.org","id":"$_oYMq-fBSqW1ZUxb_o7DEcej-AW9t8MBMS-FcGErsDM"},
{"content":{"body":"or at least, this is how everyone does it afaik","m.mentions":{},"msgtype":"m.text"},"ts":1717134571006,"senderName":"bakkot","senderId":"@bakkot:matrix.org","id":"$e8h7HpuraiNqOs6hvLU3IG3TTZYrSprtEjXw3uwqzH8"},
{"content":{"body":"that is what this sentence is getting at:\n\n> There are several situations where the identification of lexical input elements is sensitive to the syntactic grammar context that is consuming the input elements.","format":"org.matrix.custom.html","formatted_body":"<p>that is what this sentence is getting at:</p>\n<blockquote>\n<p>There are several situations where the identification of lexical input elements is sensitive to the syntactic grammar context that is consuming the input elements.</p>\n</blockquote>\n","m.mentions":{},"msgtype":"m.text"},"ts":1717134594918,"senderName":"bakkot","senderId":"@bakkot:matrix.org","id":"$huQdmWxroY3S246FJ7E2sxKZpQTotXW-WH0VGZLmGQ4"},
{"content":{"body":"i.e., you can't know how to tokenize (the lexical grammar) without knowing the context from the higher-level parse (the syntactic grammar)","m.mentions":{},"msgtype":"m.text"},"ts":1717134630798,"senderName":"bakkot","senderId":"@bakkot:matrix.org","id":"$q5-eOk66tIHws73iYpCBo8dnRYq_LTgq1vMtaKXFiC4"}
]