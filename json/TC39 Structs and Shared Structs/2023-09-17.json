[
{"content":{"body":"I'm still tinkering with my parallel parse prototype, and I'm planning to try it on a few large scale projects. I'm not currently seeing the perf-gains I would hope, but its too early to say if its an issue with the shared structs functionality, the size of the projects I've been using for testing, or something about how I've had to hack around parts of the compiler to get something functional.\nI wrote a rudimentary work-stealing thread pooling mechanism, but I'm finding that adding more threads slows down parse rather than speeding it up for the monorepo I've been using as a test case. CPU profiling shows a lot of the threads aren't processing work efficiently, and are either spinning around trying to steal work or are waiting to be notified of work. Spinning isn't very efficient because there's no spin-wait mechanism nor the ability to write an efficient one (I can sort-of approximate one using `Condition.wait` with a short timeout to emulate `sleep`, but I can't efficiently yield). I also can't write efficient lock-free algorithms with shared structs alone, since I can't do CAS, so the fastest \"lock-free\"-ish updates I can perform are inside of a `Mutex.tryLock` unless I want to fall back to also sending a `SharedArrayBuffer` to the worker just so I can use `Atomics.compareExchange`.\n\nHere's a rough approximation of the thread pool I'm using right now, if anyone has suggestions or feedback: https://gist.github.com/rbuckton/3648f878595ed4e2ff3d52a15baaf6b9","format":"org.matrix.custom.html","formatted_body":"<p>I'm still tinkering with my parallel parse prototype, and I'm planning to try it on a few large scale projects. I'm not currently seeing the perf-gains I would hope, but its too early to say if its an issue with the shared structs functionality, the size of the projects I've been using for testing, or something about how I've had to hack around parts of the compiler to get something functional.<br>I wrote a rudimentary work-stealing thread pooling mechanism, but I'm finding that adding more threads slows down parse rather than speeding it up for the monorepo I've been using as a test case. CPU profiling shows a lot of the threads aren't processing work efficiently, and are either spinning around trying to steal work or are waiting to be notified of work. Spinning isn't very efficient because there's no spin-wait mechanism nor the ability to write an efficient one (I can sort-of approximate one using <code>Condition.wait</code> with a short timeout to emulate <code>sleep</code>, but I can't efficiently yield). I also can't write efficient lock-free algorithms with shared structs alone, since I can't do CAS, so the fastest \"lock-free\"-ish updates I can perform are inside of a <code>Mutex.tryLock</code> unless I want to fall back to also sending a <code>SharedArrayBuffer</code> to the worker just so I can use <code>Atomics.compareExchange</code>.</p>\n<p>Here's a rough approximation of the thread pool I'm using right now, if anyone has suggestions or feedback: https://gist.github.com/rbuckton/3648f878595ed4e2ff3d52a15baaf6b9</p>\n","msgtype":"m.text"},"ts":1694970364059,"senderName":"rbuckton","senderId":"@rbuckton:matrix.org","id":"$k0312Le1qqzBZ_AgI-7QIdIsuBN7__7Fv949n6o_JYs"},
{"content":{"body":"Ah, wait. I just noticed I can do compareExchange with `SharedArray`. That's good.","format":"org.matrix.custom.html","formatted_body":"Ah, wait. I just noticed I can do compareExchange with <code>SharedArray</code>. That's good.","msgtype":"m.text"},"ts":1694970536043,"senderName":"rbuckton","senderId":"@rbuckton:matrix.org","id":"$5Si6PhySBPpLr-up7ioluuBO9AHJll4hwnusvSeoJjU"},
{"content":{"body":" * Ah, wait. I just noticed I can do `compareExchange` with `SharedArray` and shared structs. That's wonderful!","format":"org.matrix.custom.html","formatted_body":" * Ah, wait. I just noticed I can do <code>compareExchange</code> with <code>SharedArray</code> and shared structs. That's wonderful!","m.new_content":{"body":"Ah, wait. I just noticed I can do `compareExchange` with `SharedArray` and shared structs. That's wonderful!","format":"org.matrix.custom.html","formatted_body":"Ah, wait. I just noticed I can do <code>compareExchange</code> with <code>SharedArray</code> and shared structs. That's wonderful!","msgtype":"m.text"},"m.relates_to":{"event_id":"$5Si6PhySBPpLr-up7ioluuBO9AHJll4hwnusvSeoJjU","rel_type":"m.replace"},"msgtype":"m.text"},"ts":1694970598980,"senderName":"rbuckton","senderId":"@rbuckton:matrix.org","id":"$y-mbsm9c5eJ_CII1UBhitU2Hn4Pb_aa8CySZKclBlG8"},
{"content":{"body":"I've updated my gist slightly to perform atomic updates on the task counter, probably a few more updates later.","msgtype":"m.text"},"ts":1694973824827,"senderName":"rbuckton","senderId":"@rbuckton:matrix.org","id":"$wRcY_nWzvii4B68lYCV_n8XAr6wcvLxA1Q0rFBZ1MIc"},
{"content":{"body":">  I also can't write efficient lock-free algorithms with shared structs alone, since I can't do CAS, so the fastest \"lock-free\"-ish updates I can perform are inside of a Mutex.tryLock unless I want to fall back to also sending a SharedArrayBuffer to the worker just so I can use Atomics.compareExchange.\n\nwhy can't you CAS shared structs?","format":"org.matrix.custom.html","formatted_body":"<blockquote>\n<p>I also can't write efficient lock-free algorithms with shared structs alone, since I can't do CAS, so the fastest \"lock-free\"-ish updates I can perform are inside of a Mutex.tryLock unless I want to fall back to also sending a SharedArrayBuffer to the worker just so I can use Atomics.compareExchange.</p>\n</blockquote>\n<p>why can't you CAS shared structs?</p>\n","msgtype":"m.text"},"ts":1694991952086,"senderName":"shu","senderId":"@shuyuguo:matrix.org","id":"$GXBkjxQ-HMXdk2SofVICYwbZ6R9Q55vaxeIbWJwuVq0"},
{"content":{"body":"`Atomics.compareExchange` works with shared struct fields!","format":"org.matrix.custom.html","formatted_body":"<code>Atomics.compareExchange</code> works with shared struct fields!","msgtype":"m.text"},"ts":1694991958600,"senderName":"shu","senderId":"@shuyuguo:matrix.org","id":"$QgRJYmp9Jtxl7V52w7x8b6AowkxaI985EqsovWqz1wk"},
{"content":{"body":"oh, i should've kept reading, you noticed it","msgtype":"m.text"},"ts":1694991968058,"senderName":"shu","senderId":"@shuyuguo:matrix.org","id":"$kwZaOTDoR66AtB-8guMAle0ADIvqioyMC1zRnaME9g4"}
]