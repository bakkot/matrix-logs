2022-03-01
[16:55:47.0607] <Justin Ridgewell>
danielrosenwasser / rbuckton: The new What's Changed Since RC/Beta in the TS release notes are üëç

[17:47:45.0044] <sirisian>
Question. Possibly I'm not searching the right terms, but when async/await was added to ECMAScript, why was threading never pulled into the core language away from Web Workers? (As others I've done the blob thing for years with workers when doing heavily threaded things). I kind of expected that one would be able to just call an async function and have it execute on another thread by now with intuitive shared state, but that was never proposed. Why not?

[17:55:08.0758] <bakkot>
"intuitive shared state" is a contradiction in terms

[17:55:51.0018] <bakkot>
the thing you're proposing would be incredibly complicated to specify or implement, and we're just now getting to the point where we're fleshing out the building blocks which might let us get there someday

[17:56:03.0616] <bakkot>
or, well, not there precisely, but somewhere like it

[18:19:23.0514] <Jack Works>
> <@sirisian:matrix.org> Question. Possibly I'm not searching the right terms, but when async/await was added to ECMAScript, why was threading never pulled into the core language away from Web Workers? (As others I've done the blob thing for years with workers when doing heavily threaded things). I kind of expected that one would be able to just call an async function and have it execute on another thread by now with intuitive shared state, but that was never proposed. Why not?

we're on the route of that. ü§î
search for those proposals:
- struct (shared struct section)
- module block

[18:41:56.0618] <bakkot>
> <@gibson042:matrix.org> can someone verify my assessment that https://github.com/mishoo/UglifyJS/issues/5370 represents a deviation of V8 from other major implementations in FunctionDeclarationInstantiation with respect to non-simple parameter lists when VarDeclaredNames includes "arguments"?
> ```
> $ eshost -se '[].concat(...["function arguments(){}", "var arguments"].map(occluding => ["()", "(..._)", "(_=0)"].map(params => { const r="return typeof arguments; ", f=Function(params.slice(1,-1), r+occluding); return `${f().padEnd(9)} // function${params}{${r+occluding}}`; }))).join("\n")'
> #### ChakraCore, engine262, JavaScriptCore, Moddable XS, SpiderMonkey
> function  // function(){return typeof arguments; function arguments(){}}
> function  // function(..._){return typeof arguments; function arguments(){}}
> function  // function(_=0){return typeof arguments; function arguments(){}}
> object    // function(){return typeof arguments; var arguments}
> object    // function(..._){return typeof arguments; var arguments}
> object    // function(_=0){return typeof arguments; var arguments}
> 
> #### V8
> function  // function(){return typeof arguments; function arguments(){}}
> function  // function(..._){return typeof arguments; function arguments(){}}
> function  // function(_=0){return typeof arguments; function arguments(){}}
> object    // function(){return typeof arguments; var arguments}
> undefined // function(..._){return typeof arguments; var arguments}
> undefined // function(_=0){return typeof arguments; var arguments}
> ```

Tracing through the full machinery would take me a while, but I can at least confirm that there should not be a difference between simple and non-simple arguments lists in this case, so V8 is definitely wrong _somewhere_, and it seems quite likely to be wrong in the cases where it differs from other implementations

[18:42:31.0371] <sirisian>
Well intuitive as in all closed over variables and they automatically behave like SharedArrayBuffer items without the bloat. (And in scope functions can just be called without any module syntax). Creating a variable and using an atomic to increment it or other operation would just "work" without stuff like shared structs or shuffling stuff into TypedArrays like it's some separate API.

[18:45:12.0310] <bakkot>
SABs are the single most "handle with care" part of the entire language, especially when used without atomics; making it so that every single thing in the language behaved like that would be... not an idea I'd endorse, to put it lightly, and I imagine that's a common sentiment among the committee

[18:46:32.0295] <bakkot>
Like, just getting the memory model right for SABs was incredibly complicated, and not without bugs; see e.g. https://github.com/tc39/ecma262/issues/1680 https://github.com/tc39/ecma262/issues/2231 https://github.com/tc39/ecma262/pull/1511

[18:46:52.0305] <bakkot>
and that's the _simple_ case, where you're just dealing with raw bytes; it gets more complicated when you get more complicated data structures involved

[18:49:43.0636] <bakkot>
(also blocking atomics don't work on the main thread, so the "using an atomic to increment it" thing doesn't really make sense at least not on the main thread)

[18:49:58.0546] <bakkot>
 * (also blocking atomics don't work on the main thread, so the "using an atomic to increment it" thing doesn't really make sense at least not on the main thread)

[18:50:07.0307] <bakkot>
 * (also blocking atomics don't work on the main thread, so the "using an atomic to increment it" thing doesn't really make sense, at least not on the main thread)

[19:04:43.0339] <sirisian>
I meant incrementing in other threads. My general thinking is I'd like for SharedArrayBuffer to be deprecated such that a variable and thread system works more like C++. In this case everything is handled with care implied. Was talking to someone about my type proposal/notes and they commented that you can't just create say an integer in the main thread and increment it in multiple threads (with atomics). In this setup you'd be able to do things like swap two object references atomically or set a variable object atomically. It definitely would be very complex to implement, but for the user they could just call functions to create threads and implement parallelism without any extra sugar (wrapping of objects, functions, variables).

[19:05:06.0557] <ljharb>
also, not everyone on the committee :cough: is convinced that threads are "not incredibly harmful" :-)

[19:08:48.0643] <sirisian>
I completely get that. I'm migrating over to WebGPU for my current toy projects. Most of my applications were more "spin up 8 threads because I can't use the GPU to compute this" situation. Still for simple projects for demos it would be nice to write a few lines of code to say run a pathfinding algorithm on multiple threads. Though the module block fits those kind of applications cleanly where I'm not sharing state between threads.

[19:09:37.0328] <bakkot>
As a rule we don't usually introduce features only intended to be used in toy projects, particularly when they have sharp edges

[19:10:12.0960] <bakkot>
and shared-memory parallelism isn't just a sharp edge, it's an entire box of rusty razor blades

[19:10:44.0440] <Jack Works>
> <@bakkot:matrix.org> and shared-memory parallelism isn't just a sharp edge, it's an entire box of rusty razor blades

so how u think about the shared structs proposal?

[19:12:01.0716] <bakkot>
Jack Works: as with SABs it's something which will be useful to build safe-to-use libraries on top of, but not something I'd expect users to touch in everyday life

[19:13:14.0651] <bakkot>
it's carefully designed so that the shared memory parts are constrained to the struct and its references, and doesn't get out into the rest of your program, which is the only thing which makes it even conceivably a good idea

[19:13:52.0803] <bakkot>
that is, I agree with the readme:

> Like other shared memory features in JavaScript, it is high in expressive power and high in difficulty to use correctly. This proposal is both intended as an incremental step towards higher-level, easier-to-use (e.g. data-race free by construction) concurrency abstractions as well as an escape hatch for expert programmers who need the expressivity.

[19:13:56.0733] <Jack Works>
> <@bakkot:matrix.org> Jack Works: as with SABs it's something which will be useful to build safe-to-use libraries on top of, but not something I'd expect users to touch in everyday life

once it is available, it will be used in everyday life by programmers that has c++/rust/java/... background

[19:14:05.0084] <bakkot>
well

[19:14:07.0179] <bakkot>
seems bad

[19:14:11.0859] <Jack Works>
lol

[19:14:15.0817] <bakkot>
if we actually think that's going to happen, it's probably not worth putting in the language

[19:15:06.0585] <bakkot>
that said, I have a background in all of those languages and still wouldn't touch structs without thinking _extremely_ carefully about it

[19:15:18.0687] <Jack Works>
no one use SAB+worker because it's too hard to create one than just following JS style of multi-thread programming 

[19:15:42.0800] <bakkot>
I use SABs...

[19:16:02.0938] <bakkot>
but, you know, only after thinking extremely carefully about it

[19:16:13.0919] <bakkot>
and emscripten uses them to good effect as well

[19:16:45.0896] <bakkot>
I think module blocks will make workers more popular in general, tbh

[19:17:02.0815] <Jack Works>
> <@sirisian:matrix.org> I completely get that. I'm migrating over to WebGPU for my current toy projects. Most of my applications were more "spin up 8 threads because I can't use the GPU to compute this" situation. Still for simple projects for demos it would be nice to write a few lines of code to say run a pathfinding algorithm on multiple threads. Though the module block fits those kind of applications cleanly where I'm not sharing state between threads.

ü§î for a toy project maybe you can try a toy runtime. I've heard that the structed proposal has a demo implementation in V8. maybe u can contact v8 team to get a demo build and play around

[19:17:06.0434] <ljharb>
if something is going to encourage wider usage of multi-threaded programming in JS, that sounds like a huge detriment to the language

[19:17:14.0140] <bakkot>
multi-threading is good!

[19:17:14.0805] <ljharb>
"being single-threaded" is a feature, not a bug

[19:17:16.0216] <sirisian>
Well WebGPU makes it not a toy project technically since it's identical to an existing piece of software. The performance issue of doing the project with web workers made it very suboptimal compared to usual approaches (like much slower with limitations a GPU approach wouldn't have). The main idea though is taking a data structure and passing it through a pipeline where each operation is expensive. One could imagine say using the pipeline proposal and each function just calls a thread? yeah, that's probably close, but simplified.

[19:17:20.0962] <bakkot>
shared-memory multithreading is bad

[19:17:25.0919] <bakkot>
but multiple threads are good

[19:17:38.0830] <bakkot>
CPUs have many cores

[19:17:43.0400] <ljharb>
i can agree that things that are observably the same as "being single-threaded" is good

[19:18:10.0593] <ljharb>
the thing i value is that things must act as if they're single-threaded. they can be faster than that if i can't tell the difference, and that's a good thing

[19:18:12.0630] <bakkot>
deliberately limiting your programming language so that it can't use more than 1/16th of the CPU seems like... bad

[19:18:28.0620] <sirisian>
I have a 12900k for reference. :|

[19:19:07.0801] <bakkot>
we shouldn't be optimizing for people with 12900ks

[19:19:24.0616] <Jack Works>
> <@ljharb:matrix.org> "being single-threaded" is a feature, not a bug

this goes too far. i support multi-thread by message passing, not memory sharing

[19:19:26.0333] <bakkot>
but even the cheapest android phones available have 4 cores these days

[19:21:23.0012] <pokute>
We could simultaneously introduce manual memory management as a viable alternative to GC in ECMAScript since users will appreciate the freedom. üöé

[19:21:35.0740] <pokute>
 * We could simultaneously introduce manual memory management as a viable alternative to GC in ECMAScript since users will appreciate the freedom. üöé

[19:22:02.0476] <Jack Works>
actually I'm curious about, if Record&Tuple are shipped and highly optimized by the engine, does that make life easier?

[19:22:30.0437] <bakkot>
records and tuples are immutable so it doesn't much matter

[19:22:37.0048] <Jack Works>
we can pass immutable object/arrays with 0 serialization cost (engine can share the memory)

[19:22:38.0197] <bakkot>
you'd still have to `postMessage` them, and you can do that with a plain object

[19:22:50.0823] <Jack Works>
> <@bakkot:matrix.org> you'd still have to `postMessage` them, and you can do that with a plain object

yeah, but that need a clone

[19:22:54.0308] <bakkot>
yeah that's fair

[19:23:38.0057] <bakkot>
my impression is that the expensiveness of the clone is rarely a limiting factor, but it might be for some projects

[19:23:51.0863] <Jack Works>
> <@pokute:matrix.org> We could simultaneously introduce manual memory management as a viable alternative to GC in ECMAScript since users will appreciate the freedom. üöé

WeakMap[@@iterator]!

[19:24:07.0494] <bakkot>
that's been proposed...

[19:24:14.0977] <bakkot>
you can do it yourself with weakrefs if you really want to

[19:24:16.0614] <bakkot>
but, like

[19:24:17.0232] <bakkot>
don't

[19:25:11.0342] <Jack Works>
> <@bakkot:matrix.org> my impression is that the expensiveness of the clone is rarely a limiting factor, but it might be for some projects

üëÄ what's the common limit?

[19:25:55.0423] <bakkot>
workers are annoying to create, mostly

[19:26:01.0347] <bakkot>
and postmessage is annoying to use

[19:26:11.0469] <bakkot>
you can't just `await` stuff without building some wrappers

[19:27:23.0324] <sirisian>
> <@ljharb:matrix.org> if something is going to encourage wider usage of multi-threaded programming in JS, that sounds like a huge detriment to the language

My thinking is people should be able to use it without thinking much or from other libraries. Like years ago I wrote a small game server in C++ for web sockets then converted it to node.js with WS. In order to speed up things to support thousands of players again I moved the packet deserialization stuff to another "thread" with cluster. Creating simple producer/consumer systems in worker threads for processing packets should be like super simple. (In C++ I was using I think boost fibers for something similar and it was very elegant).

[19:27:59.0220] <Jack Works>
I think requiring memory-sharing in JS is like requiring imperative style programming in haskell ü§î

[19:28:01.0716] <ljharb>
you've got a lot of "shoulds" in there that seem pretty informed by C++ experience, which isn't something most JS programmers have or will ever have

[19:30:18.0863] <ljharb>
i'm pretty confident that in the fullness of time, the majority of JS devs won't have ever used something besides JS :-) no way to prove it either way, ofc.

[19:30:29.0151] <bakkot>
ljharb I feel like "it is good to do expensive compute off the main thread" is like... not a principle I would expect to find disagreement with?

[19:30:30.0857] <Jessidhia>
I haven‚Äôt used Go in over 5 years but I miss goroutines and channels

[19:31:00.0977] <sirisian>
Well I'm just saying there are situations where a JS programmer runs into an issue and the real solution of just calling a thread and passing work over is much more complicated than it should be.

[19:31:04.0714] <pokute>
Well, I would be interested in what kind of API would be super simple for a JS developer for writing "multi-threaded" code.

[19:31:06.0529] <ljharb>
bakkot: yeah i'm not disputing that. something that worked identically single-threaded as multi-threaded, so engines could unobservably execute them across multiple cores, would be amazing

[19:31:35.0556] <bakkot>
yeah but that's not... possible

[19:31:44.0246] <bakkot>
the whole point is that the compute is happening _while other compute is happening_

[19:31:48.0288] <bakkot>
which is inherently observable

[19:31:57.0644] <ljharb>
ay, there's the rub

[19:32:37.0600] <ljharb>
personally i would prefer a world where everything is eternally single-threaded, and parallelism is done via processes, to a world where JS is ruined by bringing in all the problems of threading. i'm quite sure there are those who violently disagree with me, ofc.

[19:32:52.0500] <bakkot>
threading is already a thing in JS

[19:33:03.0280] <ljharb>
sadly, that is true

[19:33:10.0489] <bakkot>
doesn't seem to have been ruined

[19:33:15.0554] <bakkot>
... at least, not by that

[19:33:20.0526] <ljharb>
that's because it's unapproachable and not super usable :-)

[19:33:35.0116] <Jack Works>
> <@bakkot:matrix.org> doesn't seem to have been ruined

because that api is tooooo hard to use

[19:33:37.0219] <ljharb>
i'm content to keep it that way, so that advanced niche use cases can leverage it, but regular JS devs aren't tempted to

[19:34:05.0738] <Jack Works>
you could only manipulate a number array

[19:34:13.0163] <bakkot>
you can postmessage

[19:34:27.0051] <bakkot>
which is the _only_ multithreading in some languages

[19:34:43.0810] <bakkot>
message passing is a totally normal way of doing multithreading

[19:35:13.0926] <Jack Works>
> <@bakkot:matrix.org> which is the _only_ multithreading in some languages

(including JS before we have SAB)

[19:35:13.0938] <bakkot>
ljharb I stand by "it is good to do expensive compute off the main thread"

[19:35:28.0013] <bakkot>
if that is good in general, then it is good for "regular JS devs"

[19:35:41.0384] <ljharb>
i think the goodness of that is far outweighed by the badness of threaded programming gotchas.

[19:35:54.0096] <ljharb>
slowness >>>>>> race conditions, always

[19:36:00.0013] <ljharb>
 * slowness >>>>>> race conditions, always

[19:36:02.0445] <bakkot>
basically all threaded programming gotchas are about shared memory

[19:36:19.0459] <pokute>
> <@sirisian:matrix.org> Well I'm just saying there are situations where a JS programmer runs into an issue and the real solution of just calling a thread and passing work over is much more complicated than it should be.

We can compare this to a early 2000s C++ programmer runs into an issue where they are waiting for a long operation (like disk read) and want to do something in the meantime. The default solution of threads and passing work over is a lot more complicated to wrap around than most other C++ code, especially with the special and hard-to-intuit considerations of thread-safeness.

[19:36:29.0439] <bakkot>
race conditions are almost always a thing in shared memory, but are no more a thing with message passing than they are with async functions

[19:36:30.0022] <ljharb>
i would be happy to be convinced that there's a threading model that has no shared memory yet has a deterministic way to communicate

[19:36:38.0108] <bakkot>
postmessage

[19:36:41.0763] <bakkot>
postmessage is the thing you are talking about

[19:36:45.0808] <bakkot>
also channels in go

[19:36:51.0771] <ljharb>
postMessage takes objects too

[19:36:54.0839] <bakkot>
it's like a very normal way of doing multithreading

[19:36:59.0517] <ljharb>
and to be fair, i'm not familiar with go

[19:36:59.0522] <bakkot>
the objects are cloned, not shared, in postMessage

[19:37:09.0905] <bakkot>
 * the objects are cloned, not shared, in postMessage

[19:37:33.0016] <ljharb>
sure, but structured cloning is its own pile of problems :-)

[19:38:06.0780] <bakkot>
right but whatever problems structured clone has, those problems aren't inherent to multithreading

[19:38:14.0824] <Jack Works>
> <@pokute:matrix.org> We can compare this to a early 2000s C++ programmer runs into an issue where they are waiting for a long operation (like disk read) and want to do something in the meantime. The default solution of threads and passing work over is a lot more complicated to wrap around than most other C++ code, especially with the special and hard-to-intuit considerations of thread-safeness.

don't know c++, but is io_uring some kind of async without block threading?

[19:38:30.0260] <bakkot>
being against shared memory parallelism is very reasonable, but it seems wrong to generalize this to being against multithreading in general

[19:39:44.0959] <sirisian>
That reminds me of someone's finance app I saw they made for a company. Kind of lagged. Was doing stuff with hundreds of thousands of records client-side. This was before web workers (and Power BI I think). Fascinating what people try to do in JS single page applications. Granted computers are faster now, so I don't think it's as huge of an issue.

[19:39:49.0767] <Jack Works>
> <@ljharb:matrix.org> sure, but structured cloning is its own pile of problems :-)

then message passing by R&T ‚Ñ¢!

[19:42:48.0431] <pokute>
> <@sirisian:matrix.org> That reminds me of someone's finance app I saw they made for a company. Kind of lagged. Was doing stuff with hundreds of thousands of records client-side. This was before web workers (and Power BI I think). Fascinating what people try to do in JS single page applications. Granted computers are faster now, so I don't think it's as huge of an issue.

I bet in a hundred years people will still be able to write lagging apps, even with thousands of items and even with multithreading. Can't underestimate people.  (Though if AI will write the software......)

[19:44:24.0947] <Jack Works>
another question. now we reified Realms and some host hooks (compartment proposal) as something we can control. is it impossible to have Agent/Agent Clusters reified to run suspious code? 

[19:44:59.0591] <bakkot>
depends on what you mean by "suspicious code"?

[19:45:11.0661] <Jack Works>
untrusted code

[19:45:22.0801] <bakkot>
completely untrusted? no

[19:46:02.0457] <bakkot>
spectre is going to sit there haunting you

[19:46:32.0100] <bakkot>
if timing attacks are outside your thread model, though, what do you want that realms don't already give you?

[19:46:34.0886] <Jack Works>
oh... but you can turn off high resolution timer right?

[19:46:39.0983] <bakkot>
no

[19:46:48.0216] <bakkot>
https://gruss.cc/files/fantastictimers.pdf

[19:47:01.0251] <Jack Works>
> <@bakkot:matrix.org> if timing attacks are outside your thread model, though, what do you want that realms don't already give you?

```js
while (true);
```

[19:47:15.0702] <bakkot>
do it in a worker?

[19:48:26.0980] <Jack Works>
well maybe i dont need to worry about while true so much

[19:52:22.0759] <pokute>
I would be really interested in any threading model that would allow something like `myThread.shareReference(globalThis);` that wouldn't completely break every JS coder's expectations.

[19:55:15.0922] <bakkot>
I don't think you can simultaneously have "shared memory" and "doesn't completely break every JS coder's expectations"

[19:55:36.0436] <bakkot>
at least not without adding in the whole of Rust's ownership model

[19:55:42.0946] <bakkot>
... which is going to break every JS coder's expectations anyway, for that matter

[20:00:04.0097] <pokute>
I think "multi-threading" in JS is a bad term, since "threads" imply certain stuff like shared memory that is practically impossible with JS.

[20:01:56.0621] <pokute>
threads are (I think) OS feature leveraging CPU capabilities that nothing of JS actually relies on. Workers could run on a separate process or even a remote server.

[20:03:02.0495] <pokute>
 * threads are (I think) OS feature leveraging CPU capabilities that nothing of JS actually relies on. Workers could run on a separate process or even a remote server.

[20:04:57.0734] <sirisian>
Again shared memory already exists. SharedArrayBuffer has allowed this for a long time now.

[20:06:04.0661] <pokute>
It's explicitly shared memory. That's very different from implicitly shared memory where all of a process' memory is shared between threads.

[20:24:07.0322] <pokute>
@sirisian I was thinking about your initial question, about the async/await. Async/await is just a different way to write some function calls (callbacks). For it to use multiple threads, every function call would have to be possibly using threads. For most callbacks, they just only call other functions. The functions that actually do heavy computation is a vanishingly small percentage. Creating a new costly thread for each function call would immediately erode any performance benefit gained from parallelism.

This might be fixed by JS engines inspecting code and spinning only such heavy computation functions into separate threads if it recognizes it to be safe. But that completely up to engine whether to do it and isn't a language issue at all.

[20:25:29.0164] <sirisian>
The threading would be explicit when making a call.

[20:25:30.0846] <pokute>
There's nothing that prevents existing engines to add a feature that they run heavy computation parallelly in separate threads if they can handle the possible side effects.

[20:27:01.0143] <pokute>
So it would be a normal function that is called?

[20:27:37.0722] <sirisian>
yes

[20:29:14.0921] <pokute>
A normal function has access to all globals and closures and is free to modify them as it sees fit. If it was run as a thread, this would mean implicit shared memory. How would other code that runs parallel to that be safe from variables changing their values suddenly?

[20:29:47.0993] <pokute>
 * A normal function has access to all globals and closures and is free to modify them as it sees fit. If it was run as a thread, this would mean implicit shared memory. How would other code that runs parallel to that be safe from variables changing their values suddenly?

[20:29:57.0932] <sirisian>
You could for example call multiple functions then await Promise.allSettled on them if you wanted to join back in an async task. I haven't thought about this hard at all, but like foo.callThread(..., args); which returns a promise. Ideally we'd have cancellable promises by then. >_>

[20:30:47.0310] <sirisian>
It wouldn't be safe at all. Using threads would have an assumed level of complexity just like using SharedArrayBuffer stuff.

[20:32:18.0095] <pokute>
From what I've understood of SharedArrayBuffer is that it's always completely safe to use due to how extremely narrow and restricted it's features are. It's not even complex. It's cumbersome.

[20:32:29.0063] <sirisian>
I should mentioned it would be my hope that with this we'd all get concurrent data structures and standard library stuff in the far future. I noticed that state of JS mentioned some data structure stuff. Not sure the context of that. Concurrent queue at the least. heh.

[20:35:18.0413] <pokute>
Also, people should take their promises more seriously. :-) Don't ask for promises that you can't receive later.

[20:39:51.0033] <pokute>
Cancelable promises are a terrible term since it never cancels any work a promise does. It only cancels the receiving of results. That's not what people expect.

[20:40:16.0194] <pokute>
 * Cancelable promises are a terrible term since it never reliably cancels any work a promise does. It only cancels the receiving of results. That's not what people expect.

[20:41:12.0611] <sirisian>
Good point.

[20:49:37.0390] <pokute>
Which is why code should rather gracefully receive and discard out-of-order and obsolete data received from promises. Instead of canceling promises (which is quite simple to do), you could expect a version number from a REST call. You could add metadata to a REST call that you receive with the result in a way to see that the result is for the current context you're viewing. Etc...

[20:50:18.0594] <sirisian>
Kind of surprised there isn't a simple way to throw at the next await kind of language design that could be made for that. I have a few cancellable systems where there's stuff like await Promise.race([cancelPromise, workPromise]); multiple lines.

[20:54:01.0994] <pokute>
You could do it with generators.

[20:55:49.0280] <pokute>
But it's very cumbersome.

[20:56:16.0126] <sirisian>
Consume the generator unless the cancel flag is set kind of thing and in the worker just yield all the work?

[20:57:02.0346] <sirisian>
Not a bad idea. I could see that being kind of elegant in some of my code. I think it was written before async generators.

[20:57:36.0933] <pokute>
Yeah. redux-saga is one pretty well known example of that.

[21:00:49.0648] <pokute>
I really liked redux-saga at one point. I tried to use it in everything non-simple. Now I removed it from my own hobby project.

[21:01:28.0655] <pokute>
Now I write mega-reducers. :-)

[21:02:50.0815] <pokute>
Well, I'm in the process of removing most of the complex sagas.

[09:27:42.0035] <Richard Gibson>
> Tracing through the full machinery would take me a while, but I can at least confirm that there should not be a difference between simple and non-simple arguments lists in this case, so V8 is definitely wrong _somewhere_, and it seems quite likely to be wrong in the cases where it differs from other implementations

@bakkot it looks to me like _nobody_ is following the spec here but V8 comes closest. Absent overlap between VarDeclaredNames and parameter names, FunctionDeclarationInstantiation steps 27 and 28 (the former when any parameter has an initializer, the latter otherwise) should both create a binding for each variable and initialize it to `undefined`‚Äîeven if that variable is named "arguments".

[09:41:40.0245] <shu>
that does not sound like a thing i want to implement

[10:01:17.0864] <Richard Gibson>
my primary concern on this is alignment between spec and implementations, and resolution by changing the former to match the latter seems expedient

[10:29:18.0713] <bakkot>
Richard Gibson: step 22.f:
```
Let parameterBindings be the list-concatenation of parameterNames and ¬´ "arguments" ¬ª.
```

step 27:
```
 [...]
 b. Let instantiatedVarNames be a copy of the List parameterBindings.
 c. For each element n of varNames, do
   i. If n is not an element of instantiatedVarNames, then
     1. Append n to instantiatedVarNames.
     2. Perform ! env.CreateMutableBinding(n, false).
     3. Perform ! env.InitializeBinding(n, undefined).
```

[10:29:48.0274] <bakkot>
 * Richard Gibson: step 22.f:
```
Let parameterBindings be the list-concatenation of parameterNames and ¬´ "arguments" ¬ª.
```

step 27:
```
 [...]
 b. Let instantiatedVarNames be a copy of the List parameterBindings.
 c. For each element n of varNames, do
   i. If n is not an element of instantiatedVarNames, then
     1. Append n to instantiatedVarNames.
     2. Perform ! env.CreateMutableBinding(n, false).
     3. Perform ! env.InitializeBinding(n, undefined).
```

[10:30:09.0613] <bakkot>
so no, step 27 should not create/initialize the `arguments` binding, to my reading

[10:31:35.0807] <bakkot>
step 28 works a little differently but has the same practical effect for the purposes of the code in question

[10:32:02.0339] <Richard Gibson>
/me sighs with relief


2022-03-06
[18:33:04.0550] <devsnek>
i kinda want a `new DataView(ArrayBufferView)` shortcut for `new DataView(view.buffer, view.byteOffset, view.byteLength)`

[18:37:07.0819] <Jack Works>
We have ArrayBufferView in the language? 

[18:37:42.0632] <Jack Works>
* We have ArrayBufferView in the language? 

[21:11:43.0636] <yodacode>
hello! I'm new to the tc39 proposal system, but I just wanted to ask if anyone would find a syntax feature like this useful:
instead of using `foo = foo.bar`, just using `foo = .bar` or `foo .= bar`. this just came to my mind since I use things like `array = array.map` and `array = array.filter` a lot.

[22:10:29.0632] <Jack Works>
is `foo = foo.bar` common enough to add syntax for it?

[22:11:06.0529] <Jack Works>
in my daily programming I barely write that (maybe because I'm using TypeScript and mostly it doesn't pass the type check)

[01:03:04.0362] <Ashley Claymore>
> <@yodacode:matrix.org> hello! I'm new to the tc39 proposal system, but I just wanted to ask if anyone would find a syntax feature like this useful:
> instead of using `foo = foo.bar`, just using `foo = .bar` or `foo .= bar`. this just came to my mind since I use things like `array = array.map` and `array = array.filter` a lot.

There is a thread here https://es.discourse.group/t/operator/586

[01:03:55.0291] <Ashley Claymore>
* > <@yodacode:matrix.org> hello! I'm new to the tc39 proposal system, but I just wanted to ask if anyone would find a syntax feature like this useful:
> instead of using `foo = foo.bar`, just using `foo = .bar` or `foo .= bar`. this just came to my mind since I use things like `array = array.map` and `array = array.filter` a lot.

There is a thread here https://es.discourse.group/t/operator/586

[01:07:28.0638] <YodaCode>
interesting, thanks!

[14:01:28.0792] <devsnek>
do any engines optimize queue-like array usage?

[15:14:26.0794] <Ashley Claymore>
This post seems to suggest they do/did: https://esdiscuss.org/topic/queue-feature-request#content-3

[15:14:45.0216] <Ashley Claymore>
> ‚ÄúIn WebKit the array implementation switches to an amortized constant time deque if you use push/pop/shift/unshift in anger.‚Äù

[15:14:58.0550] <Ashley Claymore>
* > ‚ÄúIn WebKit the array implementation switches to an amortized constant time deque if you use push/pop/shift/unshift in anger.‚Äù

[15:17:15.0668] <devsnek>
intresting


2022-03-08
[06:25:12.0989] <Jack Works>
https://dev.to/smpnjn/future-javascript-shadowrealms-20mg

[06:25:28.0425] <Jack Works>
I read this article and I think there are some wrong statements....

[06:26:02.0679] <Jack Works>
(or is Realm proposal updated again?? let me check that)

[06:27:42.0425] <Jack Works>
```js
let myRealm = new ShadowRealm();

const { runFunction, testFunction, createFunction } = await myRealm.importValue('./function-script.js');

let fileAnalysis = runFunction();
```

[06:28:08.0455] <Jack Works>
this article wrote this, but this actually not work ü§î

[06:34:30.0787] <Jack Works>
https://github.com/tc39/proposal-shadowrealm/issues/350

[08:34:45.0304] <Mathieu Hofman>
That article completely glosses over the callable boundary, and the fact only primitives and "functions" can be used through ShadowRealm 

[09:01:40.0825] <shu>
i... wouldn't put too much weight on content farm articles

[12:18:56.0230] <Domenic>
To me, dev.to will always be on the wrong side of the great DigitalOcean spamfest of 2020... https://blog.domenic.me/hacktoberfest/

[12:19:10.0752] <Domenic>
 * To me, dev.to will always be on the wrong side of the great DigitalOcean spamfest of 2020... https://blog.domenic.me/hacktoberfest/


2022-03-09
[17:38:51.0117] <Jack Works>
oh... I though dev.to is a new blogger for programmers. And how people misunderstand the API also give us information about how to improve it

[17:39:02.0530] <Jack Works>
> <@shuyuguo:matrix.org> i... wouldn't put too much weight on content farm articles

 * oh... I though dev.to is a new blogger for programmers. And how people misunderstand the API also give us information about how to improve it

[20:19:12.0429] <devsnek>
dev.to makes me very sad. so much useful content pushed out of the way for incorrect clickbait articles.

[00:07:26.0465] <sideshowbarker>
If anybody has a few minutes to do a technical review of https://github.com/mdn/content/pull/13681 that‚Äôd be great
‚Ä¶as far as whether it‚Äôs a useful addition to the docs, and accurate

[00:07:53.0620] <sideshowbarker>
comments welcome here or there

[00:19:11.0803] <nicolo-ribaudo>
I'd rather just say "the sort implementation can vary among engines, so there is no guarantee about the order array elements are compared or how many times `compareFn` is called"

[00:21:10.0310] <nicolo-ribaudo>
I find mentioning the array length to be confusing, since in the general case sort algorithms are expected to be O(n*log(n)) or O(n¬≤) (regardless of what JS engines do)

[00:21:29.0531] <nicolo-ribaudo>
* I find mentioning the array length to be confusing, since in the general case sort algorithms are expected to be O(n*log(n)) or O(n¬≤) (regardless of what JS engines do)

[00:36:20.0959] <sideshowbarker>
nicolo-ribaudo: thanks

[11:26:13.0961] <devsnek>
so uh

[11:26:15.0440] <devsnek>
https://devblogs.microsoft.com/typescript/a-proposal-for-type-syntax-in-javascript/

[11:27:10.0754] <devsnek>
i will be very sad if we put type syntax in the language and it doesn't have some sort of reflection capability like python

[11:28:25.0643] <bakkot>
I would not regard this as "putting type syntax in the language"

[11:28:32.0662] <bakkot>
it's just adding a dozen new, weird comment forms

[11:28:45.0550] <bakkot>
personally I am inclined to regard the existing comment forms as adequate

[11:29:07.0092] <devsnek>
yeah calling them comment forms is what makes me sad

[11:30:42.0096] <devsnek>
i mean they don't need to be evaluated, python just gives you strings of them

[11:32:32.0480] <bakkot>
I can't say I've ever used python's type reflection

[11:32:39.0077] <bakkot>
or, for that kind of types

[11:32:44.0448] <devsnek>
it enables some very cool stuff

[11:32:44.0805] <bakkot>
what is the thing you use it for?

[11:33:15.0387] <devsnek>
for example, `@server.route('/foo') fn get_foo(body: T)`

[11:33:25.0953] <devsnek>
 * for example, `@server.route('/foo') fn get_foo(body: T)`

[11:33:34.0699] <devsnek>
server can automatically validate the body against T

[11:34:42.0617] <devsnek>
another example i think is very cool is discord.py, which allows you to specify how discord bot commands are parsed, like `def ban_user(user: User)`

[11:36:01.0058] <shu>
i don't think i'd be supportive of having reflection capabilities here

[11:36:46.0240] <shu>
the implementation complexity and runtime costs would be too high -- i can only imagine some kind of reparsing when reflection is actually required, there's no way it'd be acceptable to parse it and actually keep the info around

[11:36:47.0943] <devsnek>
i really wish we could combine the usefulness of python with the expressiveness of js

[11:37:26.0164] <devsnek>
> <@shuyuguo:matrix.org> the implementation complexity and runtime costs would be too high -- i can only imagine some kind of reparsing when reflection is actually required, there's no way it'd be acceptable to parse it and actually keep the info around

i think all impls already support lazy parsing for errors, so really it would just be doing a getter of a symbol or something i think.

[11:40:18.0182] <devsnek>
basically exactly like how Error.prototype.stack is a lazy property in v8

[11:43:45.0347] <shu>
i'm not claiming impossibility, just undesirability

[13:05:31.0862] <ljharb>
> <@devsnek:matrix.org> basically exactly like how Error.prototype.stack is a lazy property in v8

fwiw unless v8 is willing to make it work eagerly, like everyone else, i doubt we'd be able to standardize stacks

[13:06:11.0995] <ljharb>
(but the stacks proposal isn't anywhere near close enough to advancing for that to be a discussion point yet)

[13:06:23.0604] <devsnek>
wdym eagerly?

[13:06:56.0729] <devsnek>
like generate a stack trace string on new Error() instead of when the .stack property is accessed?

[13:07:03.0765] <ljharb>
correct

[13:07:13.0469] <devsnek>
i mean it should be invisible to js code

[13:07:27.0863] <ljharb>
true, if it can be unobservably optimized then obv the proposal/spec wouldn't care :-)

[13:08:36.0712] <devsnek>
i guess its (error instance).stack instead of on the prototype but

[13:09:05.0142] <devsnek>
its not a js getter so that should be fine

[13:09:09.0907] <devsnek>
its engine magic

[13:10:11.0808] <ljharb>
the proposal would make it an internal slot, observable via a normative-optional getter on the prototype (_not_ an own property), and also via a static method or two on Error. so it def could be lazily generated as long as the contents matched "as if" they were eagerly generated

[13:10:36.0589] <ljharb>
 * the proposal would make it an internal slot, observable via a normative-optional getter on the prototype (_not_ an own property), and also via a static method or two on Error. so it def could be lazily generated as long as the contents matched "as if" they were eagerly generated


2022-03-10
[16:53:08.0224] <Jack Works>
I like TypeScript, but I don't think that type comment proposal is a good idea...

[16:53:44.0515] <Jack Works>
the goal of that proposal, "make devs no need to transpile code" cannot be really achieved by this approach

[16:54:48.0545] <Jack Works>
for example, TS 4.7 has a new syntax, instantiation expression like this:

```js
const numberSet = Set<number>;
const set = new numberSet(); // type: Set<number>
```

