2023-11-01
[18:00:02.0504] <snek>
i think torque could support suspend points natively with a desugaring

[18:00:27.0639] <snek>
this was one of the things i had in mind when i originally suggested the builtin async functions/generators

[18:40:29.0736] <shu>
by all means, i'd love someone to implement it

[18:40:40.0476] <shu>
 * by all means, i'd love for someone to implement it

[23:30:07.0012] <Ashley Claymore>
If anyone wants to give feedback ahead of the 'state of JS' survey: https://github.com/Devographics/surveys/issues/224 

[02:13:41.0650] <yulia>
How long has test262.report been down for? are there plans to bring it back up?

[03:54:00.0400] <nicolo-ribaudo>
test262.fyi :)

[03:55:17.0593] <yulia>
Aaaahhh

[08:47:06.0769] <bakkot>
base64 proposal is updated to remove streaming, fill out spec text, and settle outstanding questions about the API: https://github.com/tc39/proposal-arraybuffer-base64

see playground for overview and a polyfill in the console: https://tc39.es/proposal-arraybuffer-base64/

other than removing streaming, the most significant change is that the base64 decoder is now permissive by default (ignores whitespace, does not require padding), with a `strict: true` options bag argument which makes it strict (does not allow whitespace, enforces padding)

would appreciate eyes on it, and especially if anyone wants to volunteer to review before the November plenary so I can ask for stage 3 (assuming Peter no longer objects); otherwise I'll be asking in January

[09:09:19.0031] <ljharb>
I’ll volunteer to review


2023-11-02
[10:39:25.0273] <nicolo-ribaudo>
Now that we have dates & time zones for the next meetings, could we add them to the calendar?

[10:39:26.0580] <nicolo-ribaudo>
(or I can do it by myself but I don't know how to add events to the calendar)

[14:18:56.0001] <ljharb>
i'll make sure they're on there


2023-11-07
[23:04:55.0799] <bakkot>
openai announced a new Whisper model, but still no streaming support :(

all the services which offer real-time transcription, including those which just wrap whisper with some hacks, are basically garbage relative to whisper. google has a new model (Chirp) this year, but it doesn't work with real-time transcription either.

whisper gets near-perfect transcriptions for content like our meetings, everyone else misses one word in five. but using whisper without any of the streaming hacks (which lower quality a lot) means transcriptions will necessarily be 30 seconds behind (+ time to transcribe and network latency, so in practice more like 40 seconds).

I don't think automatic transcription is going to be viable until something in this landscape changes. (cc littledan)

I might set up a separate 40-second-latency transcription notes doc at the next meeting to help with fixing things the human transcriptionists miss.

anyone happen to have played with any other promising real-time transcription services recently?

[03:03:37.0883] <littledan>
> <@bakkot:matrix.org> openai announced a new Whisper model, but still no streaming support :(
> 
> all the services which offer real-time transcription, including those which just wrap whisper with some hacks, are basically garbage relative to whisper. google has a new model (Chirp) this year, but it doesn't work with real-time transcription either.
> 
> whisper gets near-perfect transcriptions for content like our meetings, everyone else misses one word in five. but using whisper without any of the streaming hacks (which lower quality a lot) means transcriptions will necessarily be 30 seconds behind (+ time to transcribe and network latency, so in practice more like 40 seconds).
> 
> I don't think automatic transcription is going to be viable until something in this landscape changes. (cc littledan)
> 
> I might set up a separate 40-second-latency transcription notes doc at the next meeting to help with fixing things the human transcriptionists miss.
> 
> anyone happen to have played with any other promising real-time transcription services recently?

saminahusain: 

[03:04:04.0429] <littledan>
Thanks for the report, bakkot . Let's check up on this again at the end of next year.

[03:04:16.0687] <littledan>
sounds like we need to repeat the budget request for transcriptionists

[03:04:33.0931] <littledan>
Are you saying we get good accuracy with a 40-second delay?

[03:04:58.0007] <ryzokuken>
it would be accurate, yeah IIUC

[03:05:17.0188] <ryzokuken>
the 40 second delay is whisper's only shortcoming

[03:06:32.0966] <ryzokuken>
actually, I haven't tried it myself. Wonder how well it does with various accents

[03:07:44.0331] <ryzokuken>
they have an example with a pretty thick accent though, fun

[03:07:45.0834] <ryzokuken>
https://openai.com/research/whisper

[07:11:54.0820] <bakkot>
right. Whisper is very accurate in my tests, but it fundamentally operates on 30-second chunks of audio and takes a little while to run (say 10 seconds per chunk), so trying to stream it to the notes doc would mean that every 30 seconds we get a high-quality transcript of the portion of the meeting starting 40 seconds ago and running through 10 seconds ago. I haven't actually set that up but I expect it to work.

[07:12:19.0097] <bakkot>
unfortunately 40 seconds of lag is a lot of lag

[07:25:11.0927] <Michael Ficarra>
> I might set up a separate 40-second-latency transcription notes doc at the next meeting to help with fixing things the human transcriptionists miss.

That would be *so* helpful!

[07:45:46.0531] <Michael Ficarra>
bakkot: What will this cost per meeting? Even if it's only like $10, we should lump in that funding with the transcription costs.

[07:47:22.0958] <bakkot>
for actual Whisper it'll be free; it runs locally

[07:49:09.0748] <bakkot>
I could maybe cut a few seconds of lag off by using the API which would cost ~$6/meeting (somehow the API manages to be substantially faster than running locally), but the difference between 35 seconds and 40 seconds probably isn't worth worrying about

[10:11:18.0457] <shu>
if the model is in fact pretty much perfect in terms of accuracy, why not record the meeting and postprocess for transcription? then delete the recording afterwards

[10:12:33.0097] <Michael Ficarra>
shu: some people like to edit the notes immediately after speaking

[10:12:56.0149] <shu>
but is that because the accuracy is in doubt?

[10:13:36.0028] <Michael Ficarra>
I think some people make minor rephrasings, remove stumbles, etc

[10:13:57.0511] <shu>
fair enough

[10:22:25.0010] <Michael Ficarra>
personally, if the transcription is very accurate, I would be fine waiting until the end of the day (or week) to do my reviews

[10:23:31.0363] <Michael Ficarra>
but having the two docs sounds like a great compromise

[10:25:05.0324] <Michael Ficarra>
the worst part about reviewing notes for me is when the notes are either incomprehensible (our previous automatic transcription) or missing entire sentences (human transcription) and I can't remember what was said

[10:25:27.0737] <Michael Ficarra>
having a more accurate document to refer to would be so helpful for that

[10:38:32.0085] <bakkot>
the transcripts are also missing paragraph breaks and speaker assignments, and you really want to do those in real time

[10:40:03.0578] <bakkot>
 * the computer-generated transcripts are also missing paragraph breaks and speaker assignments, and you really want to do those in real time

[11:02:35.0177] <Ashley Claymore>
Another thing that we try and edit in live are when people post code snippets into TCQ or matrix. As the verbatim transcription of only the audio without the code can be almost meaningless 

[11:40:43.0124] <Michael Ficarra>
oh yeah, speaker attribution is actually pretty tricky to do after the fact

[12:29:30.0025] <Ashley Claymore>
Simply get everyone to commit to saying their acronym at the start of each sentence 

[12:29:56.0361] <Ashley Claymore>
😅


2023-11-09
[11:34:40.0186] <shu>
rbuckton: `using` declarations are supposed to be early errors at script toplevels, right? is the TS playground allowing that incorrectly?

[11:47:45.0787] <rbuckton>
Yes, it should be an early error. The playground is wrong. 

[12:04:29.0255] <shu>
thanks for confirming

[12:08:13.0820] <rbuckton>
IIRC we should report an error in that case, but I'm not sure what settings the playground uses offhand. If you send me a playground link, I'll try to look at it tomorrow as I'm traveling today


2023-11-10
[16:35:06.0286] <Michael Ficarra>
Feature-Sensitive Coverage for Conformance Testing of Programming Language Implementations: https://dl.acm.org/doi/pdf/10.1145/3591240

[16:35:16.0977] <Michael Ficarra>
> We extend JEST, the state-of-the-art JavaScript conformance test synthesizer using coverage-guided mutational fuzzing, with various FS and FCPS coverage criteria. For the latest JavaScript language specification (ES13, 2022), our tool automatically synthesizes 237,981 conformance tests in 50 hours with five coverage criteria. We evaluated the conformance of eight mainstream JavaScript implementations (four engines and four transpilers) with the synthesized conformance tests and discovered bugs in all of them. The tool detected 143 distinct conformance bugs (42 in engines and 101 in transpilers), 85 of which were confirmed by the developers and 83 of which were newly discovered bugs.


2023-11-11
[08:56:01.0380] <Mathieu Hofman>
> <@bakkot:matrix.org> the computer-generated transcripts are also missing paragraph breaks and speaker assignments, and you really want to do those in real time

We just need another AI to merge the human annotated transcript with the recording.

[09:05:29.0394] <bakkot>
I have actually seriously considered hooking up a special-purpose speaker diarization model; that's definitely a thing

[09:06:32.0754] <bakkot>
but the whole system is a bit of a mess already


2023-11-13
[09:21:50.0269] <Rob Palmer>
The Interest Survey for the 100th TC39 meeting in February in San Diego is posted 🎉 

-  https://github.com/tc39/Reflector/issues/512

Please add yourself by Tuesday 21st November.

[09:23:53.0218] <shu>
is there more info on where in SD?

[09:24:07.0888] <shu>
ah it's on the top of the sheet, thanks

[09:32:58.0216] <Rob Palmer>
I am intrigued as to whether the precise part of SD makes a difference to your choice.

[09:36:48.0497] <shu>
if timezone is not inconvenient to be remote, i personally do not want to go somewhere where either i'll have to rent a car or take taxis everyday to get to the venue, or have to stay, like, near some office park outside of the city

[09:38:56.0105] <Rob Palmer>
ah I see

[10:45:25.0271] <Michael Ficarra>
Same, bike share or walkability is super important for me. I will not rent a car, and would prefer not to take 5-minute Ubers multiple times a day. SD doesn't appear to have a bike share program, so I may end up trying out those electric scooters for the first time.

[10:47:20.0211] <ptomato>
how navigable is San Diego without a car in general? never been there

[10:59:04.0516] <shu>
> <@michaelficarra:matrix.org> Same, bike share or walkability is super important for me. I will not rent a car, and would prefer not to take 5-minute Ubers multiple times a day. SD doesn't appear to have a bike share program, so I may end up trying out those electric scooters for the first time.

yeah i say "rent a car" in the general sense, i will also not rent a car

[11:07:03.0514] <ljharb>
i don't mind ubers but scooters/walkability is a huge plus

[11:07:08.0969] <ljharb>
 * i don't mind ubers but scooters/walkability is a huge plus. def not renting a car

[12:42:19.0125] <Rob Palmer>
Let's see if we can coordinate on hotels to maximise lift-sharing.

[12:57:26.0258] <ethanarrowood>
San Diego is real nice. it’s more spread out than SF so depending on hotel<->venue location scooters may not be feasible


2023-11-14
[17:00:03.0117] <rkirsling>
interesting

[17:00:46.0495] <rkirsling>
I assumed rent-a-car would be unavoidable for SD but if multiple people are opposed it'd be sweet to find another solution

[17:00:52.0494] <rkirsling>
I too don't enjoy driving

[11:05:42.0782] <snek>
can only member companies host

[11:06:33.0583] <Chris de Almeida>
> <@devsnek:matrix.org> can only member companies host

no

[11:09:36.0580] <Chris de Almeida>
https://github.com/tc39/how-we-work/blob/main/host.md

[11:11:31.0917] <snek>
neat

[13:00:14.0835] <bakkot>
man, "give me all of the own enumerable string + symbol keys of this object" is a _surprisingly_ annoying task for something I want to do pretty often

[13:01:53.0008] <bakkot>
```
let desc = Object.getOwnPropertyDescriptors(obj);
return [...Object.getOwnPropertyNames(desc), ...Object.getOwnPropertySymbols(desc)]
  .filter(x => desc[x].enumerable);
```
is the best I've got

[13:02:54.0564] <bakkot>
do you figure we could add get away with making `Object.keys`/`entries` take a options bag argument like `{ symbols: true }`

[13:05:07.0271] <bakkot>
alternative I guess is a `Object.symbolKeys` / `Object.symbolEntries` so you could at least do `[...Object.keys(x), ...Object.symbolKeys(x)]`

[13:10:11.0499] <ljharb>
`Reflect.ownKeys` doesn't do it?

[13:10:18.0109] <ljharb>
 * `Reflect.ownKeys` + a filter doesn't do it?

[13:10:52.0770] <ljharb>
(also why would you use gOPN if you want only enumerable? that's what keys already gives you)

[13:22:48.0439] <littledan>
wasn't that sort of the point, that symbols are supposed to be pseudo-private so it should be annoying to reflect over them?

[13:22:49.0060] <Michael Ficarra>
ljharb: keys is strings only

[13:23:11.0224] <littledan>
or was that just a compat decision?

[13:23:21.0599] <Michael Ficarra>
```

[13:23:38.0671] <Michael Ficarra>
 *   let keys = Object.entries(Object.getOwnPropertyDescriptors(input))
    .filter(([, desc]) => desc.enumerable)
    .map(([k]) => k);

[13:23:57.0352] <Michael Ficarra>
 * ```
let keys = Object.entries(Object.getOwnPropertyDescriptors(input))
    .filter((\[, desc\]) => desc.enumerable)
    .map((\[k\]) => k);

[13:24:12.0270] <Michael Ficarra>
 * ```
let keys = Object.entries(Object.getOwnPropertyDescriptors(input))
    .filter(([, desc]) => desc.enumerable)
    .map(([k]) => k);
```

[14:16:05.0568] <bakkot>
> <@ljharb:matrix.org> `Reflect.ownKeys` + a filter doesn't do it?

that's `Reflect.ownKeys` an improvement on using `getOwnPropertyNames` + `getOwnPropertySymbols`, sure

[14:16:18.0697] <bakkot>
> <@ljharb:matrix.org> `Reflect.ownKeys` + a filter doesn't do it?

 * ah, `Reflect.ownKeys` is an improvement on using `getOwnPropertyNames` + `getOwnPropertySymbols`, sure

[14:16:39.0167] <bakkot>
> <@ljharb:matrix.org> (also why would you use gOPN if you want only enumerable? that's what keys already gives you)

keys doesn't include symbols, is the reason

[14:16:47.0435] <bakkot>
> <@ljharb:matrix.org> (also why would you use gOPN if you want only enumerable? that's what keys already gives you)

 * `Object.keys` doesn't include symbols, is the reason

[14:16:48.0037] <ljharb>
> <@michaelficarra:matrix.org> ljharb: keys is strings only

Object.keys is Object.getOwnPropertyNames, but only enumerables

[14:17:05.0153] <ljharb>
> <@bakkot:matrix.org> `Object.keys` doesn't include symbols, is the reason

right but you're using getOwnPropertySymbols for the symbols. gOPN's only use is if you want non-enumerable strings, which you don't

[14:17:24.0037] <bakkot>
sure, yes, that does end up being equivalent here

[15:16:52.0556] <Richard Gibson>
https://github.com/endojs/endo/blob/master/packages/pass-style/doc/copyRecord-guarantees.md#how-do-i-enumerate-thee-let-me-list-the-ways


2023-11-15
[08:19:41.0747] <Mathieu Hofman>
Yeah I was going to suggest `Reflect.ownKeys({...obj})`

[08:22:48.0615] <Mathieu Hofman>
 * Yeah I was going to suggest `Reflect.ownKeys({...obj})` but only if you don't mind accessors being triggered

[08:32:28.0617] <ljharb>
why do you need the spread (which is what triggers the accessors)?

[08:51:40.0746] <bakkot>
presumably to get only the enumerable properties

[13:03:13.0918] <ptomato>
let's say I wanted to rebase and resuscitate https://github.com/tc39/ecma262/pull/1498 - should I try to get access to push to that branch, or start a new PR?

[13:32:45.0054] <Chris de Almeida>
> <@pchimento:igalia.com> let's say I wanted to rebase and resuscitate https://github.com/tc39/ecma262/pull/1498 - should I try to get access to push to that branch, or start a new PR?

I'm guessing you'd rather not have to fork and submit PRs to that branch from your fork?

[13:36:34.0876] <ptomato>
I could do that as well, but since the PR has become quite different by rebasing it on latest main, that might well be more complicated

[13:36:43.0460] <Chris de Almeida>
ah I didn't notice it was only one commit

[13:41:41.0651] <Chris de Almeida>
perhaps I am missing something but isn't the rebase the same regardless of whether you have write access to the repo?

[13:51:47.0847] <ptomato>
I mean, once I've rebased, would you ("you" meaning anyone with an interest in this PR) prefer that I figure out how to push the result up to the same PR, so that the previous discussions can resume uninterrupted? or is it better to open a new PR and say it supersedes the old PR?

[13:56:50.0529] <Chris de Almeida>
the extra step is just you'd be pushing to a branch on your fork and creating a PR to merge that branch to the PR branch

I defer to the editors on this, as they are the ones with 1. write access to the repo and 2. can decide what they prefer re: previous discussions vs new PR

[13:57:10.0205] <Chris de Almeida>
 * the extra step is just you'd be pushing to a branch on your fork and creating a PR to merge that branch to the PR branch

I defer to the editors on this, as they are the ones with 1. write access to the repo and would be the ones to merge your PR and 2. can decide what they prefer re: previous discussions vs new PR

[13:57:40.0327] <Chris de Almeida>
 * the extra step is just you'd be pushing to a branch on your fork and creating a PR to merge that branch to the PR branch

I defer to the editors on this, as they are the folks with 1. write access to the repo and would be the folks to merge your PR and 2. can decide what they prefer re: previous discussions on existing PR vs closing in favor of new PR

[13:58:03.0913] <Chris de Almeida>
 * the extra step is just you'd be pushing to a branch on your fork and creating a new PR to merge your fork branch to the existing PR branch

I defer to the editors on this, as they are the folks with 1. write access to the repo and would be the folks to merge your PR and 2. can decide what they prefer re: previous discussions on existing PR vs closing in favor of new PR

[14:24:58.0431] <Michael Ficarra>
I'm fine either way. A new PR would be less noisy, but it would be a shame to not ping the current thread participants about an update/replacement PR.


2023-11-16
[00:17:16.0573] <Rob Palmer>
A reminder:  The Interest Survey for the 100th TC39 meeting in February in San Diego is posted 🎉

- https://github.com/tc39/Reflector/issues/512

Please add yourself by Tuesday 21st November.

[08:44:32.0442] <eemeli>
For those interested, I'm putting together an incubator call for the Stable Formatting proposal. See here for an agenda and a Doodle poll for figuring out the date & time: https://github.com/tc39/Reflector/issues/513

[14:24:02.0029] <bakkot>
from jmdyck:

```
Function(
  'a = console.log("oh"',
  '"no")',
  ''
)()
```

[14:25:36.0699] <bakkot>
this is very dumb, though I don't think it's an actual problem for anyone (in particular SES implements the spec as written, i.e., join with a comma and then validate as parameters)

[14:26:42.0581] <ptomato>
isn't that disallowed as described in the note in step 18 of https://tc39.es/ecma262/#sec-createdynamicfunction?

[14:27:24.0731] <ptomato>
oh, I guess the parameters as a whole are validated, not each parameter individually

[14:27:44.0831] <ptomato>
"oh no" indeed

[14:28:00.0957] <bakkot>
yup

[14:28:26.0114] <bakkot>
and people do rely on the ability to do `Function('a, b', 'body')` - combining multiple parameters into one argument, rather than putting each into their own argument


2023-11-17
[13:28:56.0963] <Chris de Almeida>
upcoming plenary on the calendar was mistakenly extended for 2 hours per day.  it has been corrected


2023-11-18
[07:55:56.0293] <Jack Works>
hello, is there any syntax pro? I'm stuck on designing cover grammar

[07:58:07.0854] <Jack Works>
Grammar:

```
MatchStatement: `match` [nLTh] `(` Expression `) [nLTh] `{ MatchStatementClauses `;` `}`
```

This is ambiguous with ExpressionStatement, therefore I need a CoverExpressionStatementAndMatchStatement grammar

[07:58:32.0718] <Jack Works>
 * Grammar:

```
MatchStatement: `match` [nLTh] `(` Expression `) [nLTh] `{ MatchStatementClauses `;` `}`
```

This is ambiguous with ExpressionStatement (cannot decide `match (expr)` until see `{` or any other token), therefore I need a CoverExpressionStatementAndMatchStatement grammar

[07:58:40.0540] <Jack Works>
 * Grammar:

```
MatchStatement: `match` [nLTh] `(` Expression `) [nLTh] `{ MatchStatementClauses `;` `}`
```

This is ambiguous with ExpressionStatement (cannot decide production for `match (expr)` until see `{` or any other token), therefore I need a CoverExpressionStatementAndMatchStatement grammar

[08:00:48.0809] <Jack Works>
Now I have this cover grammar:

```
CoverExpressionStatementAndMatchStatement :
    match [no LineTerminator here] Arguments 
```

This can cover the match head `match (a, b, c)` (where `,` is comma operator) and a call expression `match (a, b, c)` (where `,` is parameter separator). But I don't know how to use it in ExpressionStatement

[08:01:50.0684] <Jack Works>
```
MatchStatement :
    CoverExpressionStatementAndMatchStatement [no LineTerminator here] `{ ` MatchStatementClauses `;` `}`
```

This looks good to me for now

[08:03:39.0384] <Jack Works>
```
ExpressionStatement[Yield, Await] :
        CoverExpressionStatementAndMatchStatement
        (current definition)
```

This one does not. It does not cover everything that can follow a CallExpression, like `match (expr) + 1` or `match(expr).prop`.

[08:05:05.0982] <Jack Works>
It looks like I need to add all expressions to this cover grammar (e.g. it can follow a `++` or `.x` or `[prop]` or `(...args`)) which is unrealistic.

[08:05:55.0873] <Jack Works>
 * Now I have this cover grammar:

```
CoverExpressionStatementAndMatchStatement :
    `match` [no LineTerminator here] Arguments 
```

This can cover the match head `match (a, b, c)` (where `,` is comma operator) and a call expression `match (a, b, c)` (where `,` is parameter separator). But I don't know how to use it in ExpressionStatement

[08:06:08.0019] <Jack Works>
 * ```
ExpressionStatement :
        CoverExpressionStatementAndMatchStatement
        (current definition)
```

This one does not. It does not cover everything that can follow a CallExpression, like `match (expr) + 1` or `match(expr).prop`.

[08:06:56.0624] <Jack Works>
 * Now I have this cover grammar:

```
CoverExpressionStatementAndMatchStatement :
    `match` [no LineTerminator here] Arguments

// Refined to this in MatchStatement
MatchHead :
    `match` `(` Expression `)`
```

This can cover the match head `match (a, b, c)` (where `,` is comma operator) and a call expression `match (a, b, c)` (where `,` is parameter separator). But I don't know how to use it in ExpressionStatement

[08:07:05.0208] <Jack Works>
 * Now I have this cover grammar:

```
CoverExpressionStatementAndMatchStatement :
    `match` [no LineTerminator here] Arguments
```

This can cover the match head `match (a, b, c)` (where `,` is comma operator) and a call expression `match (a, b, c)` (where `,` is parameter separator). But I don't know how to use it in ExpressionStatement

[08:07:38.0314] <Jack Works>
 * ```
MatchStatement :
    CoverExpressionStatementAndMatchStatement [no LineTerminator here] `{ ` MatchStatementClauses `;` `}`

// Refined to this in MatchStatement
MatchHead :
    `match` [no LineTerminator here] `(` Expression `)` [no LineTerminator here] `{ ` MatchStatementClauses `;` `}`
```

This looks good to me for now

[08:07:53.0205] <Jack Works>
 * ```
MatchStatement :
    CoverExpressionStatementAndMatchStatement [no LineTerminator here] `{ ` MatchStatementClauses `;` `}`

// Refined to
MatchHead :
    `match` [no LineTerminator here] `(` Expression `)` [no LineTerminator here] `{ ` MatchStatementClauses `;` `}`
```

This looks good to me for now

[12:15:29.0445] <Richard Gibson>
Jack Works: for that approach, I think you'll want to use and rename (and probably generalize) [|CoverCallExpressionAndAsyncArrowHead|](https://tc39.es/ecma262/multipage/ecmascript-language-functions-and-classes.html#prod-CoverCallExpressionAndAsyncArrowHead), e.g.
```
<emu-grammar type="definition">
  MatchStatement : 
    CoverCallExpressionAndAsyncArrowHeadAndMatchHead [no LineTerminator here] `{` MatchStatementClauses `;` `}`
</emu-grammar>
<h2>Supplemental Syntax</h2>
<p>
  When processing an instance of the production<br>
  <emu-grammar>MatchStatement : CoverCallExpressionAndAsyncArrowHeadAndMatchHead [no LineTerminator here] `{` MatchStatementClauses `;` `}`</emu-grammar><br>
  the interpretation of |CoverCallExpressionAndAsyncArrowHeadAndMatchHead| is refined using the following grammar:
</p>
<emu-grammar type="definition">
  MatchHead :
    `match` [no LineTerminator here] `(` Expression `)
</emu-grammar>
```

[12:17:42.0165] <Richard Gibson>
 * Jack Works: for that approach, I think you'll want to use and rename (and probably generalize) [|CoverCallExpressionAndAsyncArrowHead|](https://tc39.es/ecma262/multipage/ecmascript-language-functions-and-classes.html#prod-CoverCallExpressionAndAsyncArrowHead), e.g.

```
<emu-grammar type="definition">
  MatchStatement : 
    CoverCallExpressionAndAsyncArrowHeadAndMatchHead [no LineTerminator here] `{` MatchStatementClauses `;` `}`
</emu-grammar>
<h2>Supplemental Syntax</h2>
<p>
  When processing an instance of the production<br>
  <emu-grammar>MatchStatement : CoverCallExpressionAndAsyncArrowHeadAndMatchHead [no LineTerminator here] `{` MatchStatementClauses `;` `}`</emu-grammar><br>
  the interpretation of |CoverCallExpressionAndAsyncArrowHeadAndMatchHead| is refined using the following grammar:
</p>
<emu-grammar type="definition">
  MatchHead :
    `match` [no LineTerminator here] `(` Expression `)
</emu-grammar>
```
(following the pattern in [Async Arrow Function Definitions](https://tc39.es/ecma262/multipage/ecmascript-language-functions-and-classes.html#sec-async-arrow-function-definitions))


2023-11-19
[18:15:42.0813] <Jack Works>
Yes, I'm already doing that, just unsure if I'm doing it correctly


2023-11-20
[07:57:56.0727] <Rob Palmer>
A final reminder: The Interest Survey for the 100th TC39 meeting in February in San Diego is posted 🎉

- https://github.com/tc39/Reflector/issues/512

Please add yourself by Tuesday 21st November.


2023-11-25
[22:20:18.0487] <bakkot>
bugfix in set methods, for anyone who is implementing; cc shu https://github.com/tc39/proposal-set-methods/pull/102


2023-11-26
[12:01:05.0309] <nicolo-ribaudo>
Is there a draft schedule for tomorrow?

[15:29:28.0910] <Chris de Almeida>
> <@nicolo-ribaudo:matrix.org> Is there a draft schedule for tomorrow?

yes -- please see the reflector issue for the meeting, 3rd line 


2023-11-27
[01:23:03.0680] <sffc>
Hey Jesse I took a look at how other programming languages handle decimal normalization since both those things are subjects of your slide deck. I may have a conflict during the scheduled time for that discussion; I'll try to call in, but you already know my position on the issue of normalization.
https://github.com/tc39/proposal-decimal/issues/89

[01:29:50.0364] <Jesse>
thanks, that's a great contribution! Right, many other languages do support trailing zeros. I appreciate the suggestion to see how the "middle ground" suggestion. I'll continue the discussion in the GitHub issue.

[01:30:04.0166] <littledan>
Do we have a draft schedule yet?

[07:01:41.0966] <Chris de Almeida>
we have a packed agenda, so please be mindful (as well as forgiving if the chairs seem pushy as we approach or exceed timeboxes 🙂)

[07:04:41.0783] <Chris de Almeida>
 Ben and Michael Ficarra have topics that are currently in overflow, but we hope to be able to slot those in where possible, so please be on the lookout for messages from chairs

as usual, similar goes for everyone presenting, as we will try to move things forward if time allows, while still respecting constraints

[07:05:05.0950] <littledan>
amazing how the agenda always fills up despite looking empty shortly before the deadline

[08:03:51.0773] <Chris de Almeida>
> <@softwarechris:matrix.org> Ben and Michael Ficarra have topics that are currently in overflow, but we hope to be able to slot those in where possible, so please be on the lookout for messages from chairs
> 
> as usual, similar goes for everyone presenting, as we will try to move things forward if time allows, while still respecting constraints

Ben: due to a timebox change, your topic is out of overflow and is now scheduled on Day 4

[08:04:04.0864] <Ben>
Thanks for letting me know!

[08:54:08.0952] <Chris de Almeida>
both overflow topics are now on the schedule on Day 4

[09:31:47.0576] <nicolo-ribaudo>
Thanks chairs for adding "END DAY X" and "LUNCH" to TCQ :)

[10:01:27.0279] <rbuckton>
Hmm. I may also be unavailable in April for the same reason, though I believe we have a hotel so I may be able to dial in.

[10:09:39.0616] <littledan>
Note: Ashley and Ben volunteer for notes all the time; it'd be great to have additional note-takers to relieve them

[10:11:52.0349] <ljharb>
also the Meet apps don't have an "incognito mode"

[10:20:59.0783] <Ben>
> <@littledan:matrix.org> Note: Ashley and Ben volunteer for notes all the time; it'd be great to have additional note-takers to relieve them

I'll also have to step out for ~20 minutes after the 402 editor's update

[10:22:47.0313] <Michael Ficarra>
chairs, can we ask Samina to add a link to these slides to the agenda?

[10:23:00.0136] <Rob Palmer>
yes, that will happen

[10:24:06.0381] <littledan>
Note, "New Proposal?" is, WinterCG is looking for a place to publish standards, and I'm proposing Ecma. https://github.com/wintercg/admin/issues/58

[10:24:43.0314] <littledan>
This could be a good way to enable TC39 collaboration with efforts on server-side JS runtimes

[10:26:45.0637] <ljharb>
(please don't use AI for any image designs for legal reasons)

[10:26:57.0087] <snek>
and aesthetic reasons

[10:28:05.0756] <rbuckton>
Here's the other cap design we've used

[10:28:23.0924] <ljharb>
there's a beanie too

[10:29:04.0983] <saminahusain>
rbuckton: both look good.

[10:29:33.0143] <saminahusain>
What would be good to recognize 100th

[10:30:31.0664] <ljharb>
i grab more socks at conference booths than hats or shirts these days :-) but also a windbreaker/jacket would be awesome

[10:31:44.0812] <shu>
> <@ljharb:matrix.org> (please don't use AI for any image designs for legal reasons)

wait why? i used AI for the old hat logos

[10:33:09.0419] <Jesse>
are we going more in the baseball hat direction, or rather trucker-style?

[10:33:13.0163] <ljharb>
> <@shuyuguo:matrix.org> wait why? i used AI for the old hat logos

the old hats were created long before LLMs were commonplace, so i'm not sure what you mean - unless you think i meant adobe illustrator?

[10:33:23.0176] <shu>
yes, i have AI at home, Adobe Illustrator

[10:33:42.0699] <ljharb>
this isn't TDZ :-p

[10:33:42.0905] <ethanarrowood>
> <@jesse:igalia.com> are we going more in the baseball hat direction, or rather trucker-style?

trucker please for us big headed folk 

[10:34:04.0607] <shu>
> <@jesse:igalia.com> are we going more in the baseball hat direction, or rather trucker-style?

the last run we had 3 styles: trucker, "dad cap", and beanie

[10:34:16.0078] <rbuckton>
> <@jesse:igalia.com> are we going more in the baseball hat direction, or rather trucker-style?

Hopefully a choice? I have a strong preference for the baseball cap style from a comfort perspective

[10:34:59.0805] <snek>
should probably make a channel for hats

[10:35:12.0924] <ryzokuken 🇮🇹>
or a reflector thread?

[10:35:16.0560] <ljharb>
Jack Works: just installed it, this is awesome thanks

[10:35:19.0078] <saminahusain>
I think 3 styles would be fine. Should I plan for these threetrucker, "dad cap", and beanie

[10:35:39.0036] <saminahusain>
Yes, please a channel for hats would be great.

[10:35:40.0172] <snek>
is this a LSP, can i run it in my vim

[10:35:51.0252] <Michael Ficarra>
oooh this will be super handy

[10:36:29.0814] <Chris de Almeida>
#tc39-swag:matrix.org 

[10:36:44.0436] <rbuckton>
This is what I wanted my extension to do, but I haven't had the time to work on it in a long while. This looks great.

[10:36:46.0930] <Jesse>
new channel? this is a full-service channel

[10:36:54.0304] <Jesse>
 * new channel? this is a full-service channel!

[10:36:56.0452] <bakkot>
> <@devsnek:matrix.org> is this a LSP, can i run it in my vim

apparently yes!

[10:37:12.0979] <snek>
> <@softwarechris:matrix.org> #tc39-swag:matrix.org

room isn't in the category 

[10:37:16.0171] <snek>
oh wait now it is

[10:37:24.0118] <Chris de Almeida>
so impatient

[10:37:48.0729] <Jack Works>
https://marketplace.visualstudio.com/items?itemName=MagicWorks.ecmarkup

[10:40:21.0877] <Jack Works>
> <@devsnek:matrix.org> is this a LSP, can i run it in my vim

the VSCode extension is made of TMLanguage (syntax highlight JSON), snippets (JSON), language definition (JSON) and a language server (provides hover information and completion)

[10:40:46.0538] <Jack Works>
I believe you can take the tmlanguage, that will highly improve the editing experience

[10:41:03.0331] <Jack Works>
 * I believe you can take the tmlanguage (https://github.com/Jack-Works/ecmarkup-language-service/tree/main/extension-vscode/syntaxes), that will highly improve the editing experience

[10:44:00.0477] <Jack Works>
Now all LSP features are based on @tc39/ecma262-biblio and simple string analysis, no real analyze (using ecmarkup/grammarkdown in the backend) support, but I plan to add them. For example I want to make goto definition work for local-defined grammar/AOs

[10:46:48.0515] <Jack Works>
I tried to do real analyze last year, but having some problem with bundling those two libs, and they are not built in an incremental way so the performance is not good. I hope I can have time to improve or reimplement part of them to provide better experience

[10:52:38.0340] <bakkot>
https://github.com/tc39/faq/pull/2

[10:52:45.0969] <bakkot>
^ PR documenting how to resolve disagreements

[10:55:56.0159] <rbuckton>
> <@jackworks:matrix.org> Now all LSP features are based on @tc39/ecma262-biblio and simple string analysis, no real analyze (using ecmarkup/grammarkdown in the backend) support, but I plan to add them. For example I want to make goto definition work for local-defined grammar/AOs

Grammarkdown has ways to reference other grammars, but doesn't itself parse a full ecmarkup file. I'd love for ecmarkup to generate a grammarkdown `.grammar` file that is included in ecma262-biblio to make that process easier.

[10:56:51.0636] <littledan>
even if the disclaimer is read and understood, it might not be believed as credible

[10:57:11.0250] <bakkot>
wonder if it might be better to attribute answers to specific delegates? maybe that would be believed?

[10:58:45.0024] <bakkot>
rbuckton: I have an issue for putting the grammar in the biblio https://github.com/tc39/ecmarkup/issues/431 but I either did not know or forgot that grammarkdown had a specific format it used

[10:59:05.0594] <littledan>
> <@bakkot:matrix.org> wonder if it might be better to attribute answers to specific delegates? maybe that would be believed?

I don't think so either? The community might view each of us (or, worse, just some of us) as authoritative.

[10:59:05.0626] <bakkot>
anyway definitely agreed it would be nice for the biblio to hold the grammar

[10:59:31.0083] <bakkot>
> <@littledan:matrix.org> I don't think so either? The community might view each of us (or, worse, just some of us) as authoritative.

that's fair but if people attribute quotes to "a TC39 delegate" instead of "TC39" that would at least be an improvement

[10:59:46.0502] <bakkot>
I don't know if they would, though

[11:00:10.0295] <littledan>
I dunno, it feels like some alleged weasel wording that people at each level would just filter out unless they feel forced to repeat it

[11:00:25.0687] <bakkot>
fair

[11:00:39.0464] <Jack Works>
by the way can you bakkot  add a `.d.ts` for the biblio package?
https://github.com/Jack-Works/ecmarkup-language-service/blob/main/language-server/src/biblio.d.ts

It should be something like index.d.json.ts as I know how TS NodeNext should work

[11:00:56.0168] <littledan>
to be clear I like the idea of having a disclaimer--we don't want to let people lawyer their way through to something by citing the FAQ

[11:00:58.0725] <Jack Works>
 * by the way, can you bakkot add a `.d.ts` for the Biblio package?
https://github.com/Jack-Works/ecmarkup-language-service/blob/main/language-server/src/biblio.d.ts

It should be something like `index.d.json.ts` as I know how TS NodeNext should work

[11:01:28.0414] <bakkot>
Jack Works: can do; open an issue? (or a PR)

[11:05:26.0349] <ljharb>
https://github.com/tc39/proposal-array-grouping/issues/60

[11:11:54.0148] <littledan>
Great work from @legendecas on the V8 implementation 

[11:13:58.0742] <littledan>
What is the current plan for which globals will be included

[11:14:12.0445] <littledan>
(Sorry I cannot access the queue right now)

[11:15:23.0498] <Chris de Almeida>
added to tcq queue

[11:18:25.0558] <littledan>
Great to see this moving forward 

[11:18:29.0012] <littledan>
Thanks Leo!

[11:23:26.0514] <leobalter>
[Slides](https://docs.google.com/presentation/d/17esbBbAlKe1nZzWx47ItpVP1XovIupxKEAL1PgUDFrk/edit#slide=id.g26255f6e788_0_0) added to the TC39 Agenda (I just opened the PR: https://github.com/tc39/agendas/pull/1506

[11:24:39.0008] <leobalter>
> <@littledan:matrix.org> What is the current plan for which globals will be included

Thanks for the feedback (cc syg ). I'll focus on that in the next plenary.

[11:28:51.0498] <littledan>
If someone wants to pick up Array.isTemplateTag, it would be a great complement to this proposal, together with trusted types

[11:30:08.0521] <littledan>
Please keep going ptomato

[11:30:13.0448] <littledan>
We heard you well

[11:30:48.0292] <ljharb>
nicolo-ribaudo: that's a case for Function tho, not necessarily `eval`

[11:31:14.0117] <bakkot>
if you can't hear, reload

[11:31:23.0690] <bakkot>
I have run into this bug with google meet before

[11:31:32.0064] <bakkot>
where it drops the audio feed from a specific person

[11:31:43.0976] <nicolo-ribaudo>
If somebody can ask Philip to screen share yb himself I'll reload and fix my audio

[11:32:04.0613] <nicolo-ribaudo>
> <@nicolo-ribaudo:matrix.org> If somebody can ask Philip to screen share yb himself I'll reload and fix my audio

Robert Pamely: 

[11:39:40.0588] <littledan>
I don’t think what Jordan is saying is aligned with the goals around CSP

[11:40:06.0812] <shu>
i don't think "only direct eval is a problem" is a widely shared web security opinion afaik

[11:40:16.0200] <ljharb>
it very much might not be aligned with CSP's goals, i'm not sure what those are

[11:40:24.0237] <littledan>
It would probably be good to say that for the notes 

[11:40:26.0892] <snek>
jordan i don't quite understand like

[11:40:36.0647] <snek>
i mean i understand your want of Function()

[11:40:49.0611] <snek>
but i don't understand how you can distinguish it from eval in any meaningful way

[11:40:57.0063] <ljharb>
i just mean i'm personally concerned when i see use of `eval()` but not `Function()`

[11:41:07.0423] <ljharb>
i mean, they're different code paths

[11:41:15.0556] <ljharb>
and `eval` even has special stuff for direct vs indirect

[11:42:23.0474] <littledan>
Maybe in the future you could be more clear about your goals and that you aren’t talking about the goals of CSP itself

[11:43:13.0572] <littledan>
I agree that direct eval is a terrible extra level of bad but I also like the guarantees of unsafe-eval

[11:43:41.0360] <littledan>
Note that csp also disallows things like inline event handlers, which also don’t see local scope

[11:43:50.0513] <ljharb>
i'm not sure why it's on me to clarify that my goals aren't the goals of others when i'm not claiming to be speaking for the goals of others.

[11:43:52.0892] <bakkot>
I am definitely concerned when I see `Function`, and you should be too

[11:44:00.0857] <ljharb>
CSP blocks lots of things

[11:44:08.0736] <ljharb>
> <@bakkot:matrix.org> I am definitely concerned when I see `Function`, and you should be too

i'd love to understand more about those concerns

[11:45:36.0562] <bakkot>
you have to be really careful to audit that either a) no user-control code ends up in the call to `Function()` or b) the result is never invoked, and that is very hard to do in a large web application

[11:46:06.0845] <bakkot>
of course if the argument is static it's fine, which is the point of this proposal

[11:46:13.0272] <ljharb>
fair enough

[11:46:18.0186] <bakkot>
 * you have to be really careful to audit that either a) no user-controled code ends up in the call to `Function()` or b) the result is never invoked, and that is very hard to do in a large web application

[11:46:36.0553] <ljharb>
i still wouldn't want `eval()` in my codebase even with a static string tho, and i'd be fine with having that with Function

[11:47:12.0306] <bakkot>
fine not to want `eval` with a static string, but that's not a security issue, I would think? more of a linter concern, not something that needs to be banned in the browser

[11:48:21.0656] <ljharb>
fair enough

[11:48:23.0745] <ljharb>
 * fair enough as well

[11:56:13.0362] <Michael Ficarra>
CSP also fails at composition

[12:05:31.0521] <littledan>
> <@michaelficarra:matrix.org> CSP also fails at composition

What do you mean by this?

[12:13:22.0919] <bakkot>
littledan: there are some cases where policy A enables one behavior, and policy B enables a second, but no combination of policies can enable both behaviors (other than not using CSP at all)

[12:13:59.0543] <littledan>
Do you have an example?

[12:14:18.0559] <bakkot>
IIRC `unsafe-inline` plus nonces

[12:14:42.0569] <littledan>
Wow weird, how is that prohibited?

[12:14:59.0278] <bakkot>
mm, maybe I am thinking of `unsafe-inline` plus `strict-dynamic` actually?

[12:15:19.0118] <bakkot>
ah, no, both of those

[12:15:23.0229] <bakkot>
here: https://www.w3.org/TR/CSP3/#allow-all-inline

[12:15:29.0128] <bakkot>
see step 2.1

[12:15:52.0464] <bakkot>
it just explicitly checks for nonce sources when determining whether `unsafe-inline` can be used

[12:16:22.0606] <littledan>
So that might be fixable?

[12:16:25.0731] <bakkot>
nonce sources, hash sources, and strict-dynamic

[12:16:41.0019] <bakkot>
yeah, presumably; on the other hand it was presumably done on purpose

[12:58:25.0104] <bakkot>
(also changing it without introducing a new directive would potentially weaken the security posture of existing pages, which would maybe be bad.)

[13:24:49.0111] <rbuckton>
I'm still generally a fan of an API like:
```js
let bytesRead = Uint8Array.encodeBase64(input, inputPos, output, outputPos, count);
```
and you use `count - bytesRead` to determine how much data is yet to be encoded

[13:26:24.0388] <bakkot>
rbuckton: that doesn't give you streaming, unfortunately

[13:26:26.0882] <rbuckton>
it gives the developer more control over buffer sizes for memory-constrained environments, avoids excess allocations, and is consistent with a lot of similar C++ APIs

[13:26:32.0614] <rbuckton>
That specifically gives you streaming.

[13:26:43.0117] <bakkot>
even accounting for the fact that you need to skip over whitespace?

[13:26:53.0244] <bakkot>
whitespace is the thing that has tripped me up here

[13:31:56.0199] <rbuckton>
> <@bakkot:matrix.org> even accounting for the fact that you need to skip over whitespace?

Fair point, I suppose. In .NET, the streaming API requires state so it has its own class like `TextEncoder` (https://learn.microsoft.com/en-us/dotnet/api/system.security.cryptography.tobase64transform?view=net-8.0)

[13:38:25.0086] <rbuckton>
Possibly feasible by splitting the API into two methods, one that normalizes base64 input (removes whitespace, etc.), and one that does the decoding, but it's certainly not as convenient.

[13:38:52.0525] <Michael Ficarra>
I think engines should work on just not making the allocation when it's immediately destructured

[13:38:54.0087] <nicolo-ribaudo>
The whole point of all this discussion is to avoid two passes

[13:39:32.0499] <nicolo-ribaudo>
 * The reason for this discussion is to avoid two passes

[13:39:40.0728] <nicolo-ribaudo>
Since that's what the proposal was blocked on

[13:42:45.0171] <shu>
it's unclear if that pays off in the general case

[13:42:59.0768] <shu>
whereas the # of web APIs that have *that* level of performance requirements is very small

[13:43:04.0591] <shu>
and we can probably just design those specially

[13:43:43.0529] <rbuckton>
It would be nice to be able to have multiple return values without depending on destructuring. That's one of the things my as-yet-not-presented `ref` proposal would provide:

```
let bytesRead;
let bytesWritten = Uint8Array.encodeBase64(input, inputPos, inputLen, output, outputPos. ref bytesRead);
```

[13:44:02.0448] <rbuckton>
 * It would be nice to be able to have multiple return values without depending on destructuring. That's one of the things my as-yet-not-presented `ref` proposal would provide:

```
let bytesRead;
let bytesWritten = Uint8Array.encodeBase64(input, inputPos, inputLen, output, outputPos, ref bytesRead);
```

[13:44:51.0852] <rbuckton>
 * It would be nice to be able to have multiple return/output values without depending on destructuring. That's one of the things my as-yet-not-presented `ref` proposal would provide:

```
let bytesRead;
let bytesWritten = Uint8Array.encodeBase64(input, inputPos, inputLen, output, outputPos, ref bytesRead);
```

[13:49:58.0435] <Luca Casonato>
Thanks for seeing this one through bakkot 

[13:51:16.0600] <bakkot>
don't jinx it!

[13:56:23.0768] <Michael Ficarra>
okay `toFixed` exists though

[14:06:57.0856] <littledan>
Objective C/Swift also has its own ad-hoc kind of decimal that no one seems to mind

[14:19:39.0889] <littledan>
Sorry for jumping in; will stop

[14:22:04.0038] <littledan>
But, I would kinda appreciate it if Waldemar could just make his point rather than quizzing the presenter

[14:22:06.0198] <Michael Ficarra>
IEEE is normalising though, right?

[14:22:29.0054] <littledan>
No, IEEE explicitly does represent trailing zeroes

[14:22:59.0181] <littledan>
So, normalizing would be sort of subsetting IEEE, just like we are also sort of subsetting by not including a bunch of signaling modes

[14:23:26.0128] <rbuckton>
I'm not sure this Q&A approach is constructive 

[14:34:28.0234] <shu>
i am losing the thread of discussion here wrt decimal

[14:37:16.0631] <shu>
i am not hearing an argument for why this should be part of the data model, just that having it in the data model gives you extra bits of info...?

[14:41:51.0646] <littledan>
Yes there are three libraries by MikeMcl, and the design here is better

[14:42:36.0485] <littledan>
But they aren’t adopted broadly enough, and people try to avoid using them with strings or fixed point number usage 

[14:43:19.0276] <ljharb>
those usages would still apply with a non-primitive builtin tho, no?

[14:43:24.0682] <ljharb>
 * those usages (that people want to avoid) would still apply with a non-primitive builtin tho, no?

[14:43:43.0535] <littledan>
Sorry what is the connection to primitiveness?

[14:44:03.0945] <ljharb>
i guess it's less about it being a primitive and more about operator overloading - syntax support

[14:44:25.0946] <ljharb>
if i can't write `1.23m` or the equivalent, then i wouldn't think anything we could add would be ergonomic enough to warrant using it

[14:44:33.0526] <ljharb>
 * if i can't write `1.23m * 3m` or the equivalent, then i wouldn't think anything we could add would be ergonomic enough to warrant using it

[14:44:49.0329] <hax (HE Shi-Jun)>
I guess people avoid using them  because they don't want introduce a heavy lib?

[14:44:58.0867] <ljharb>
iow the java-style API on the slide isn't something i'd want to see us add, nor would i want to see used in a codebase i had to maintain

[14:45:26.0193] <ljharb>
 * iow the java-style API on the slide isn't something i'd want to see us add, nor would i want to see used in a codebase i had to maintain. numbers are too fundamental for a `.add()` to be reasonable imo

[14:45:56.0913] <ljharb>
 * iow the java-style API on the slide isn't something i'd want to see us add, nor would i want to see used in a codebase i had to maintain. numbers are too fundamental for a `.add()` to be reasonable or elegant enough to use, imo

[14:47:09.0221] <ljharb>
the argument does apply that it's a coordination point, but we had a single dominant userland library already for temporal to replace Date, and we had a decade or more of usage to validate the need, and the variety of use cases it supports

[14:47:21.0853] <shu>
sidebar: i want to resist coming to some black and white conclusions here like "batteries included is always a bad rationale" or "tc39 shouldn't try to solve any coordination problems"

[14:47:37.0284] <shu>
these all end up being case-by-case in the end

[14:47:45.0070] <hax (HE Shi-Jun)>
I also hope we can have decimal literal and op overloading but it could be a separate problem. People could use transpilers if they really want.

[14:48:18.0270] <eemeli>
Ashley Claymore: You mentioned a YAML library that came with its own "decimal" type. Was that a real-world example?

[14:49:05.0276] <shu>
why doesn't bloomberg make a library?

[14:49:28.0680] <shu>
it could put its engineering weight behind something that's fast and maintainable and evangelize that

[14:49:29.0946] <hax (HE Shi-Jun)>
> <@eemeli:mozilla.org> Ashley Claymore: You mentioned a YAML library that came with its own "decimal" type. Was that a real-world example?

which yaml lib?

[14:49:52.0737] <ljharb>
> <@shuyuguo:matrix.org> it could put its engineering weight behind something that's fast and maintainable and evangelize that

imo that would build a much stronger case for a builtin decimal that lacks syntactic support

[14:50:24.0072] <rbuckton>
One of the best reasons to have a built-in decimal, IMO, was to be able to implement it as a primitive value with operators. The worst part of Decimal in Java is that it's method based.

[14:55:41.0123] <rbuckton>
shu: IIRC, you said in a previous plenary that the effort to add bigint outweighed its benefits for the language, given that the predominant use of bigint so far is cryptocurrency mining. Would that be an accurate characterization? Would higher-precision calculates in Sheets not be enough of a motivator for V8 to consider implementing this as a primitive? Are there runtime optimizations/performance benefits of syntactic decimal math vs method-based math that are worth considering?

[14:56:25.0926] <shu>
bad ROI on BigInts is an accurate characterization

[14:56:35.0734] <rbuckton>
 * shu: IIRC, you said in a previous plenary that the effort to add bigint outweighed its benefits for the language, given that the predominant use of bigint so far is cryptocurrency mining. Would that be an accurate characterization? Would higher-precision calculations in Sheets not be enough of a motivator for V8 to consider implementing this as a primitive? Are there runtime optimizations/performance benefits of syntactic decimal math vs method-based math that are worth considering?

[14:56:48.0235] <shu>
higher-precision calculations in Sheets may be a motivator for me if it's Sheets making the feature request, but it's not?

[14:56:52.0570] <shu>
like, look at Excel

[14:57:12.0375] <shu>
Excel also uses IEEE floating point, and it truncates

[14:57:44.0618] <snek>
we use bigints in discord a lot :)

[14:57:55.0143] <shu>
i'm saying, if you want this to be motivated by a product, the product needs to speak up

[14:58:06.0687] <shu>
gesturing at possible adoption is not compelling in itself

[14:58:10.0177] <rbuckton>
Do you use them for actual math, or as a standin for a numeric string.

[14:58:24.0092] <rbuckton>
 * Do you use them for actual math, or as a standin for a numeric string?

[14:58:24.0412] <snek>
we do bitwise math on them

[14:58:49.0149] <bakkot>
I have used a bigint as a bitset once I think

[14:58:58.0868] <shu>
that says we should've added Bitset :)

[14:59:04.0544] <shu>
more than that BigInt was the right call

[14:59:35.0620] <Ashley Claymore>
> <@eemeli:mozilla.org> Ashley Claymore: You mentioned a YAML library that came with its own "decimal" type. Was that a real-world example?

nope sorry, I was trying to turn internal Bloomberg things into more generic terms on the fly. YAML here stands for internal xml based APIs coming from other systems

[14:59:39.0692] <snek>
the only non-bitset operation we do on them can also be done on f64

[14:59:53.0272] <rbuckton>
> <@devsnek:matrix.org> we do bitwise math on them

IMO, the two main use cases for bigint that *aren't* crypto are nanosecond precision and 64-bit integer flags/bitmasks, neither of which needed an arbitrarily-sized integer value.

[14:59:55.0497] <snek>
 * the only non-bitset operation we do on them can also be done on f64 (shifting right 22 bits)

[15:00:34.0836] <bakkot>
(my bitset was > 64 bits fwiw)

[15:01:05.0115] <eemeli>
> <@aclaymore:matrix.org> nope sorry, I was trying to turn internal Bloomberg things into more generic terms on the fly. YAML here stands for internal xml based APIs coming from other systems

Ah, got it. That's what I thought, but wanted to check. For context, I maintain the `yaml` package on npm and was not aware of such a JS YAML library.

[15:01:51.0898] <littledan>
Note that Jesse has been working on a good library here, having a full JS implementation of the proposal

[15:02:01.0054] <shu>
FYI all i will not be able to attend for the next 3 days, Rezvan will be attending on V8's behalf

[15:02:27.0267] <bakkot>
who else was taking notes? I have a question for other note takers. Ashley Claymore ?

[15:03:21.0474] <rbuckton>
My last question still stands: Could native, syntactic decimal math outperform any given userland library? And if so, by how much?

[15:03:43.0848] <rbuckton>
 * My last question still stands: Could native, syntactic decimal math outperform any given userland library? And if so, by how much (approximately)?

[15:05:05.0159] <littledan>
I think moving towards engaging products is a good direction for TC39. It isn’t something we have done in the past—product discussions have often been treated as out of scope and implicitly discouraged. Ashley described a real product need that we have at Bloomberg, and we can work with survey respondents to more fully develop more of them.

[15:08:46.0337] <rbuckton>
> <@littledan:matrix.org> I think moving towards engaging products is a good direction for TC39. It isn’t something we have done in the past—product discussions have often been treated as out of scope and implicitly discouraged. Ashley described a real product need that we have at Bloomberg, and we can work with survey respondents to more fully develop more of them.

I've never heard of such a practice being discouraged, and if it is that seems unfortunate. IIRC, a number of proposals are driven by the needs of large projects. ShadowRealm, WeakRef, Shared Structs, Async Context, etc. are all driven by such a need, I think.

[15:09:30.0986] <littledan>
> <@rbuckton:matrix.org> IMO, the two main use cases for bigint that *aren't* crypto are nanosecond precision and 64-bit integer flags/bitmasks, neither of which needed an arbitrarily-sized integer value.

We did discuss BigInt vs Int64 at some length while developing things. Int64 introduces quite some additional unfortunate complexity/arbitrary design decisions. And from an implementation standpoint, my understanding was that the difficult part was adding a primitive, not the contents of whether it was big or not

[15:09:57.0474] <rbuckton>
I have seen cases where feedback from these projects has been discounted and ignored, however.

[15:10:31.0922] <littledan>
> <@rbuckton:matrix.org> I've never heard of such a practice being discouraged, and if it is that seems unfortunate. IIRC, a number of proposals are driven by the needs of large projects. ShadowRealm, WeakRef, Shared Structs, Async Context, etc. are all driven by such a need, I think.

No one is explicitly discouraging it, but we also aren’t seeing lots of examples of product-driven presentations. This is why I said it was *implicitly* discouraged.

[15:14:05.0666] <rbuckton>
> <@littledan:matrix.org> We did discuss BigInt vs Int64 at some length while developing things. Int64 introduces quite some additional unfortunate complexity/arbitrary design decisions. And from an implementation standpoint, my understanding was that the difficult part was adding a primitive, not the contents of whether it was big or not

It's unfortunate that the introduction of bigint didn't pave the way for implementations to become more flexible in terms of adding new primitives. IIRC, BigNumber/Decimal/etc. was being discussed at the same time as BigInt, so the potential was already present.

[15:15:09.0416] <rbuckton>
And BigInt followed on the heels of Symbol

[15:16:13.0709] <rbuckton>
IMO, both Decimal and Temporal should be primitive, as they both involve operations that could be better expressed syntactically (`+`, `/`, `>`, `<`, etc.)

[15:17:26.0685] <rbuckton>
 * IMO, both Decimal and Temporal should be primitive, as they both involve operations that could be better expressed syntactically (`+`, `-`, `>`, `<`, etc.)

[15:20:46.0097] <ljharb>
also Records and Tuples

[15:20:51.0314] <rbuckton>
Though, I have to admit I'm biased, having many years of using .NET, where `Decimal` and `DateTimeOffset`/`TimeSpan` have syntactic operators (`DateTimeOffset.Now + TimeSpan.FromMinutes(5)`)

[15:20:57.0056] <ljharb>
 * also Records and Tuples and shared structs

[15:24:10.0627] <rbuckton>
Or rather:
```
// C#
DateTimeOffset.Now <= start + TimeSpan.FromMinutes(5)

// vs

// JS/Temporal
Temporal.Instant.compare(Temporal.Now.instant(), start.add(Temporal.Duration.from({ minutes: 5 })) <= 0
```

[15:24:34.0833] <rbuckton>
 * Or rather:

```
// C#
DateTimeOffset.Now <= start + TimeSpan.FromMinutes(5)

// vs

// JS/Temporal
Temporal.Instant.compare(Temporal.Now.instant(), start.add({ minutes: 5 }) <= 0
```

[15:25:04.0690] <Chris de Almeida>
> <@bakkot:matrix.org> who else was taking notes? I have a question for other note takers. Ashley Claymore ?

yes

[15:25:08.0034] <rbuckton>
 * Or rather:

```
// C#
DateTimeOffset.Now > start + TimeSpan.FromMinutes(5)

// vs

// JS/Temporal
Temporal.Instant.compare(Temporal.Now.instant(), start.add({ minutes: 5 }) > 0
```

[15:26:15.0798] <rbuckton>
 * Or rather:

```js
// C#
DateTimeOffset.Now > start + TimeSpan.FromMinutes(5)

// vs

// JS/Temporal
Temporal.Instant.compare(Temporal.Now.instant(), start.add({ minutes: 5 })) > 0
```

[15:31:23.0000] <Rob Palmer>
> <@rbuckton:matrix.org> IMO, both Decimal and Temporal should be primitive, as they both involve operations that could be better expressed syntactically (`+`, `-`, `>`, `<`, etc.)

If this is the ideal, why are we accepting of the non-primitive compromise for Temporal?

[15:32:34.0946] <shu>
because... browsers would not ship the primitive version, like with Decimal?

[15:33:25.0819] <Rob Palmer>
Ok, so we are being pragmatic in order to make progress. Fine by me.

[15:36:26.0640] <rbuckton>
> <@shuyuguo:matrix.org> because... browsers would not ship the primitive version, like with Decimal?

Can you clarify, do you mean "would not support" or "would not ship even if standardized"? 

[15:37:17.0074] <shu>
what is the difference between those two statements?

[15:37:25.0062] <shu>
as in, how did it get standardized, if the browsers do not support it?

[15:37:27.0482] <rbuckton>
That statement seems more definitive than "would not support unless convinced the motivation is sufficient"

[15:37:57.0791] <rbuckton>
"would not ship" has multiple connotations

[15:38:06.0366] <shu>
the general statement is "would not support unless convinced"

[15:38:14.0638] <rbuckton>
Thank you for the clarification

[15:38:24.0491] <shu>
in the specific cases of temporal and decimal, since we have discussed those at length, the answer is "not convinced"

[15:38:38.0259] <shu>
that is, the bar is high

[15:40:35.0618] <shu>
> <@rbuckton:matrix.org> "would not ship" has multiple connotations

okay, right, i'm not supposing a hypothetical where the current TC39 working mode has broken down, and that the browsers continue to do things they've agreed to via the staging process

[15:42:42.0934] <rbuckton>
> <@shuyuguo:matrix.org> okay, right, i'm not supposing a hypothetical where the current TC39 working mode has broken down, and that the browsers continue to do things they've agreed to via the staging process

It still bears clarification. Despite being specified, there are parts of the spec that aren't implemented in all runtimes, like TCO, and things that are normative optional.

[15:43:25.0547] <shu>
ah, i see. well, TCO remains a special case as it predates the current staging process.

[15:43:45.0131] <shu>
but normative optional is interesting

[15:45:04.0843] <shu>
my personal take is i don't think normative optionality is a good idea except in very broad strokes, like "browsers have this for legacy reasons", as we use it today

[15:47:34.0560] <rbuckton>
As well as browsers unshipping SAB and disallowing `Atomics.wait` on the main thread

[15:48:20.0784] <rbuckton>
(both of which are understandable concerns, but are specific to browsers)

[15:49:14.0372] <shu>
yeah i think it's probably actually fine to have some implicit notion of "profiles"

[15:49:29.0695] <shu>
but full-on pick-and-choose normative optionality is harmful imoi

[15:49:34.0052] <shu>
 * but full-on pick-and-choose normative optionality is harmful imo


2023-11-28
[16:00:59.0330] <Chris de Almeida>
🚨 📢  some things have moved around on the schedule.  please have a look, especially if you are presenting as some items have moved to a different day.  no constraints were impacted

[16:26:00.0457] <yulia | PTO until Dec. 8>
I can't believe im missing one of the hats

[16:29:10.0012] <Anthony Bullard>
Getting a new phone and forgetting to install matrix for a month means a lot of catching up to do.

[10:03:25.0859] <rbuckton>
IIRC, it runs on a VM in Azure

[10:11:18.0767] <Michael Ficarra>
I would love to implement some TCQ feature improvements once it's in a developable state

[10:18:29.0949] <bakkot>
why do we put our names in the notes doc? I find it easier to keep delegates.txt open in a different tab where I can c-f for names

[10:20:15.0731] <Chris de Almeida>
> <@bakkot:matrix.org> why do we put our names in the notes doc? I find it easier to keep delegates.txt open in a different tab where I can c-f for names

for helping note-takers is one use case.  we also use it to record attendance -- something Ecma cares about.  it also can be helpful to know who was present at the meeting when reviewing notes, as not everyone speaks at every meeting

[10:20:38.0285] <bakkot>
gotcha

[10:23:35.0378] <eemeli>
Heh, is TCQ stuck again?

[10:23:55.0882] <Rob Palmer>
TCQ advanced

[10:24:08.0839] <eemeli>
 * Heh, is TCQ stuck again? (apparently not)

[10:24:12.0226] <Ashley Claymore>
> <@softwarechris:matrix.org> for helping note-takers is one use case.  we also use it to record attendance -- something Ecma cares about.  it also can be helpful to know who was present at the meeting when reviewing notes, as not everyone speaks at every meeting

It never seems better than 50% accurate tho

[10:44:03.0414] <Ashley Claymore>
42 people on the call.
18 names on the notes. Not sure how many of those missing 24 are observers.

[10:51:11.0554] <Chris de Almeida>
> <@aclaymore:matrix.org> It never seems better than 50% accurate tho

true.  I don't know if this has ever _not_ been the case, and if so, how long ago.  IME it has been voluntary; folks only add themselves and not others

for Ecma's attendance-keeping it is not the only system of record.  the secretary monitors the online meeting participants (and in-person folks), as well as the sign-in form people complete to get the link for the online meeting

I think it's useful to have the complete attendees in the doc itself for the notes/history but it may be that some people don't want to be listed for some reason

[10:52:35.0533] <Chris de Almeida>
maybe some of the two-letter folks can provide further context

[10:57:24.0628] <bakkot>
Prior to remote meetings attendance was kept by having a physical sheet of paper passed around, and I think we used that to populate the list in the published notes

[10:57:37.0015] <bakkot>
I think "no data-driven exceptions" is a confusing way to phrase this principle

[10:58:00.0024] <bakkot>
the principle appears to be "don't reject anything which could in principle be valid", which seems like a totally fine principle

[10:59:56.0141] <Chris de Almeida>
📝 we will need someone to volunteer to help with notes after this item.  please consider helping out 🙏

[11:00:31.0736] <ryzokuken 🇮🇹>
29-02 _is_ valid though, it's the combination that isn't valid

[11:00:36.0498] <ryzokuken 🇮🇹>
 * `29-02` _is_ valid though, it's the combination that isn't valid

[11:01:02.0653] <eemeli>
I think I'm a bit confused by how asking for 2030-02-29 could return 2030-02-28 rather than 2030-03-01.

[11:01:23.0683] <ljharb>
what about `04-31`?

[11:02:10.0729] <ryzokuken 🇮🇹>
> <@ljharb:matrix.org> what about `04-31`?

`31-04` should be invalid because it never occurs in the ISO calendar

[11:02:36.0400] <ljharb>
right but april, and the 31st, are both valid in the same way that february, and the 29th, are both valid

[11:02:46.0868] <ljharb>
or are you saying 2/29 is special because of leap days

[11:02:55.0224] <ryzokuken 🇮🇹>
> <@ljharb:matrix.org> or are you saying 2/29 is special because of leap days

precisely

[11:03:10.0887] <ryzokuken 🇮🇹>
because it is valid but when added to a year it might not be

[11:03:16.0260] <ljharb>
philip's answer of "the shape", tho, would mean that a month 01 - 12 and a day 01 - 31 are all "valid" in that sense

[11:03:26.0720] <Kris Kowal>
(The one person I know with a February 29 birthday celebrates on March 1.)

[11:03:34.0976] <ljharb>
thus april 31st, while obv a day that doesn't exist, each part is still valid

[11:03:44.0215] <ljharb>
 * thus april 31st, while obv a day that doesn't exist, each part is still the right "shape"

[11:03:51.0917] <ljharb>
just like february 29th depending on the year

[11:04:45.0142] <Kris Kowal>
Seems to me the reasonable behaviors are `throw`, `truncate` (to 02-28), and `carry` (to 03-01).

[11:06:13.0231] <eemeli>
```
new Date(2030, 1, 29) → Date Fri Mar 01 2030 00:00:00
```

[11:06:19.0983] <ryzokuken 🇮🇹>
> <@kriskowal:matrix.org> Seems to me the reasonable behaviors are `throw`, `truncate` (to 02-28), and `carry` (to 03-01).

at the moment we support `constrain` and `reject`

[11:06:43.0743] <ryzokuken 🇮🇹>
carrying over is not generally applicable but it could be useful in certain cases as you mentioned

[11:09:56.0807] <eemeli>
I think either `throw` or `carry` can make sense, but `truncate` is _weird_.

[11:14:41.0325] <ryzokuken 🇮🇹>
They cases are well documented in the Temporal docs

[11:14:47.0747] <ryzokuken 🇮🇹>
 * The cases are well documented in the Temporal docs

[11:15:53.0718] <bakkot>
We should have a notion of "consensus pending one person's offline stamp"

[11:16:30.0061] <bakkot>
so that this can get consensus when waldemar has a chance to review this behavior offline and approves of it, assuming that he does

[11:19:17.0544] <ptomato>
> <@eemeli:mozilla.org> I think either `throw` or `carry` can make sense, but `truncate` is _weird_.

we used to have "carry" (it was called `{overflow: 'balance'}`) but removed it during stage 2, based on experience from the Moment maintainers that people only wanted it because it was what `new Date()` does.

[11:19:36.0907] <Chris de Almeida>
> <@bakkot:matrix.org> We should have a notion of "consensus pending one person's offline stamp"

provisional advancement is fairly common, no?

[11:19:56.0519] <bakkot>
yes but usually it's like "editor's review" or something, rarely "someone approving the normative behavior"

[11:20:07.0865] <Kris Kowal>
> <@pchimento:igalia.com> we used to have "carry" (it was called `{overflow: 'balance'}`) but removed it during stage 2, based on experience from the Moment maintainers that people only wanted it because it was what `new Date()` does.

Anecdotally, at least one person uses it for her birthday math.

[11:21:09.0474] <Kris Kowal>
(And I do not have an iron in this fire, just this anecdote.)

[11:21:53.0746] <waldemar>
I'm not withholding consensus. I (and others) just found the information to be too poorly presented to understand.

[11:26:49.0089] <nicolo-ribaudo>
> <@waldemarh:matrix.org> I'm not withholding consensus. I (and others) just found the information to be too poorly presented to understand.

If it helps, this is what I understood happens by default based on the type of methods/conversions
- String->Temporal validates the strings and throws
- Plain object->Temporal validates that each parameter is _individually_ in its potential domain (e.g. days are positive integers, month names specific strings, ...) and then "rounds towards zero" to get a valid date
- Temporal->Temporal rounds towards zero to get a valid date

There is an exception to that Temporal->Temporal class, which is the method today the champions were proposing to change to not throw anymore 

[11:27:18.0919] <nicolo-ribaudo>
* In reply to @waldemarh:matrix.org
I'm not withholding consensus. I (and others) just found the information to be too poorly presented to understand.


If it helps, this is what I understood happens by default based on the type of methods/conversions
String->Temporal validates the strings and throws

- Plain object->Temporal validates that each parameter is individually in its potential domain (e.g. days are positive integers, month names specific strings, ...) and then "rounds towards zero" to get a valid date

- Temporal->Temporal rounds towards zero to get a valid date

There is an exception to that Temporal->Temporal class, which is the method today the champions were proposing to change to not throw anymore


[11:27:43.0071] <nicolo-ribaudo>
> <@waldemarh:matrix.org> I'm not withholding consensus. I (and others) just found the information to be too poorly presented to understand.

 * In reply to @waldemarh:matrix.org
I'm not withholding consensus. I (and others) just found the information to be too poorly presented to understand.

If it helps, this is what I understood happens by default based on the type of methods/conversions
- String->Temporal validates the strings and throws
- Plain object->Temporal validates that each parameter is individually in its potential domain (e.g. days are positive integers, month names specific strings, ...) and then "rounds towards zero" to get a valid date
- Temporal->Temporal rounds towards zero to get a valid date

There is an exception to that Temporal->Temporal class, which is the method today the champions were proposing to change to not throw anymore

[11:27:53.0373] <nicolo-ribaudo>
 * If it helps, this is what I understood happens by default based on the type of methods/conversions

- String->Temporal validates the strings and throws
- Plain object->Temporal validates that each parameter is individually in its potential domain (e.g. days are positive integers, month names specific strings, ...) and then "rounds towards zero" to get a valid date
- Temporal->Temporal rounds towards zero to get a valid date

There is an exception to that Temporal->Temporal class, which is the method today the champions were proposing to change to not throw anymore

[11:28:08.0446] <nicolo-ribaudo>
 * If it helps, this is what I understood happens by default based on the type of methods/conversions

- String->Temporal validates the strings and throws
- Plain object->Temporal validates that each parameter is individually in its potential domain (e.g. days are positive integers, month names some strings, ...) and then "rounds towards zero" to get a valid date
- Temporal->Temporal rounds towards zero to get a valid date

There is an exception to that Temporal->Temporal class, which is the method today the champions were proposing to change to not throw anymore

[11:28:34.0363] <nicolo-ribaudo>
 * If it helps, this is what I understood happens by default based on the type of methods/conversions

- String->Temporal validates the strings and throws
- Plain object->Temporal validates that each parameter is individually in its potential domain (e.g. days are positive integers, which is all we know about days without looking at other parameters) and then "rounds towards zero" to get a valid date
- Temporal->Temporal rounds towards zero to get a valid date

There is an exception to that Temporal->Temporal class, which is the method today the champions were proposing to change to not throw anymore

[11:32:42.0110] <nicolo-ribaudo>
Or maybe "rounds down" and not "rounds towards zero"

[11:33:26.0885] <bakkot>
nicolo-ribaudo: from reading the spec I think the "plain object -> temporal" and "temporal -> temporal" cases were handled the same?

[11:33:38.0683] <bakkot>
could be wrong though, haven't traced through the whole thing

[11:34:36.0078] <nicolo-ribaudo>
Oh probably yes, given that if the input is a temporal object all the properties are already in the valid domain

[11:36:14.0726] <ptomato>
yes, what nicolo-ribaudo said is mostly accurate. for String->Temporal conversions, ISO 8601 is clear on what is and isn't a valid ISO string

[11:36:41.0399] <ptomato>
Plain object->Temporal is indeed basically the same as Temporal->Temporal, but Temporal objects are already valid in the domain

[11:38:42.0051] <ptomato>
Plain object->Temporal and Temporal->Temporal methods - the `overflow: 'constrain'` algorithm is a bit more complicated than rounding down: https://tc39.es/proposal-temporal/#sec-temporal-calendardatetoiso

[11:39:05.0806] <ptomato>
but in the ISO and Gregorian calendars, the only place where this is relevant is February 29

[11:39:56.0373] <ptomato>
 * but in the ISO and Gregorian calendars, the only place where this is relevant is February 29 (if you assume valid data)

[11:40:08.0170] <ptomato>
 * but in the ISO and Gregorian calendars, the only place where this is relevant is February 29 (if you assume valid data, as you would for a Temporal→Temporal conversion)

[11:44:29.0028] <littledan>
We have experience with Intl in checking in tests amid imprecise specifications, using a specific tag to note that case. We could do this for sum (and transcendental fns) if needed

[11:45:13.0537] <ljharb>
users will rely on whatever algorithm browsers select and they won't be able to change it in the future anyways

[11:46:22.0549] <Michael Ficarra>
a PDF of what waldemar linked in TCQ: https://people.eecs.berkeley.edu/~jrs/papers/robustr.pdf

[11:47:45.0908] <littledan>
I think “batteries included” is a decent reason for this, alongside precision—as Kevin said, this just comes up frequently

[11:49:41.0876] <littledan>
Historically, users have come to depend on answers even if the spec doesn’t say so. Eg see transcendental fns

[11:50:17.0737] <snek>
well we did manage to make sorting stable, even though it made lots of people angry

[11:51:42.0016] <Michael Ficarra>
snek: it being not guaranteed to be stable also made lots of people angry

[11:51:55.0291] <snek>
it made me angry

[12:00:36.0963] <snek>
the meeting in san diego is confirmed to be happening right?

[12:02:31.0386] <Chris de Almeida>
yes

[12:04:33.0647] <Anthony Bullard>
Yes, we can’t wait to have everyone on campus snek 

[12:05:05.0869] <snek>
is there a recommended hotel or anything? i recall the building was a little bit far from most stuff 

[12:09:10.0076] <bakkot>
apparently Python's full-precision floating point sum is about 10x slower than a naive summation, and probably about 7x slower than Neumaier

[12:10:11.0373] <bakkot>
but in JS using `.reduce` is probably at least 10x slower than a native Math.sum anyway, so maybe this is fine?

[12:12:23.0980] <snek>
http://blog.zachbjornson.com/2019/08/11/fast-float-summation.html

[12:13:06.0474] <snek>
it seems like with avx512 its *faster* to do the neumaier

[12:13:47.0727] <snek>
if only intel would properly support avx512

[12:15:45.0740] <Chris de Almeida>
> <@devsnek:matrix.org> is there a recommended hotel or anything? i recall the building was a little bit far from most stuff

we are waiting on this information; will share once available

[12:22:40.0674] <Anthony Bullard>
@snek I don’t speak officially on this, but we typically stay at a nice Embassy Suites that’s roughly a 10 minute walk from campus. It across from a large shopping center

[12:23:12.0995] <Anthony Bullard>
I’d be surprised if a different recommendation was made, but it is possible

[12:29:30.0053] <waldemar>
I figured out how to add n IEEE doubles in linear O(n) time and get the correctly rounded exact result in all cases, including avoiding overflow. In practice the running time is similar to Neumaier's but you always get exact results.

[12:31:21.0937] <ljharb>
sounds like that's the algorithm we should specify then?

[12:33:03.0427] <waldemar>
There are many algorithms that can do this. We should not specify one any more than we should specify JS language parsing by describing what data structures the parser uses and what how the parser updates them when it receives the next character of program text.

[12:33:39.0044] <waldemar>
 * There are many algorithms that can do this. We should not specify one any more than we should specify JS language parsing by describing what data structures the parser uses and how the parser updates them when it receives the next character of program text.

[12:34:37.0808] <snek>
horwat's last theorem 

[12:34:50.0286] <snek>
can you post the algorithms you're aware of on the repo?

[12:35:00.0962] <waldemar>
The important thing is that the results are completely deterministic.

[12:35:14.0854] <ljharb>
the reality tho is that if we don't pick an algorithm, browsers will, and it won't ever be changeable

[12:35:33.0462] <ljharb>
certainly if we have an algorithm that can unobservably be replaced then they can do so

[12:36:23.0370] <waldemar>
> <@ljharb:matrix.org> the reality tho is that if we don't pick an algorithm, browsers will, and it won't ever be changeable

Is this claim provable?

[12:37:16.0176] <bakkot>
waldemar: people have started to depend on the precise results of Math.tan and friends, which historically vary across browsers, such that the minority browsers have been updating to match the semantics of the majority ones

[12:37:27.0947] <bakkot>
This may or may not mean that it is not changeable in practice

[12:37:30.0837] <ljharb>
> <@waldemarh:matrix.org> Is this claim provable?

of course not, but it doesn't have to be, because that's already been browsers' experience and feedback

[12:37:32.0114] <waldemar>
The choice of algorithm is unobservable except by side channels like timing

[12:37:57.0042] <bakkot>
of course, if the result is deterministic, then yes the precise choice of algorithm doesn't matter. though Mark Miller wanted us to write down a precise algorithm.

[12:37:57.0891] <ljharb>
the exact results is what's observable

[12:38:21.0975] <bakkot>
Which I don't really want to do because writing down Shewchuk's will be somewhat lengthy.

[12:38:43.0876] <bakkot>
here's Python's, for refernece https://github.com/python/cpython/blob/48dfd74a9db9d4aa9c6f23b4a67b461e5d977173/Modules/mathmodule.c#L1359-L1474

[12:39:07.0868] <waldemar>
The whole point of what I want to do here is to ensure that the result is deterministic by being the exact, correctly rounded answer.

[12:39:16.0284] <bakkot>
Anyway if Mark is OK with not specifying an algorithm I'm quite happy with that.

[12:40:14.0976] <bakkot>
waldemar: Are you OK with nondeterminism in the case of overflow/underflow? Because specifying those exactly will be hard, I think, without specifying a full algorithm.

[12:40:54.0148] <bakkot>
Or overflow at least; not sure about underflow.

[12:42:23.0765] <ljharb>
if the result is deterministic, then what's the problem with specifying an algorithm? it wouldn't be observable to follow it or not as long as you produced the right results

[12:43:41.0852] <bakkot>
it means that implementations probably won't innovate, for one thing

[12:46:02.0726] <bakkot>
Python's fsum throws if the intermediate sum overflows, looks like; e.g. `math.fsum([1.6e308, 1.6e308, -1.6e308, -1.6e308])`. I would not want to throw in this case though I'm not sure what a better option would be.

[12:46:06.0558] <waldemar>
The algorithm I'm thinking of gives the exact, correctly rounded result in all cases. If that final rounding is ±∞ or NaN, then that's what you get. If the rounding produces a finite double, then that's what you get. No nondeterminism in cases of ±∞ or NaN.

[12:46:59.0436] <waldemar>
Python's fsum is buggy when it gets intermediate overflows. But there is a simple way to avoid that.

[12:47:16.0385] <ljharb>
> <@bakkot:matrix.org> it means that implementations probably won't innovate, for one thing

the alternative is that they’ll all probably copy the first shipper, no?

[12:47:47.0602] <bakkot>
waldemar: That sounds like a great option, then, though the paper you linked does not handle intermediate overflow from what I can tell

[12:48:25.0998] <waldemar>
It doesn't, but the way to solve that is so obvious they probably didn't bother with it.

[12:48:32.0025] <snek>
can you produce the algorithm you are thinking of

[12:48:38.0231] <snek>
just to sate my curiosity 

[12:51:48.0569] <waldemar>
1. If you have 0, 1, or 2 inputs, the result is trivial.

[12:52:04.0332] <waldemar>
2. If you have 3 or more inputs, use the approach in the paper to compute an exact sum, represented as (p0+p1+…), where each p_i is a double and their exponents differ by at least 53 binary powers — in practice you'll likely end up with just one or two such p_i. Then round the sum as in fsum, taking care of the round-to-nearest-breaking-ties-to-even case in fsum.

[12:52:54.0043] <waldemar>
3. If you get ±∞ or NaN as any of the inputs, the result is always ±∞ or NaN and you can figure it out directly without doing arithmetic.

[12:55:01.0992] <waldemar>
4. Getting ±∞ as an intermediate result is only an issue if you have later cancellation coming that can bring the result back into a finite range. To take care of that case, always try to add in arguments with the opposite sign from your running total first.

[12:58:29.0331] <ljharb>
presumably -∞ yields -∞, but what does `∞ + -∞` yield?

[12:58:50.0677] <bakkot>
NaN

[12:58:51.0394] <waldemar>
NaN

[12:58:53.0185] <bakkot>
same as normal

