2024-04-04
[07:14:40.0599] <ljharb>
i hope Temporal will be able to support the moon https://www.reuters.com/science/white-house-directs-nasa-create-time-standard-moon-2024-04-02/

[07:17:02.0068] <nicolo-ribaudo>
That is a clear use case for sub-microsecond precision

[07:21:24.0968] <Jesse>
we'll need a v2 of Temporal where we specify the astronomical "home base" object. CLDR will need to be extended with a new catalog of astronomical objects and new lunar time zones. Should be doable!

[07:22:01.0255] <Andreu Botella>
make sure you never end up with a home base inside a black hole

[07:25:47.0132] <Jesse>
maybe this time we can get it right and agree to use timex time (100 second minutes, 100 minute hours) on the moon

[07:30:17.0337] <Jesse>
 * we'll need a v2 of Temporal where we specify the astronomical "home base" object for all operations. CLDR will need to be extended with a new catalog of astronomical objects and new lunar time zones. Should be doable!

[12:23:57.0519] <ptomato>
what I learned from researching the moon standard time in the past couple of days, is that local gravity affects the rate at which atomic clocks tick. Earth's atomic time is the average of several dozen atomic clocks, all with gravitational corrections applied so that they are effectively ticking at mean sea level (even if the clock itself is physically far above sea level)

[12:34:03.0904] <TabAtkins>
Yup, that's relativity for you. Gravity affects the rate time passes.

[12:34:36.0407] <bakkot>
yeah it's not just that it affects the rate at which the clocks tick, it's that it affects the rate at which _everything_ ticks https://en.wikipedia.org/wiki/Gravitational_time_dilation

[12:35:20.0711] <bakkot>
looking forward to Temporal being updated to include a "strength of local gravity" parameter :D

[12:38:07.0627] <ptomato>
right, so I'm a bit skeptical about whether it makes any sense to stretch the definition of POSIX time to incorporate other astronomical bodies

[13:56:02.0800] <Chris de Almeida>
gentle reminder to please add any and all plenary schedule constraints as soon as possible

[14:45:50.0407] <TabAtkins>
> <@bakkot:matrix.org> looking forward to Temporal being updated to include a "strength of local gravity" parameter :D

"velocity relative to timebase station", too

[14:46:24.0570] <bakkot>
if we're doing velocity we need acceleration and jerk and so on as well, so we can properly represent dates in the future

[14:46:37.0262] <bakkot>
really just a full PDE I figure

[14:52:33.0535] <Andreu Botella>
the curvature of the entire universe too

[14:57:37.0525] <shu>
what the fuck


2024-04-05
[17:19:11.0869] <waldemar>
The current time systems in common use are only really designed to work on the surface of the Earth. Astronomers and other space scientists use different time systems which account for relativistic effects such as https://en.wikipedia.org/wiki/Barycentric_Dynamical_Time

[17:21:00.0409] <waldemar>
One of my favorite papers is measuring the masses of various solar system bodies such as Saturn using nothing more than clocks, comparing earthbound clocks to clocks outside the solar system (in the form of distant pulsars): https://arxiv.org/abs/1008.3607

[17:24:04.0707] <waldemar>
The approach of counting seconds won't work well after we expand into space because clocks tick at different rates in different places in the solar system. If you want everyone to stay synced to Earth time, you'll need to adjust the duration of the second depending on where you are. If you want to keep the SI definition of a second, clocks in various places will diverge over time.

[17:25:16.0778] <waldemar>
We already have that issue with spacecraft, but the scientists and engineers working them account for the differences.

[15:18:54.0730] <Aki>
if you'll all allow a brief single off-topic post: i'm baaaaaack. üòò

[15:37:44.0040] <Chris de Almeida>
requesting consensus for an eclipse break on Monday

[15:39:42.0077] <Chris de Almeida>
well. I guess that doesn't make much sense unless the break is like.. 2 hours long

[15:39:44.0800] <Aki>
i wonder if people will be too distributed

[15:39:46.0787] <Aki>
lol

[15:39:50.0436] <Aki>
also that

[15:40:40.0576] <Chris de Almeida>
ah, actually for me the meeting will be over already

[15:41:04.0653] <Aki>
yeah the farther east you are, i think


2024-04-06
[17:35:11.0123] <rbuckton>
I will be missing Monday for the eclipse, though I might try to dial in to observe the plenary for part of the day. 

[23:36:03.0603] <Chris de Almeida>
https://github.com/tc39/Reflector/issues/522#issuecomment-2040991367

[23:38:46.0738] <Chris de Almeida>
‚òùÔ∏è draft schedule is available. all constraints have been accommodated


2024-04-08
[07:02:26.0932] <shu>
is there a way to join the meeting without logging in

[07:02:59.0511] <Jesse>
I joined the call anonymously (no prior log in)

[07:03:46.0202] <bakkot>
you do not have to use the client

[07:04:12.0479] <shu>
oh i see, i can just enter any name/email, thanks

[07:04:12.0879] <bakkot>
if you click the "use on the web" it kind of implies you're signing in, but you just put your name and email and then join regardless of what you put in those boxes

[07:04:22.0400] <Chris de Almeida>
> <@shuyuguo:matrix.org> is there a way to join the meeting without logging in

yes

[07:04:37.0660] <littledan>
I just gave my name and email address, and then the "join as guest" button un-grayed

[07:04:52.0415] <littledan>
(done on the native client)

[07:07:19.0489] <shu>
> <@bakkot:matrix.org> if you click the "use on the web" it kind of implies you're signing in, but you just put your name and email and then join regardless of what you put in those boxes

thanks, that's what confused me

[07:20:48.0227] <littledan>
Slides for this presentation at https://github.com/tc39/agendas/blob/littledan-patch-2/2024/tc39-2024-016.pdf (PR'd to the agenda also)

[07:21:29.0352] <Michael Ficarra>
ooohh we're bringing WinterCG into Ecma?

[07:21:35.0040] <littledan>
yep!

[07:21:40.0316] <ryzokuken>
WinterTC

[07:21:42.0628] <Michael Ficarra>
I imagine it won't continue to be called WinterCG?

[07:22:02.0902] <littledan>
More context: https://github.com/wintercg/admin/issues/58

[07:22:28.0541] <littledan>
The W3C CG will be the main place for technical development; WinterTC will be more for validation and formal standardization (this mirrors CycloneDX)

[07:25:15.0098] <nicolo-ribaudo>
Are temp checks an official vote?

[07:25:21.0423] <littledan>
no

[07:25:26.0632] <nicolo-ribaudo>
It's weird that voting rules apply to temp checks 

[07:26:05.0675] <littledan>
yes, I agree. I think these Ecma rules only apply directly to official votes, which we do not have. That said, I'm not sure if IEs should be able to block.

[07:26:09.0848] <ljharb>
they're def not votes

[07:26:35.0227] <littledan>
calling for consensus on advancement might be thought of as an implicit vote

[07:26:39.0873] <littledan>
but temperature checks certainly aren't fotes

[07:26:43.0137] <littledan>
 * but temperature checks certainly aren't votes

[07:26:44.0160] <Michael Ficarra>
IEs definitely should not be voting/blocking

[07:26:48.0579] <ljharb>
IEs not being able to participate in consensus would be a radical change from the way tc39 has always operated, so that'd be something that needs discussion

[07:27:02.0636] <shu>
IEs should not be able to veto

[07:27:08.0299] <littledan>
> <@ljharb:matrix.org> IEs not being able to participate in consensus would be a radical change from the way tc39 has always operated, so that'd be something that needs discussion

OK, let's have this discussion now with Samina

[07:27:13.0942] <littledan>
in the queue

[07:27:55.0522] <ljharb>
about temp checks sure. but ecma rules aren't really relevant; IEs participate in consensus here, and we'd need an agenda item to get consensus on changing that.

[07:31:40.0124] <ljharb>
shu: "being an IE" is at the discretion of chairs and ecma, so if that were ever abused it would be pretty easy to shut it down

[07:32:48.0877] <eemeli>
Does consensus for stage advancement count as a "vote" in ECMA terms?

[07:33:08.0900] <shu>
imo yes?

[07:33:25.0901] <nicolo-ribaudo>
I think so

[07:33:26.0192] <ljharb>
no

[07:33:27.0989] <shu>
like i don't see why there would be any bylaws if any TC can also just say "actually we don't do that"?

[07:33:33.0498] <ljharb>
it's consensus. not a ote.

[07:33:34.0769] <ljharb>
 * it's consensus. not a vote.

[07:33:43.0685] <ljharb>
if it was a vote than we wouldn't ask individuals, we'd ask members.

[07:33:50.0747] <nicolo-ribaudo>
And we informally agree that the chairs only ask for the vote if there is would be full consensus

[07:34:00.0218] <shu>
i strongly disagree

[07:34:04.0350] <ljharb>
for example, google having 30 delegates would still only get 1 response to a call for consensus. that's not how we operate.

[07:34:19.0368] <littledan>
there has long been disagreement within the committee about what the policy is. It's good for this to be on the table for discussion.

[07:35:06.0618] <ljharb>
 * for example, google having 30 delegates would still only get 1 response to a call for consensus. that's not how we operate, or have literally ever operated.

[07:35:28.0730] <nicolo-ribaudo>
 * And we informally agree that the champions only ask for the vote if there is would be full consensus

[07:35:39.0534] <nicolo-ribaudo>
 * And we informally agree that the champions only "ask for the vote" if there is would be full consensus anyway, so no vote needed

[07:35:45.0497] <ljharb>
it's fine to discuss it, and if someone would like to, it'd be great to add an agenda item for it. but making a change here would be dramatic and unprecedented for tc39, and isn't a matter of simply "interpreting bylaws".

[07:35:47.0564] <eemeli>
It would be Really Good for execom to explicitly comment on our consensus practices.

[07:36:13.0061] <littledan>
good reminder from @ljharb on GitHub teams, and thank you for your good work on setting up the GitHub teams. I do want to note that we have some inconsistencies between the GitHub and Ecma data (which member organizations have provided to Ecma and are published in the Ecma memento) and we will need to work through these. I believe neither one of these is perfectly up to date, and we will make a lot of progress by reconciling them.

[07:36:30.0673] <ljharb>
in general, laws serve the people, so if the bylaws conflict with what we actually do, the bylaws, not us, should change.

[07:37:22.0954] <littledan>
> <@eemeli:mozilla.org> It would be Really Good for execom to explicitly comment on our consensus practices.

In general, the ExeCom and Ecma management are very happy with TC39's "self-governance" and don't want to intervene too much. Ecma folks have previously said that they are happy with consensus-based processes like ours, but have found our way of dealing with vetos as absolute to be a bit much.

[07:37:29.0948] <ljharb>
 * in general, laws serve the people, so if the bylaws conflict with what committees actually do, the bylaws, not us, should change.

[07:39:42.0536] <littledan>
> <@ljharb:matrix.org> in general, laws serve the people, so if the bylaws conflict with what committees actually do, the bylaws, not us, should change.

Yes, I very strongly agree with you that we should be thoughtful about any change to TC39's practices and not just blindly apply rules/bylaws, but consider whether they need to be changed if they don't fit, and submit such changes to the Ecma GA for a vote [in practice, consensus there too]. That said, the committee has long contained multiple opinions about whether IEs can block, so it's not clear what the change would/should be. Ecma rules are still set by the GA and not by TC39 precedent.

[07:40:06.0634] <littledan>
I mean, this is why I got involved in Ecma stuff in the first place, to ensure that we had an IE policy in the first place and that we didn't accidentally kick Babel etc out

[07:42:21.0294] <eemeli>
littledan: Does "a bit much" mean that there's an expectation for us to change something at some point, or that the divergence from expectations is small enough to ignore?

[07:43:36.0431] <ljharb>
i mean sure, but opinions that differ from 100% of past history don't change what's actually happened

[07:44:02.0808] <ljharb>
it's fine to believe IEs shouldn't participate in consensus, for example, but that's only relevant in a discussion about whether to change the fact that they do :-)

[07:45:10.0345] <ljharb>
 * it's fine to believe IEs shouldn't participate in consensus, for example, but that's only relevant in a discussion about whether to change the fact that they do :-) (which is also fine to have, ofc)

[07:50:01.0990] <littledan>
> <@eemeli:mozilla.org> littledan: Does "a bit much" mean that there's an expectation for us to change something at some point, or that the divergence from expectations is small enough to ignore?

No, there is no expectation that we change anything; they respect our self-management here and don't want to excessively intervene.

[07:50:38.0182] <littledan>
> <@ljharb:matrix.org> i mean sure, but opinions that differ from 100% of past history don't change what's actually happened

in past incidents of IEs blocking, IMO there is ambiguity as to whether the IE actually executed a block, or whether the IE expressed a strong negative opinion and the champion withdrew the request for advancement.

[07:51:18.0335] <ljharb>
there's no such thing as "block". there's either consensus for something, or not

[07:51:19.0727] <littledan>
IEs are definitely here to participate actively in all technical discussions, and express strong negative opinions when there's a request for consensus, no doubt about that. If they make a good argument, they won't be the only blocker, so this is probably not a very impactful decision.

[08:10:06.0150] <Ben>
402 update slides: https://notes.igalia.com/p/fxx00_k5K#/

[08:14:39.0447] <nicolo-ribaudo>
This transcriber wrote "camel cased" as CamelCased

[08:14:47.0790] <nicolo-ribaudo>
üíØ

[08:19:43.0281] <ljharb>
oh no, that's PascalCased tho

[08:21:34.0343] <dminor>
ptomato: Could you please provide a link to the sovereign tech fund that is funding the test262 work? Or to your slides?

[08:22:08.0509] <ljharb>
it's Germany

[08:22:14.0492] <ljharb>
https://www.sovereigntechfund.de

[08:22:27.0910] <ptomato>
I was about to paste the content of the slide into the notes, will that work?

[08:22:30.0491] <ljharb>
they also gave nearly a million to the OpenJS Foundation last year

[08:22:33.0853] <ptomato>
otherwise yes what Jordan said

[08:22:38.0930] <ljharb>
they're doing what all governments should be doing :-) it's great

[08:22:50.0560] <dminor>
Great, thank you :)

[08:29:53.0178] <dminor>
Hypothetical question, would we take money from any sovereign tech fund, or would we consider things like human rights records, etc. before accepting funding?

[08:29:55.0536] <littledan>
apparently there's also https://nlnet.nl/bluehatsprize/2024 currently seeking nominations

[08:31:06.0719] <shu>
> <@dminor:mozilla.org> Hypothetical question, would we take money from any sovereign tech fund, or would we consider things like human rights records, etc. before accepting funding?

we = TC39?

[08:33:33.0268] <dminor>
Well, in that case I guess it's Igalia's decision, but yes, I'm kind of wondering how we as a group would feel about this.

[08:33:46.0813] <littledan>
There's also https://www.opentech.fund (from the US govt)

[08:34:09.0282] <littledan>
> <@dminor:mozilla.org> Well, in that case I guess it's Igalia's decision, but yes, I'm kind of wondering how we as a group would feel about this.

I guess this would be something at the Ecma level? In which case it'd definitely be a matter up for GA discussion

[08:34:18.0521] <shu>
i feel like TC39 itself isn't a legal entity to receive funds, so i imagine it's just up to Ecma

[08:35:14.0197] <littledan>
 * There's also https://www.opentech.fund (from the US govt) , specifically https://apply.opentech.fund/foss-sustainability-fund/

[08:35:30.0172] <Michael Ficarra>
it'd be nice if the CoC update included what actions were taken (if any) instead of just saying "it's been resolved"

[08:36:04.0448] <shu>
the usual non-profit donation tricks abound, i imagine, with whether you can or cannot earmark donations for specific activities, especially if it's from a government

[08:42:48.0319] <littledan>
> <@shuyuguo:matrix.org> the usual non-profit donation tricks abound, i imagine, with whether you can or cannot earmark donations for specific activities, especially if it's from a government

FWIW Ecma is a Swiss "association", not a US 501(c)(3). I think this makes certain things more flexible.

[08:42:49.0122] <Michael Ficarra>
serious question: is there anyone who goes to the Firefox download page, says "300MB?! No thanks.", and leaves?

[08:43:01.0054] <Michael Ficarra>
I think by the time you're there, you're downloading Firefox, right?

[08:43:11.0121] <littledan>
it's sort of a cumulative thing though, right?

[08:43:19.0205] <littledan>
especially for mobile

[08:43:21.0208] <shu>
my intuition on almost all size concerns are about mobile, not desktop

[08:43:25.0833] <Michael Ficarra>
you mean Mozilla wants to save upload bandwidth?

[08:43:33.0612] <shu>
indeed i don't think people say that to the desktop downloader

[08:43:37.0711] <nicolo-ribaudo>
> <@michaelficarra:matrix.org> serious question: is there anyone who goes to the Firefox download page, says "300MB?! No thanks.", and leaves?

When your phone is out of storage you have to start going through the list of big apps ü§∑

[08:43:52.0500] <nicolo-ribaudo>
And all phones already have a built-in browser

[08:44:03.0169] <littledan>
> <@shuyuguo:matrix.org> the usual non-profit donation tricks abound, i imagine, with whether you can or cannot earmark donations for specific activities, especially if it's from a government

 * FWIW Ecma is a Swiss "association", not a US 501(c)(3). I think this makes certain things more flexible (IANAL!)

[08:44:24.0422] <shu>
also, markets with significantly cheaper hardware

[08:44:35.0991] <ljharb>
how small is the average phone in those markets these days?

[08:44:52.0859] <littledan>
I think it's more about bandwidth

[08:45:08.0499] <nicolo-ribaudo>
> <@ljharb:matrix.org> how small is the average phone in those markets these days?

Idk but my dad is always uninstalling apps to free up space because his phone is full

[08:45:18.0199] <littledan>
 * I think it's more about download bandwidth

[08:48:05.0841] <bakkot>
> <@ljharb:matrix.org> how small is the average phone in those markets these days?

(nominally 64GB-128GB, usually)

[08:48:18.0998] <ljharb>
that's what i'd expect

[08:48:47.0927] <Jesse>
for me it's images/movies, not apps, that take up space

[08:49:31.0939] <eemeli>
> <@michaelficarra:matrix.org> serious question: is there anyone who goes to the Firefox download page, says "300MB?! No thanks.", and leaves?

To be picky, Firefox desktop on MacOS is currently 134Mb, and on Android it's 88Mb.

[08:49:44.0151] <eemeli>
> <@michaelficarra:matrix.org> serious question: is there anyone who goes to the Firefox download page, says "300MB?! No thanks.", and leaves?

 * To be picky, Firefox desktop on MacOS is currently 134MB, and on Android it's 88MB.

[08:49:57.0772] <Michael Ficarra>
yeah I was too lazy to look up the actual number

[08:50:25.0530] <Michael Ficarra>
here, let me fix it for you: "134MB?! No thanks."

[08:51:12.0437] <ryzokuken>
> <@jesse:igalia.com> for me it's images/movies, not apps, that take up space

spotify's cache grows nearly exponentially 

[08:53:42.0877] <Chris de Almeida>
> <@michaelficarra:matrix.org> it'd be nice if the CoC update included what actions were taken (if any) instead of just saying "it's been resolved"

per the Code of Conduct:  

> The Committee will never publicly discuss the issueÕæ all public statements, if needed, will be made by the TC39 Chair and/or the Ecma Secretariat.

[08:55:37.0682] <Michael Ficarra>
telling us what actions were taken (like somebody being banned from a particular forum) is not discussing the issue IMO

[08:58:53.0469] <littledan>
The CoC committee could refer more public statements to the chair or secretariat for disclosure. Overall I think we have enough experience that statements like, "there was a report, it was handled" don't really make all of TC39 feel more secure about the process. But maybe we should just trust the CoC committee, and even these notifications are unnecessary--confidentiality is really important to preserve.

[08:59:21.0144] <shu>
yeah i think if you want to be confidential just don't update

[08:59:31.0979] <shu>
100% confidential, that is

[09:00:38.0215] <Chris de Almeida>
depending on the action taken, saying what that action was may have privacy risk

[09:00:45.0184] <ryzokuken>
there's no harm in evolving our CoC processes in order to better serve delegates and make everyone feel more secure about our working environment here

[09:10:07.0761] <Chris de Almeida>
it's up to TC39 what the CoC is and how the CoC committee reports back to TC39 and the ExeCom/GA. if folks want to change the CoC, that's fine. it needs to be raised and get consensus at plenary, and I think Ecma ExeCom also would need to support if I'm not mistaken

[09:11:13.0487] <Chris de Almeida>
 * it's up to TC39 what the CoC is and how the CoC committee reports back to TC39 and the ExeCom/GA. if folks want to change the CoC, that's fine. it needs to be raised and get consensus at plenary

[09:22:37.0997] <littledan>
Definitely needs an agenda item to draw a conclusion; this is just some earlier discussion/feedback, which is also valid (like our above discussion about Ecma rules despite this not being a GA meeting). The CoC committee could also be the ones to propose something to plenary, based on this kind of feedback.

[09:33:14.0276] <Chris de Almeida>
you're absolutely right. I want to be clear it's not a matter the CoC committee can unilaterally decide

[09:40:03.0157] <littledan>
About blocks: IMO IEs should generally be able to operate equally to all other committee delegates, and the process focus should probably be more on, what can we do in response to someone (anyone) blocking, and whether the committee may still have general consensus (e.g., by establishing that general consensus at a follow-on meeting once we all have more time to consider things).

[10:06:38.0293] <bakkot>
I don't know that "I would prefer to work with arrays" is... really an answer to "what is the benefit"?

[10:13:14.0896] <littledan>
yeah I think we kinda settled this with iterator helpers a while ago... I did try to give more space to the iterables vs iterators discussion with inviting Axel in, etc.

[10:14:40.0695] <shu>
i mean i also to prefer to work with arrays when cache locality matters

[10:14:53.0769] <shu>
but i don't know if i care about it for joint iteration in particular

[10:15:14.0243] <shu>
and "caring about cache locality" certainly argues for case-by-case for the operation, not a catch-all

[10:15:26.0619] <ljharb>
to be clear i'm not arguing for 100% symmetry

[10:16:32.0099] <Michael Ficarra>
FYI I consider take/drop to be the analogue to slice @nicolo-ribaudo:matrix.org @bakkot:matrix.org

[10:16:45.0068] <bakkot>
they're certainly similar, just not identical

[10:20:36.0850] <bakkot>
I would like us to explicitly have a policy that we don't use "this package has many downloads" as a reason to add a feature

[10:20:59.0442] <bakkot>
"this package has many dependents from different authors", sure

[10:21:41.0686] <nicolo-ribaudo>
(in this case, the package has a dependency of Jest)

[10:21:45.0127] <ljharb>
yeah i was more saying, this is empirical evidence that the original belief is false

[10:21:54.0495] <ljharb>
(that everybody would prefer an aiife)

[10:22:13.0426] <nicolo-ribaudo>
 * (in this case, the package is a transitive dependency of Jest)

[10:22:30.0550] <Michael Ficarra>
> <@shuyuguo:matrix.org> but i don't know if i care about it for joint iteration in particular

please add these comments to https://github.com/tc39/proposal-joint-iteration/issues/1

[10:23:32.0294] <nicolo-ribaudo>
 * (in this case, the package is a transitive dependency of Jest and yargs)

[10:26:24.0038] <shu>
ok

[10:26:28.0184] <bakkot>
tbc, the closest analogy is `new Promise(r => r(foo, ...args))`, not a try-catch

[10:26:41.0794] <bakkot>
 * tbc, the closest analogy is `new Promise(r => r(foo(args)))`, not a try-catch

[10:26:48.0086] <littledan>
We've heard a lot of skepticism on motivation. Maybe we should do a temperature check/

[10:26:52.0606] <littledan>
 * We've heard a lot of skepticism on motivation. Maybe we should do a temperature check?

[10:27:56.0365] <nicolo-ribaudo>
My position is exactly the same

[10:28:03.0225] <nicolo-ribaudo>
"Not bad, but not convinced that it's useful"

[10:29:54.0512] <littledan>
Promise.prototype.catch/finally are really different from Promise.try...

[10:30:26.0888] <shu>
we have spent more time talking about the check than just doing the check

[10:31:17.0288] <tkopp>
I like the hoisting of a sometimes promised function into a definite promise.
It helps decluttering functional chaining.

[10:31:59.0561] <ptomato>
> <@shuyuguo:matrix.org> we have spent more time talking about the check than just doing the check

we do that every time. but temperature checks are rare. if they were more common, I think we wouldn't have to talk about them so much

[10:34:06.0303] <danielrosenwasser>
> <@littledan:matrix.org> Promise.prototype.catch/finally are really different from Promise.try...

could you say more about what the big differences are?

[10:34:52.0945] <nicolo-ribaudo>
Temp polls should have a symmetrical state, going from Strong Positive to Strong Negative

[10:36:06.0616] <littledan>
I voted "indifferent" based on agreeing with what Nicolo said. The intended meaning is not "abstain"

[10:37:12.0071] <bakkot>
"very weak negative" is how I intended my "indifferent"

[10:37:23.0817] <danielrosenwasser>
I assumed "üëÄ" was abstain

[10:37:39.0733] <waldemar>
Indifferent indicates that you had time to consider the issue and vote. 

[10:38:03.0075] <waldemar>
Indifferent has no negative connotations to me.

[10:38:28.0604] <waldemar>
Without "indifferent" it would be hard to tell if people had a chance to vote.

[10:38:33.0136] <littledan>
communication is all about relationships and context, and not only absolute meanings of words

[10:39:14.0024] <littledan>
here, several people explicitly clarified that they specifically meant "very weak negative", so it doesn't really matter if "indifferent" generally has no negative connotations

[10:39:22.0218] <littledan>
anyway it has Stage 2.7 so this is closed, I think

[10:39:31.0287] <bakkot>
I guess given that we would not advance a proposal unless at least some people were strongly positive, and that "very weak negative" is "I don't object to advancement", there's not much practical difference between the two

[10:40:09.0667] <littledan>
in this case, yes

[10:40:23.0112] <Chris de Almeida>
more of an aside, but we regularly change the semantics of what the temp check options are because they don't always align well with the question

[10:40:25.0642] <littledan>
I did want to elicit some more positive/strongly positive feedback, which we did get

[10:42:13.0844] <Michael Ficarra>
just a backslash wouldn't work anyway since we got rid of identity escapes

[10:42:30.0766] <Michael Ficarra>
so it'd be replacing the first character with an escape sequence for that character, like a hex escape

[10:42:39.0129] <Michael Ficarra>
if this is even needed, which I don't believe it is

[10:44:33.0107] <littledan>
> <@nicolo-ribaudo:matrix.org> Temp polls should have a symmetrical state, going from Strong Positive to Strong Negative

I think this choice was deliberate because it was trying to avoid negativity, but after a couple years of experience, it doesn't seem like that design worked. I like the idea of a basically 1-5 symmetrical scale; the other options don't seem to be very easy to interpret.

[10:44:58.0284] <littledan>
and in particular, temperature checks were designed to avoid, well, this kind of vote as a use case, to be honest

[10:44:58.0494] <nicolo-ribaudo>
I opened https://github.com/bterlson/tcq/pull/67for now

[10:45:12.0241] <nicolo-ribaudo>
 * I opened https://github.com/bterlson/tcq/pull/67 for now

[10:46:35.0698] <Michael Ficarra>
strictly more options?!

[10:46:42.0933] <Michael Ficarra>
please no, please get rid of some options at the same time

[10:47:37.0849] <nicolo-ribaudo>
Who should take the fall, "Strongly positive" or "Following"

[10:47:59.0219] <ljharb>
following

[10:48:03.0667] <ptomato>
following. has anyone ever voted following

[10:48:31.0037] <Michael Ficarra>
following for sure

[10:49:18.0624] <littledan>
So "unconvinced" is weakly negative, and "negative" is strongly negative? Should we rename the options to be symmetrical?

[10:49:24.0508] <Michael Ficarra>
also confused because if you're confused, you should be asking for clarification, not voting!

[10:49:44.0896] <littledan>
I guess in this case, "unconvinced" being the strongest negative option makes it scary to vote for

[10:50:03.0976] <littledan>
no, confused is good, we should keep it--it's a big problem if people are confused and afraid to ask!

[10:50:43.0771] <nicolo-ribaudo>
I think calling it unconvinced is more expressive than "weakly negative"

[10:51:04.0400] <nicolo-ribaudo>
Or "This temperature check has been worded terribly I don't know what I'm voting" üòõ

[10:51:07.0151] <littledan>
OK, I'm convinced :)

[10:51:15.0439] <nicolo-ribaudo>
 * Or "This temperature check has been worded terribly I don't understand what the options mean in this case" üòõ

[10:51:25.0428] <littledan>
the most important thing is to have something stronger than unconvinced, so that unconvinced becomes less harsh, I think

[10:57:14.0993] <nicolo-ribaudo>
Ughh I just noticed that I forgot to add slides to one of my topics on the agenda (a status update)

[10:57:26.0116] <Michael Ficarra>
this is enough change in the proposal that, even Wednesday, I don't think I'd be prepared to advance to 2.7

[10:57:26.0547] <nicolo-ribaudo>
 * Ughh I just noticed that I forgot to add slides to one of my topics on the agenda (a status update) -- I'm sorry

[10:57:41.0666] <ljharb>
100% agreed

[10:58:06.0556] <ljharb>
maybe with just one of these changes, but with 2 or 3 i'd rather wait

[10:58:50.0013] <Michael Ficarra>
to be clear, I think they're all good improvements, but I'd want to review it as a whole again

[11:00:31.0247] <ljharb>
yep, i've unchecked all the signoffs so i know to re-ask

[11:00:42.0656] <ljharb>
btw for the steno, can we get them to stop double spacing after periods?

[11:01:18.0285] <Michael Ficarra>
they're also inserting newlines at the page width instead of letting it wrap üò≠

[11:02:17.0713] <nicolo-ribaudo>
"Can you please set your line width to 100_000_000?"

[11:02:43.0350] <ljharb>
both of those, yes please

[11:03:15.0141] <littledan>
we've asked the stenographers to do this before. They should be doing it. I'll call them today.

[11:03:27.0536] <littledan>
They've fixed this in the past, it's just that not all of them do it

[11:25:27.0279] <bakkot>
waldemar: On the topic of RegExp escapes, what escaping do you think we ought to use for null bytes? We have `\0`, but `\x00` is plenty readable, and `\0` has the complication that you can't use it if the next character is an ASCII digit. My inclination is to use `\x00`.

[11:56:29.0626] <Michael Ficarra>
should `microwait` be called `microWait`?

[11:58:54.0669] <bakkot>
should "kilogram" be spelled "kiloGram"?

[12:00:52.0828] <Michael Ficarra>
if it was a JS API? probably

[12:01:03.0838] <bakkot>
nooooo

[12:01:14.0277] <bakkot>
we use camel case when it's two words

[12:01:21.0453] <bakkot>
but "micro" is a prefix, not a new word

[12:01:47.0696] <nicolo-ribaudo>
`setTimeOut`

[12:03:47.0535] <nicolo-ribaudo>
Feedback about WebEx: much better than zoom

[12:04:04.0285] <shu>
i liked how it had a light mode

[12:04:07.0488] <shu>
down with dark mode!!

[12:04:11.0315] <Michael Ficarra>
much better than I expected, about the same as zoom

[12:04:11.0484] <ryzokuken>
please qualify better better.

[12:04:11.0796] <bakkot>
it is literally indistinguishable afacit

[12:04:24.0283] <nicolo-ribaudo>
In Zoom I always have audio issues

[12:04:30.0244] <nicolo-ribaudo>
It never works the first time

[12:04:41.0866] <shu>
is this a zoom problem or is this "year of linux on the desktop" problem

[12:04:52.0340] <ptomato>
video/screenshare entirely didn't work on firefox for me, so webex is a üëéÔ∏è from me

[12:05:03.0336] <nicolo-ribaudo>
> <@shuyuguo:matrix.org> is this a zoom problem or is this "year of linux on the desktop" problem

A year of firefox problem üòõ

[12:05:07.0476] <Michael Ficarra>
it only allowed you to share "apps", not windows, so if I changed which Chrome window was focused, it would share that one instead

[12:05:11.0874] <ryzokuken>
IMO the web version was nicer than zoom and thus I had no reason to even attempt to use the native (apropos the parens thingie that was weird) and zoom's native version just takes years off my life

[12:05:13.0098] <nicolo-ribaudo>
> <@pchimento:igalia.com> video/screenshare entirely didn't work on firefox for me, so webex is a üëéÔ∏è from me

Oh weird, I had zero problems with it

[12:05:25.0322] <nicolo-ribaudo>
> <@usharma:igalia.com> IMO the web version was nicer than zoom and thus I had no reason to even attempt to use the native (apropos the parens thingie that was weird) and zoom's native version just takes years off my life

Oh yes, I use the web version for both

[12:05:31.0690] <nicolo-ribaudo>
Long live the web

[12:06:16.0136] <ryzokuken>
> <@usharma:igalia.com> IMO the web version was nicer than zoom and thus I had no reason to even attempt to use the native (apropos the parens thingie that was weird) and zoom's native version just takes years off my life

but I'd clarify that calling zoom not working hard enough on their linux app a linux problem is unfair

[12:06:35.0866] <ryzokuken>
like other native video conferencing apps exist, many of them are electron based and still do a vastly better job

[13:17:37.0105] <ljharb>
> <@michaelficarra:matrix.org> it only allowed you to share "apps", not windows, so if I changed which Chrome window was focused, it would share that one instead

mine, from chrome, let me choose which specific chrome tab i wanted to share

[13:17:41.0839] <ljharb>
> <@michaelficarra:matrix.org> it only allowed you to share "apps", not windows, so if I changed which Chrome window was focused, it would share that one instead

 * mine, from chrome, let me choose which specific chrome tab i wanted to share (zoom does also)

[13:30:12.0215] <ptomato>
I think that's a chrome/chromium-specific feature

[16:10:10.0622] <waldemar>
> <@bakkot:matrix.org> waldemar: On the topic of RegExp escapes, what escaping do you think we ought to use for null bytes? We have `\0`, but `\x00` is plenty readable, and `\0` has the complication that you can't use it if the next character is an ASCII digit. My inclination is to use `\x00`.

I didn't ask that question, but I did notice that non-whitespace control characters weren't escaped. I thought that was deliberate, but escaping them would be a worthwhile change for readability. I agree with `\x00` for the reasons you state.


2024-04-09
[06:52:32.0959] <ryzokuken>
good morning/evening/night everyone!

[06:52:36.0888] <ryzokuken>
meeting starts in ~7

[07:29:19.0744] <littledan>
I have trouble understanding the motivation for this null change, but also it doesn't seem harmful

[07:29:55.0863] <littledan>
(or rather, I have trouble understanding the motivation for the null skipping in the first place)

[07:30:39.0976] <nicolo-ribaudo>
Random fact: Babel accidentally ignores `null`s while guaranteeing at least one `await` -- we have a PR open to match the behavior of the current (pre-this-change) proposal

[07:35:07.0570] <hax (HE Shi-Jun)>
It seems this PR try to avoid nulls introducing extra awaits, am I understanding this correctly?

[07:35:17.0535] <nicolo-ribaudo>
Yes

[07:37:51.0235] <shu>
this is a small thing, but i'd be interested in people's thoughts on banning `using` inside base switch cases: https://github.com/tc39/proposal-explicit-resource-management/issues/215#issuecomment-2040486653

[07:39:23.0609] <nicolo-ribaudo>
Babel's `using` support in `switch` is currently completely broken

[07:39:42.0017] <nicolo-ribaudo>
Because everything in `switch` is incredibly annoying to compile

[07:39:57.0272] <shu>
i wanna ban it but recognize that'll break symmetry with let/const

[07:40:52.0756] <nicolo-ribaudo>
Is it for implementation reasons?

[07:41:54.0326] <shu>
it's laid out in the comment -- saves some codegen complexity

[07:42:36.0729] <shu>
we can unroll the dispose loop in all cases except switch cases

[07:44:25.0497] <nicolo-ribaudo>
I'm trying to think of any usecase for `using` in switch, but I cannot think of any where I would want `using`'s scope to fall through multiple cases

[07:46:00.0809] <nicolo-ribaudo>
(Babel doesn't unroll the loop anymore, so for us it wouldn't actually be difficult to fix `using` in `switch`)

[07:46:39.0248] <shu>
we don't unroll currently, but would like to

[07:50:26.0532] <rbuckton>
> <@nicolo-ribaudo:matrix.org> I'm trying to think of any usecase for `using` in switch, but I cannot think of any where I would want `using`'s scope to fall through multiple cases

The most relevant case I can see would be something like manual loop unrolling, where you skip over the `using` for a chunk of operations when it isn't needed, such as if a lock was needed for a 16k chunk of data that isn't needed for a smaller chunk of data. The point of manual loop unrolling is to avoid a bunch of comparisons and branches based on a single condition such as input size, so a smaller chunk of data skips over the `using` (and avoids the extraneous `null`/`undefined` check), while a larger chunk of data enforces the `using` and holds the lock until the current iteration of the loop ends.

[07:52:52.0530] <nicolo-ribaudo>
Oh I see, like for transpiling generators

[07:53:13.0016] <nicolo-ribaudo>
(in a world where generators are transpiled and `using` is not I guess)

[07:53:51.0282] <rbuckton>
```js
for (let start = 0; start < len; start += 8) {
    switch (start % 8) {
        case 0:
          // full chunk, perform lock
          using lck = new UniqueLock(mut);
          readByte();
        case 1: readByte();
        case 2: readByte();
        case 3: readByte();
        case 4: readByte();
        case 5: readByte();
        case 6: readByte();
        case 7: readByte();
    } // lock released if taken
}
```

[07:56:40.0590] <rbuckton>
not for transpiling generators, no. that would be using a `switch` as a finite state machine, but an FSM would result in the `using` terminating early. Loop unrolling in this case is to handle chunks of data without continuously spinning and checking in the `for` to process one element at a time and cutting down the number of comparisons/branching from n to 1/n for a given chunk size of n.

[07:58:31.0396] <rbuckton>
 * not for transpiling generators, no. that would be using a `switch` as a finite state machine, but an FSM would result in the `using` terminating early. Loop unrolling in this case is to handle chunks of data without continuously spinning and checking in the `for` to process one element at a time and cut down the number of comparisons/branching from n to 1/n for a given chunk size of n.

[08:25:18.0882] <littledan>
If we could get to Ashley's point, he can explain why TLA running eagerly is useful within Bloomberg

[08:26:40.0529] <hax (HE Shi-Jun)>
tla already can break expectations...

[08:29:10.0363] <ljharb>
certainly a TLA being added anywhere in your graph is a breaking change

[08:29:20.0562] <littledan>
The thing is: in practice, you really shouldn't use JSON or CSS modules either, due to the lack of built-in bundling. The limited utility of built-in modules is not at all limited to this feature

[08:29:46.0958] <bakkot>
this strongly suggests to me that we need a path to standardize bundler-only syntax

[08:29:48.0867] <littledan>
until then, we'll be talking about features that are mostly useful for bundlers and non-web environments

[08:29:55.0338] <ljharb>
 * certainly a TLA being added anywhere in your graph (that's not an entrpoint) is a breaking change

[08:30:13.0856] <littledan>
> <@bakkot:matrix.org> this strongly suggests to me that we need a path to standardize bundler-only syntax

I disagree; I think we should fix the issues to allow native modules to be usable in browsers

[08:30:27.0596] <shu>
i disagree with that disagree

[08:30:32.0747] <shu>
doesn't seem a good use of resources tbh

[08:31:06.0008] <bakkot>
> <@littledan:matrix.org> I disagree; I think we should fix the issues to allow native modules to be usable in browsers

That is also good! And then, after that, standardizing things like this everywhere instead of bundler-only. But not before that.

[08:31:13.0688] <littledan>
these are all arguments against ES6 modules in the first place

[08:31:22.0335] <bakkot>
*cough*

[08:31:31.0248] <bakkot>
I mean, yes.

[08:31:36.0224] <bakkot>
But that ship has sailed.

[08:31:45.0035] <ljharb>
you're soooo close

[08:31:53.0368] <rbuckton>
bundler-related, but could `import defer` potentially avoid fetch and parse as well if we could serialize the import graph on the server side ahead of time?

[08:32:03.0172] <hax (HE Shi-Jun)>
In Jack's "assert sync" proposal I suggest we can also add "use async" directive which might help to make TLA explicit. Maybe it also help this issue.

[08:32:16.0253] <littledan>
well, yeah, so this would be good input to the module harmony group, if we don't like modules features anymore...

[08:32:19.0410] <bakkot>
I think standardizing ES6 modules as bundler-only syntax would have been better than the current world

[08:32:33.0030] <rbuckton>
or is that not an option because fetch is async

[08:33:28.0283] <bakkot>
> <@littledan:matrix.org> well, yeah, so this would be good input to the module harmony group, if we don't like modules features anymore...

`import source` is useful on the web!

[08:33:45.0613] <bakkot>
so it's not "module features" in general, just those specific ones which aren't useful on the web

[08:34:11.0898] <Justin Ridgewell>
/me Taking over Chair responsibilities for a bit

[08:34:12.0251] <bakkot>
(possibly "[...] aren't useful on the web _yet_")

[08:34:29.0614] <littledan>
I think the Matrix results show that it's useful on the web *in practice*

[08:34:53.0125] <littledan>
It's a good thing that bundlers are aligned to TC39 and browsers in their syntax and semantics. It will be good for us to preserve that.

[08:35:07.0286] <Ashley Claymore>
> <@rbuckton:matrix.org> bundler-related, but could `import defer` potentially avoid fetch and parse as well if we could serialize the import graph on the server side ahead of time?

yep. That's what we do at Bloomberg. We find the TLA at build time. And add a simplified module graph of which imports have TLA deps to our equivalent of 'package.json'

[08:35:09.0814] <bakkot>
IIUC the Matrix results show that it's useful on the web to have bundler-level syntax for this, but not that it's useful to have in browsers, right?

[08:35:22.0291] <littledan>
we've made tons of progress by actually building things into JS; the code splitting situation was a mess before import(), and it resulted in code splitting not occurring.

[08:35:30.0794] <bakkot>
I am not proposing "give up on this"; I am proposing "have a path to standardize bundler-level syntax that isn't actually in browsers"

[08:35:40.0746] <littledan>
TC39 is the JavaScript standards committee--our role is to find this common syntax

[08:36:27.0193] <littledan>
once we find common syntax, it's OK if some implementations fall behind and don't implement everything, but it'd be a big cost to split the language in two

[08:36:33.0100] <bakkot>
my response is the thing Shu is saying out loud right now

[08:36:54.0555] <littledan>
we should have this as an actual agenda item; that'd make it easier to discuss

[08:39:05.0549] <littledan>
IMO Stage 3 serves this purpose of "it's in tools and not necessarily in browsers". Maybe we just want to leave things in Stage 3 for longer.

[08:39:36.0712] <bakkot>
fwiw eslint refuses to implement features prior to stage 4, though that's maybe a them problem

[08:41:07.0294] <ljharb>
stage 3 is when it gets shipped in browsers tho

[08:41:10.0342] <ljharb>
 * stage 3 is when it gets shipped in (most) browsers tho

[08:42:48.0786] <shu>
John-David Dalton: why is it disingenuous? this is arguably _better_ handled by tools. tools have a different view (they can see the whole app) and optimization opportunities than a VM

[08:43:14.0638] <shu>
we designed a super static module system. it is not surprising to me that it has been leveraged to success with ahead-of-time tooling

[08:44:10.0049] <littledan>
> <@bakkot:matrix.org> fwiw eslint refuses to implement features prior to stage 4, though that's maybe a them problem

well, there's babel-eslint

[08:46:23.0828] <ljharb>
(`@babel/eslint-parser` as of babel 7)

[08:47:03.0198] <littledan>
> <@ljharb:matrix.org> stage 3 is when it gets shipped in (most) browsers tho

IMO browsers *should* ship features like this at that point, but if they want to leave some features out of browsers for now (but we still assess that the feature is solid enough for Stage 3), maybe they can just let them sit in that bucket. Doesn't require holding back 2.7 or 3.

[08:47:22.0696] <littledan>
> <@ljharb:matrix.org> stage 3 is when it gets shipped in (most) browsers tho

 * I'd be happiest if browsers ship features like this at that point, but if they want to leave some features out of browsers for now (but we still assess that the feature is solid enough for Stage 3), maybe they can just let them sit in that bucket. Doesn't require holding back 2.7 or 3.

[08:47:33.0695] <ljharb>
3 is a pretty clear signal, that's the big purpose of 2.7. i agree it wouldn't require holding back 2.7

[08:48:23.0429] <Michael Ficarra>
so is this feature going to encourage the dreaded "barrel" module pattern?

[08:48:36.0398] <littledan>
> <@michaelficarra:matrix.org> so is this feature going to encourage the dreaded "barrel" module pattern?

it's about optimizing the feature--no encouragement is needed

[08:48:44.0114] <bakkot>
While that's technically true, I would be happier revising our process if we want to do that - I would prefer that stage 2.7/3 be taken as a commitment from browsers to implement a feature at some point. I don't want to get to a point where browsers allow features to reach 2.7 that they intend to never implement.

[08:49:04.0020] <shu>
agree

[08:49:09.0469] <shu>
the two design spaces are honestly different

[08:49:14.0285] <shu>
the constraints are different

[08:49:17.0420] <ljharb>
> <@michaelficarra:matrix.org> so is this feature going to encourage the dreaded "barrel" module pattern?

oof, i hadn't thought about that.

[08:49:29.0454] <littledan>
> <@bakkot:matrix.org> While that's technically true, I would be happier revising our process if we want to do that - I would prefer that stage 2.7/3 be taken as a commitment from browsers to implement a feature at some point. I don't want to get to a point where browsers allow features to reach 2.7 that they intend to never implement.

ah OK well I'm happy to get browser commitments like that; I don't want to discourage that. I haven't thought this through enough.

[08:49:54.0372] <Michael Ficarra>
> <@littledan:matrix.org> it's about optimizing the feature--no encouragement is needed

well it doesn't provide any benefit to those not using the pattern, so it seems like encouragement to use it

[08:50:06.0567] <shu>
littledan: i have been thinking about for most of this year, i'll give you something more thought out soon

[08:51:05.0282] <littledan>
> <@michaelficarra:matrix.org> well it doesn't provide any benefit to those not using the pattern, so it seems like encouragement to use it

I think you're overthinking it... there's a lot of existing usages of this pattern, and it's slow, and it is hard to migrate away from (a lot of effort has gone into this migration)

[08:51:20.0789] <littledan>
it's not about newly incentivizing usage

[08:51:54.0139] <Michael Ficarra>
so someone who wants to get similar tree-shakeability can just dump this pattern?

[08:52:24.0635] <littledan>
> <@michaelficarra:matrix.org> so someone who wants to get similar tree-shakeability can just dump this pattern?

sure, if you can get all your dependencies to dump this pattern, then you'll have no reason to use this pattern in your dependency tree

[08:52:44.0025] <littledan>
> <@michaelficarra:matrix.org> so someone who wants to get similar tree-shakeability can just dump this pattern?

 * sure, if you can get all your dependencies to dump this pattern, then you'll have no reason to use this feature in your dependency tree

[08:52:59.0639] <ljharb>
there's a growing group of vocal folks in the ecosystem telling people to get rid of barrel modules, fwiw

[08:53:18.0876] <ljharb>
(coinbase's RN app's binary size dropped 71% when we banned barrel exports)

[08:53:40.0499] <ljharb>
 * (coinbase's RN app's binary size dropped 71% when we/they banned barrel exports back in 2021)

[08:53:52.0538] <littledan>
> <@ljharb:matrix.org> there's a growing group of vocal folks in the ecosystem telling people to get rid of barrel modules, fwiw

yes, they're doing good work; I think those two groups (the ecosystem effort and this proposal) should be understood to be supporting each other

[08:54:42.0621] <ljharb>
even with import defer, barrel exports will still result in a larger app than "just import what you need directly", no?

[08:54:53.0357] <bakkot>
I don't think "this feature is not useful in browsers" is a new category of objection?

[08:54:57.0161] <bakkot>
that's like... the main objection

[08:55:03.0284] <Michael Ficarra>
can someone remind me why people ever did that in the first place?

[08:55:23.0889] <ljharb>
i don't know why people tend to like "god objects"

[08:55:44.0526] <ljharb>
 * i don't know why people tend to like "god objects", deep imports is The Way

[08:55:53.0557] <ljharb>
 * i don't know why people tend to like "god objects", deep imports is The Way. but they do tend to like them.

[08:56:02.0865] <ptomato>
maybe the pattern was copied from python modules and `__init__.py`?

[08:56:08.0294] <littledan>
> <@michaelficarra:matrix.org> can someone remind me why people ever did that in the first place?

I always understood it to be a response to named exports being a thing, making use of that syntactic space, whereas require returning a single function was more natural

[08:56:16.0208] <ljharb>
i've seen people have a visceral preference for one `import` keyword that has N identifiers, instead of N `import` keywords

[08:56:44.0865] <shu>
> <@bakkot:matrix.org> that's like... the main objection

yeah i feel like most of our concerns that have caused feature compromises and redesigns boil down to this. sometimes it's couched in more specific terms, like "performance footgun" etc

[08:56:59.0201] <Michael Ficarra>
I'm finding it very hard to find sympathy for these people...

[08:57:00.0961] <ljharb>
also i think that a number of major IDEs implemented auto-refactoring features for named exports but ignored default exports

[08:57:06.0477] <ljharb>
 * also i think that a number of major IDEs implemented auto-refactoring features for named exports but ignored default exports (for no technical reason)

[08:57:15.0173] <ljharb>
 * also i think that a number of major IDEs implemented auto-refactoring features for named exports but ignored default exports (for no technical reason) which drove increased usage of named exports

[08:57:26.0804] <littledan>
> <@michaelficarra:matrix.org> I'm finding it very hard to find sympathy for these people...

why does it matter whose fault this is? it's currently a performance issue, and this is a solution.

[08:58:01.0118] <ljharb>
but is "don't use barrel files" perhaps a better solution?

[08:58:08.0095] <ljharb>
 * but is "don't use barrel files" perhaps a better solution? (genuine question)

[08:58:53.0606] <Justin Ridgewell>
Barrels are so convenient, and so awful for performance (both browsers and bundlers)

[08:58:56.0043] <littledan>
I dunno, there's a lot of recommendations about performance that people aren't taking up...

[08:59:24.0498] <Justin Ridgewell>
@guybedford:matrix.org Your mic is echoing

[08:59:47.0003] <bakkot>
but wouldn't this be a recommendation for performance in exactly the same way? it requires work to adopt; it doesn't just give you performance for free

[08:59:59.0606] <ryzokuken>
sorry guybedford bad timing

[09:00:06.0237] <Justin Ridgewell>
Timebox!

[09:00:09.0827] <bakkot>
and if the people in question were willing to do work to get performance they already can already do so, right?

[09:01:13.0988] <Michael Ficarra>
@nicolo-ribaudo:matrix.org your async feedback from me is that, for now, I'm unconvinced by the motivation

[09:01:30.0332] <ljharb>
> <@jridgewell:matrix.org> Barrels are so convenient, and so awful for performance (both browsers and bundlers)

convenience often makes for better paving than good intentions

[09:01:48.0748] <littledan>
> <@bakkot:matrix.org> but wouldn't this be a recommendation for performance in exactly the same way? it requires work to adopt; it doesn't just give you performance for free

The uptake is a "semver-minor" change--it doesn't require that importers update

[09:02:09.0563] <ljharb>
> <@jridgewell:matrix.org> Barrels are so convenient, and so awful for performance (both browsers and bundlers)

 * convenience often makes for better road-paving than good intentions

[09:03:04.0365] <ljharb>
so importers keep thinking they're doing a fine thing, when they're doing a horrible thing, and the entire ecosystem has to move to `import defer` to avoid the education problem?

[09:03:41.0791] <ljharb>
education's super hard so maybe that's the right tradeoff to make, tbf

[09:10:02.0762] <nicolo-ribaudo>
> <@bakkot:matrix.org> but wouldn't this be a recommendation for performance in exactly the same way? it requires work to adopt; it doesn't just give you performance for free

It moves the changes from the consumers to the library itself

[09:10:08.0224] <nicolo-ribaudo>
So 1 instead of N

[09:10:47.0173] <nicolo-ribaudo>
> <@ljharb:matrix.org> so importers keep thinking they're doing a fine thing, when they're doing a horrible thing, and the entire ecosystem has to move to `import defer` to avoid the education problem?

There is currently a choice to make between convenience and performance, and the goal here is to not make them exclusive

[09:43:07.0539] <ljharb>
does using `import defer` on a barrel file with a bundler that supports it give the ~same results as using deep imports in the first place?

[09:43:31.0739] <ljharb>
 * does using `import defer` on a barrel file with a bundler that supports it give the ~same results as using deep imports in the first place? because treeshaking so far still doesn't fully achieve "only importing what you need in the first place" afaik.

[09:46:05.0602] <Michael Ficarra>
in a language without so many hidden effects all over the place, it would be

[09:49:25.0896] <nicolo-ribaudo>
> <@ljharb:matrix.org> does using `import defer` on a barrel file with a bundler that supports it give the ~same results as using deep imports in the first place? because treeshaking so far still doesn't fully achieve "only importing what you need in the first place" afaik.

Sorry no, it's `export defer`/`export optional` that helps with barrel files

[09:49:50.0264] <nicolo-ribaudo>
And `export defer` would have the same result as using deep imports

[09:50:02.0350] <ljharb>
ok, so that's a compelling argument in favor of that one

[09:51:34.0893] <ljharb>
so `import defer` would be to lessen the downside of importing a barrel file that did not use `export defer`?

[09:52:04.0637] <nicolo-ribaudo>
And the boundary is still at the `export defer` level, so if you do
```js
// main.js
import { x } from "library;

// library
export defer { x, y } from "./x-and-y";
export defer { z } from "./z";

// library/x-and-y
export const x = 1;
export const y = 2;
```

it will also load `y` (so it's not complete dead code elimination), but gives the building block to remove code if you put unrelated code in separate modules

[09:52:09.0264] <nicolo-ribaudo>
 * And the boundary is still at the `export defer` level, so if you do

```js
// main.js
import { x } from "library";

// library
export defer { x, y } from "./x-and-y";
export defer { z } from "./z";

// library/x-and-y
export const x = 1;
export const y = 2;
```

it will also load `y` (so it's not complete dead code elimination), but gives the building block to remove code if you put unrelated code in separate modules

[09:52:39.0112] <nicolo-ribaudo>
 * And the boundary is still at the `export defer` level, so if you do

```js
// main.js
import { x } from "library";

// library
export defer { x, y } from "./x-and-y";
export defer { z } from "./z";

// library/x-and-y
export const x = 1;
export const y = 2;
```

it will also load/run the code for `const y = 2` (so it's not complete dead code elimination), but gives the building block to remove code if you put unrelated code in separate modules

[09:52:55.0016] <nicolo-ribaudo>
Exactly like deep imports

[09:53:14.0206] <nicolo-ribaudo>
> <@ljharb:matrix.org> so `import defer` would be to lessen the downside of importing a barrel file that did not use `export defer`?

`import defer` is not really related to barrel file

[09:53:28.0915] <nicolo-ribaudo>
It's in general for "big modules subgraphs"

[09:53:40.0275] <nicolo-ribaudo>
Even if you have a file with a single export but many dependencies, `import defer` is useful there

[09:54:00.0084] <littledan>
One thing that's important to understand is, the barrel file stuff doesn't relate to the motivation for `import defer`--they solve for totally unrelated issues, just both about loading less code

[10:14:46.0864] <littledan>
Agree with the various arguments for minimalism here, we just don't have any reason to go into this fractional stuff or BigInts, and IsSafeInteger is a good test.

[10:16:38.0985] <Michael Ficarra>
I agree with Kevin that this isn't especially confusing

[10:17:57.0970] <littledan>
 * <del>Agree with the various arguments for minimalism here, we just don't have any reason to go into this fractional stuff or BigInts, and IsSafeInteger is a good test.</del> I don't have a strong opinion about any of this and am just happy for range to happen

[10:18:06.0226] <Michael Ficarra>
is there maybe justification to have this produce its own iterator subclass that can have optimised helpers implemented on it?

[10:18:33.0888] <Michael Ficarra>
like `.drop(1e300)` could be implemented very efficiently for this special iterator

[10:19:07.0346] <bakkot>
I think `drop` and `take` are the only things which could have better implementations and I don't think it's worth doing just for those

[10:19:38.0502] <bakkot>
and engines could do this optimization anyway

[10:20:16.0703] <hax (HE Shi-Jun)>
The original proposal includes `BigInt.range()`, don't remember why it is added in first place

[10:20:25.0275] <Bradford Smith>
I might expect to be able to use `Iterator.range()` to generate unique identifiers, in which case possibly a BigInt type is desirable.

[10:21:10.0762] <hax (HE Shi-Jun)>
> <@bradfordcsmith:matrix.org> I might expect to be able to use `Iterator.range()` to generate unique identifiers, in which case possibly a BigInt type is desirable.

seems a valid use case :P

[10:21:11.0214] <Michael Ficarra>
to waldemar's point, yes, there are some editorial bugs, but nothing that's not fixable

[10:21:21.0391] <Michael Ficarra>
it hasn't passed editorial review yet

[10:21:35.0623] <shu>
> <@bradfordcsmith:matrix.org> I might expect to be able to use `Iterator.range()` to generate unique identifiers, in which case possibly a BigInt type is desirable.

oh yeah?

[10:21:56.0277] <shu>
like, give me monotonic ids starting with <large number> or something?

[10:22:19.0093] <ljharb>
i have no bigint range use cases, but "works for one kind of numeric primitive and not the others" seems like a big problem

[10:22:55.0359] <Bradford Smith>
> <@shuyuguo:matrix.org> like, give me monotonic ids starting with <large number> or something?

yes, something like that

[10:23:28.0592] <Justin Ridgewell>
Are bigints still massively slower than numbers?

[10:23:31.0141] <rbuckton>
I'd prefer it work for bigint just so I'm not having to coerce using `BigInt()` when I need to do math with other bigints.

[10:23:31.0609] <shu>
> <@ljharb:matrix.org> i have no bigint range use cases, but "works for one kind of numeric primitive and not the others" seems like a big problem

why is that a big problem?

[10:23:36.0139] <shu>
> <@jridgewell:matrix.org> Are bigints still massively slower than numbers?

haha yes

[10:23:51.0728] <danielrosenwasser>
Mathieu Hofman: can you add yourself to the notes?

[10:23:57.0368] <ljharb>
it's an inconsistency. one of those warts we'd inevitably have to make a "fill in the table" proposal for in a few years.

[10:23:59.0128] <eemeli>
Timestamps in microseconds as a use case?

[10:24:26.0548] <ljharb>
it's fine if we want to wait for that, but is there a reason why it's beneficial to defer it?

[10:24:28.0683] <shu>
> <@ljharb:matrix.org> it's an inconsistency. one of those warts we'd inevitably have to make a "fill in the table" proposal for in a few years.

not everyone shares that goal though

[10:24:53.0581] <ljharb>
that is true of most of the goals we all have :-)

[10:25:09.0283] <shu>
right, which is why i pushed back on "seems like a big problem"

[10:25:19.0072] <bakkot>
it's not that inconsistent - the Math methods do not and never will take Numbers

[10:25:23.0971] <bakkot>
 * it's not that inconsistent - the Math methods do not and never will take BigInts

[10:25:35.0052] <shu>
in any case i was given a concrete use case i found plausible

[10:25:38.0744] <bakkot>
in fact I don't think we have _anything_ that takes only Number of BigInt?

[10:25:39.0682] <shu>
so i'm happy with bigints being accepted here

[10:25:53.0572] <bakkot>
but yeah I also prefer accepting BigInt here

[10:26:13.0522] <ptomato>
> <@eemeli:mozilla.org> Timestamps in microseconds as a use case?

I think the idea was to introduce Temporal.Instant ranges for this use case in the future

[10:28:10.0892] <nicolo-ribaudo>
> <@pchimento:igalia.com> I think the idea was to introduce Temporal.Instant ranges for this use case in the future

Maybe `Iterator.range(instant1, instant2, duration)` if `range` is overloaded anyway

[10:28:15.0922] <nicolo-ribaudo>
> <@pchimento:igalia.com> I think the idea was to introduce Temporal.Instant ranges for this use case in the future

 * Maybe `Iterator.range(instant1, instant2, duration)` if `range` is overloaded anyway?

[10:28:41.0761] <Jack Works>
> <@bradfordcsmith:matrix.org> I might expect to be able to use `Iterator.range()` to generate unique identifiers, in which case possibly a BigInt type is desirable.

can you explain this use case more? I think unique id should be something like crypto.getRandomUUID()

[10:29:17.0689] <shu>
might not need to be unique

[10:29:36.0590] <ljharb>
also autoincrementing is fine sometimes, not everything has the german tank problem

[10:30:00.0346] <nicolo-ribaudo>
Python bans floats in range() right?

[10:30:46.0389] <ptomato>
right

[10:32:40.0106] <ptomato>
python's popular computing library has `numpy.arange()` which does suffer from unexpected iterations due to floating point errors, and `numpy.linspace()` which does not

[10:33:08.0960] <Jesse>
...decimal.

[10:33:58.0185] <bakkot>
I do like linspace 

[10:34:13.0086] <bakkot>
the options object does leave room for it

[10:34:57.0125] <nicolo-ribaudo>
You can just use a range of integers and .map for what Matthew is proposing, right?

[10:35:02.0238] <Michael Ficarra>
FWIW it would be nice to have extra time to iron out all the editorial issues as well

[10:35:09.0610] <Michael Ficarra>
then we can have a really solid 2.7 advancement

[10:36:23.0494] <Bradford Smith>
I'll definitely +1 this feature either with or without fractional values.

[10:36:39.0158] <bakkot>
same though I do prefer accepting fractional values

[10:36:52.0090] <bakkot>
but if left out it's not the end of the world

[10:41:01.0148] <hax (HE Shi-Jun)>
> <@bakkot:matrix.org> the options object does leave room for it

I think linspace should be a separate method?

[10:41:30.0943] <Michael Ficarra>
even 2-4x slower must still be faster than `.reduce((a, b) => a + b, -0)`

[10:43:58.0486] <hax (HE Shi-Jun)>
As the original author of range floating issue, I prefer not accepting franctional values , and change the name from`Iterator.range` to `Iterator.integers` which make it even more clear to developers üòâ 

[10:44:38.0306] <Michael Ficarra>
`intRange`

[10:46:34.0236] <hax (HE Shi-Jun)>
Do people also need `ProductExact()` ?

[10:46:51.0683] <littledan>
I can't understand the difference in precision/exactitude between precise and exact in this case... can anyone else?

[10:47:42.0675] <eemeli>
I think "precise" applies to all numbers. So `0.1 + 0.2` has a precise value, it's just not exactly `0.3`.

[10:47:45.0962] <shu>
kinda, i guess there is a notion of "low precision" vs "high precision" that's more commonly used than "low exactitude" vs "high exactitude"

[10:47:56.0832] <shu>
but in this particular case i don't really understand

[10:47:59.0640] <eemeli>
"Accurate" would be more... accurate.

[10:48:21.0363] <hax (HE Shi-Jun)>
> <@littledan:matrix.org> I can't understand the difference in precision/exactitude between precise and exact in this case... can anyone else?

It just avoid some loss and more close to exact number?

[10:48:23.0882] <littledan>
> <@eemeli:mozilla.org> I think "precise" applies to all numbers. So `0.1 + 0.2` has a precise value, it's just not exactly `0.3`.

huh? but we're starting with Numbers, not those funny things that we don't have a representation of in JS

[10:49:04.0788] <littledan>
> <@shuyuguo:matrix.org> kinda, i guess there is a notion of "low precision" vs "high precision" that's more commonly used than "low exactitude" vs "high exactitude"

OK but it's not like we have a precision arg here... it's just supposed to get the right answer

[10:49:12.0294] <littledan>
right?

[10:49:22.0826] <shu>
right, in this particular case i don't understand the difference

[10:49:41.0299] <shu>
if it were up to me i'd name it sumSlow

[10:50:13.0140] <shu>
like i would totally believe that if kevin's slides said "this is named sumPrecise, but it may give the wrong impression", someone will then say "sumExact is better"

[10:50:15.0934] <eemeli>
To be clear, I'm fine with sumExact as a least worst option.

[10:50:53.0161] <Jack Works>
> <@nicolo-ribaudo:matrix.org> Maybe `Iterator.range(instant1, instant2, duration)` if `range` is overloaded anyway?

Yes, next follow on might be adding a new Symbol.rangeTo, and then range(a, b, options) where a is an object will do the following: `yield* a[Symbol.rangeTo](b, options)`, then you can add it on Temporal, Decimal (they're not primitive now) and your own class.

[10:51:01.0101] <Jack Works>
> <@nicolo-ribaudo:matrix.org> Maybe `Iterator.range(instant1, instant2, duration)` if `range` is overloaded anyway?

 * Yes, next follow on proposal might be adding a new Symbol.rangeTo, and then range(a, b, options) where a is an object will do the following: `yield* a[Symbol.rangeTo](b, options)`, then you can add it on Temporal, Decimal (they're not primitive now) and your own class.

[10:51:01.0197] <rbuckton>
Doesn't temporal use `from` ?

[10:51:12.0861] <littledan>
what name are we considering?

[10:52:16.0817] <Bradford Smith>
So, I guess we should go with `Math.sumPreciseFrom()`?

[10:52:33.0603] <Bradford Smith>
or not...

[10:52:37.0067] <bakkot>
it sounds like we are not doing `From` based on everyone else doesn't like it

[10:52:41.0303] <bakkot>
so `sumExact` or `sumPrecise`

[10:54:29.0625] <hax (HE Shi-Jun)>
> <@shuyuguo:matrix.org> if it were up to me i'd name it sumSlow

As I understand, it is not necessarily slow.

[10:54:42.0708] <danielrosenwasser>
dminor: can you clarify your last point in the notes?

[10:54:43.0245] <shu>
yeah it is?

[10:54:48.0756] <shu>
it's necessarily slow_er_

[10:54:50.0160] <nicolo-ribaudo>
I was going to say that I dislike `From` because it currently means "I'm creating something of this type from these other values". `Iterator.from` creates an iterator, `Array.from` an array, `Object.fromEntries` an object. If we wanted this to contain from it should be on number (`Number.fromSum`), but also Number is not a collection

[10:55:23.0762] <rbuckton>
Temporal uses `from` in many places and those functions do not take iterables, so I disagree with the Michael Ficarra 's statement that "everything named from takes an iterable"

[10:56:03.0724] <Mathieu Hofman>
> <@nicolo-ribaudo:matrix.org> You can just use a range of integers and .map for what Matthew is proposing, right?

It's not ergonomic at all: `range(start * stepDivider, end * stepDivider, stepMultipler) | map(x => x / stepDivider)`

[10:56:20.0889] <rbuckton>
> <@nicolo-ribaudo:matrix.org> I was going to say that I dislike `From` because it currently means "I'm creating something of this type from these other values". `Iterator.from` creates an iterator, `Array.from` an array, `Object.fromEntries` an object. If we wanted this to contain from it should be on number (`Number.fromSum`), but also Number is not a collection

Agreed. "Foo.from" does imply "takes an iterable", it imples "make a `Foo` from these inputs"

[10:56:28.0104] <rbuckton>
> <@nicolo-ribaudo:matrix.org> I was going to say that I dislike `From` because it currently means "I'm creating something of this type from these other values". `Iterator.from` creates an iterator, `Array.from` an array, `Object.fromEntries` an object. If we wanted this to contain from it should be on number (`Number.fromSum`), but also Number is not a collection

 * Agreed. "Foo.from" does not imply "takes an iterable", it imples "make a `Foo` from these inputs"

[10:57:42.0897] <littledan>
I'm having trouble understanding why we're bothering with an optimization for an error case

[10:57:46.0107] <Michael Ficarra>
I don't think arithmetic commutativity comes into play when we're talking about throwing, which is inherently not arithmetic

[10:58:10.0356] <Michael Ficarra>
@littledan:matrix.org an iterable of Number producing a NaN is not an error case?

[10:58:45.0358] <littledan>
I think NaN is kinda usually for error cases?

[10:59:05.0953] <littledan>
I get that it's within the domain of Numbers but.... when was the last time you wanted NaN to come up for you?

[10:59:08.0733] <Michael Ficarra>
at the business logic layer, maybe, but at this data processing layer, no

[10:59:38.0109] <dminor>
I have to drop, Eemeli and Matthew Gaudet will represent SpiderMonkey for the rest of the day.

[11:00:18.0622] <littledan>
> <@michaelficarra:matrix.org> at the business logic layer, maybe, but at this data processing layer, no

obviously we need a well-defined answer, but is this going to provide a meaningful speedup meaningfully often?

[11:00:38.0045] <Michael Ficarra>
yes, iterators can yield very many values

[11:01:04.0621] <Michael Ficarra>
a multi-hours' batch could be short-circuited immediately after starting instead of waiting until the end

[11:03:16.0007] <hax (HE Shi-Jun)>
> <@shuyuguo:matrix.org> it's necessarily slow_er_

As https://en.wikipedia.org/wiki/Pairwise_summation "Pairwise summation is the default summation algorithm in NumPy[8] and the Julia technical-computing language,[9] where in both cases it was found to have comparable speed to naive summation"

[11:04:22.0688] <danielrosenwasser>
eemeli: can you add yourself to the notes doc?

[11:09:51.0346] <Justin Ridgewell>
I had to miss the presentation, but why is empty list `-0`? (no opinion, just curious)

[11:10:11.0098] <shu>
it is the identity of floating point addition

[11:10:36.0658] <Michael Ficarra>
@jridgewell:matrix.org `Object.is(-0 + -0, -0)`

[11:10:58.0835] <shu>
(while +0 + -0 = +0)

[11:11:20.0612] <Justin Ridgewell>
Why is `-0` the starting point?

[11:11:32.0340] <Justin Ridgewell>
If I‚Äôm interpreting those correctly....

[11:11:32.0664] <shu>
what does starting point mean?

[11:11:57.0197] <Justin Ridgewell>
`let sum = -0; for (const i of array) sum += i`

[11:12:22.0686] <Michael Ficarra>
so that when `array` is `[-0]` you get the correct answer

[11:17:46.0171] <Duncan MacGregor>
The equality question feels very like the question of `==` on value types in Java.

[11:19:32.0485] <bakkot>
the slides will reference project Valhalla IIRC

[11:19:38.0459] <Michael Ficarra>
value types being the ones with lowercase names?

[11:19:43.0209] <bakkot>
(i.e. value objects for java)

[11:19:59.0459] <bakkot>
https://openjdk.org/projects/valhalla/

[11:24:22.0706] <Michael Ficarra>
this presentation is so well structured üòç

[11:25:58.0649] <bakkot>
I really like the composite object approach though I would not call them "CompositeKey"

[11:27:42.0113] <bakkot>
I linked a few userland implementations here: https://github.com/tc39/proposal-record-tuple/issues/387#issuecomment-2033531920 though I am sure there are others

[11:29:02.0219] <rbuckton>
Composite keys don't seem like a solution to case-insensitive Maps. I still strongly favor equals/hash.

[11:29:56.0465] <bakkot>
I think they solve a different problem - equals/hash doesn't let me write `groupBy` with the result of my comparator being a composite key (without doing a bunch of work)

[11:29:57.0684] <ptomato>
but uniqBy without CompositeKey would cover that use case, no?

[11:30:11.0763] <rbuckton>
i.e., `new Map([], { comparer: caseInsensitiveStringComparer }`

[11:30:28.0924] <Michael Ficarra>
@rbuckton:matrix.org it works fine, Unicode has case folding for tht

[11:30:51.0739] <rbuckton>
> <@bakkot:matrix.org> I think they solve a different problem - equals/hash doesn't let me write `groupBy` with the result of my comparator being a composite key (without doing a bunch of work)

Wouldn't you just do groupBy over anything you want?

[11:31:46.0331] <rbuckton>
> <@michaelficarra:matrix.org> @rbuckton:matrix.org it works fine, Unicode has case folding for tht

It's an extra allocation, likely thrown away, for any given key comparison. equals/hash is defined once and reused

[11:32:30.0079] <bakkot>
I don't know what that means? I am asking about, for example, I have a list of { name, employer, city } objects, and I want to collect them by `{ employer, city }`. with composite key that's just `Map.groupBy(vals, x => Tuple(x.employer, x.city))`. with equals/hash there's a bunch more ceremony 

[11:33:48.0586] <rbuckton>
I have already written a `groupBy` that uses `equals`/hash`, and an equaler that already does tuple structural equality. 

[11:34:57.0949] <rbuckton>
That library also supports `[Equatable.equals](obj)` and `[Equatable.hash]()` that can be used if an equaler is not provided, so a given composite key just builds on top of that.

[11:35:54.0406] <bakkot>
sure, it can certainly be done, there's just a bunch more ceremony

[11:36:11.0494] <rbuckton>
It is far more flexible, IMO. 

[11:36:35.0816] <bakkot>
it's just different

[11:36:39.0911] <bakkot>
it solves different problems

[11:36:50.0888] <rbuckton>
Having to turn everything into a `CompositeKey` seems like a lot more ceremony to me.

[11:37:01.0391] <eemeli>
Map.p.getImprecise, anyone?

[11:37:06.0158] <rbuckton>
`CompositeKey` can be built on equals/hash, the other is not true.

[11:37:43.0443] <bakkot>
`Map.groupBy(vals, x => Tuple(x.employer, x.city))` is very close to zero ceremony

[11:37:47.0700] <bakkot>
that's exactly how I think about the problem

[11:38:02.0084] <rbuckton>
Plus, AFAIK equals/hash is how every implementation implements maps natively, it's just not exposed to user code.

[11:40:25.0551] <rbuckton>
For that case, maybe. What about `map.set(key, value)` though? You have to write `map.set(new CompositeKey(foo.a, foo.b), value)` or `map.get(new CompositeKey(foo.a, foo.b))`. With equals/hash, you can set it up once and just do `map.set(foo, value)` or `map.get(foo)`.

[11:40:54.0638] <bakkot>
but if my map is not keyed by `foo`, I don't want it to behave that way?

[11:41:01.0683] <bakkot>
I want to use a composite key for that case

[11:41:02.0171] <ljharb>
with a Map constructor hook, you could set it up once too

[11:41:16.0022] <ljharb>
 * with a Map constructor hook, you could set it up once too with composite keys

[11:41:19.0943] <rbuckton>
You can use a composite key for that case, I'd like to *not* have to use composite key for all of the other cases.

[11:41:31.0916] <Mathieu Hofman>
> <@rbuckton:matrix.org> It is far more flexible, IMO.

it's a lot more risk prone

[11:41:35.0103] <rbuckton>
> <@ljharb:matrix.org> with a Map constructor hook, you could set it up once too with composite keys

The same is true for equals/hash.

[11:41:58.0424] <ljharb>
right. which is why it's not an argument in favor of either one.

[11:42:12.0066] <rbuckton>
> <@mhofman:matrix.org> it's a lot more risk prone

It's far more efficient. If I want to write a custom collection that employs a hashtable, I'd rather have it easier to compute a hash.

[11:43:02.0144] <sffc>
For the set comparator, it seems like a prototype method `[Symbol.setCompare]` would work, and if Record/Tuple implement that function, then R&T Set/Map semantics should just work

[11:43:09.0175] <bakkot>
> <@rbuckton:matrix.org> You can use a composite key for that case, I'd like to *not* have to use composite key for all of the other cases.

right that's what I mean by "they are different"

[11:43:14.0994] <Mathieu Hofman>
JS is a high level language, I don't want low level concept like computing hashes exposed to programmer, especially if they can cause erroneous executions if mishandled

[11:43:25.0984] <bakkot>
I'm not saying that we should have composite keys _instead of_ hash/equals, just that they solve different problems

[11:45:30.0646] <bakkot>
(I am _separately_ somewhat skeptical of hash/equals because of the concerns about inconsistency, especially since that seems like it might be a bug farm in engines themselves and not just programs. but that concern is unrelated to this.)

[11:50:02.0058] <Mathieu Hofman>
> <@sffc:mozilla.org> For the set comparator, it seems like a prototype method `[Symbol.setCompare]` would work, and if Record/Tuple implement that function, then R&T Set/Map semantics should just work

That means the collection correctness is dependent on the stable behavior of its values. I want to use a collection that is resilient against misbehaving values

[11:50:28.0218] <Mathieu Hofman>
> <@sffc:mozilla.org> For the set comparator, it seems like a prototype method `[Symbol.setCompare]` would work, and if Record/Tuple implement that function, then R&T Set/Map semantics should just work

 * That means the collection correctness is dependent on the stable behavior of its values. I want the ability to create a collection that is resilient against misbehaving values

[11:55:03.0753] <Duncan MacGregor>
+1 on pretty much everything rbuckton said.

[11:58:16.0417] <rbuckton>
> <@mhofman:matrix.org> That means the collection correctness is dependent on the stable behavior of its values. I want the ability to create a collection that is resilient against misbehaving values

If you do not trust the stability of your keys, then you could use a `CompositeKey` and pay the overhead for every get/set. If you do trust the stability of your keys, equals/hash lets you avoid that overhead.

[12:00:45.0527] <rbuckton>
I have a strong preference for fast, efficient JS. `CompositeKey` overhead does not seem fast/efficient.

[12:01:19.0339] <Mathieu Hofman>
> <@rbuckton:matrix.org> If you do not trust the stability of your keys, then you could use a `CompositeKey` and pay the overhead for every get/set. If you do trust the stability of your keys, equals/hash lets you avoid that overhead.

Not if the only way is for the collection to ask the value. My answer was to sffc who was proposing that

[12:01:51.0193] <rbuckton>
equals/hash does not preclude `CompositeKey`, but rather is the building block a `CompositeKey` could be built on. It's also the building block using a `Uri` as a key could be built on too.

[12:02:37.0781] <bakkot>
It's not something you could build `CompositeKey` on because `CompositeKey` has `===` equality

[12:02:46.0586] <bakkot>
and `===` will never invoke a userland `equals`

[12:03:22.0843] <shu>
i missed that there was a configuration of the new direction that has new objects that have special ===?

[12:03:28.0265] <rbuckton>
If we could have `CompositeKey` have `===` equality, why would we not have R&T have `===` equality?

[12:03:31.0558] <shu>
that isn't any more acceptable than the R&T's overloading of ===

[12:03:51.0610] <bakkot>
> <@shuyuguo:matrix.org> i missed that there was a configuration of the new direction that has new objects that have special ===?

the CompositeKey thing he presented, with interning, which is already being done in userland

[12:03:53.0983] <littledan>
can we change indexOf just for these new objects?

[12:04:00.0738] <bakkot>
it was not one ACE advocated for

[12:04:20.0417] <shu>
> <@bakkot:matrix.org> the CompositeKey thing he presented, with interning, which is already being done in userland

tools compile away === or something?

[12:04:34.0001] <bakkot>
no I mean they do interning

[12:05:03.0311] <Ashley Claymore>
> <@littledan:matrix.org> can we change indexOf just for these new objects?

I assumed 'no', but never asked

[12:05:16.0687] <shu>
> <@bakkot:matrix.org> no I mean they do interning

oh by "===" you mean they do interning?

[12:05:40.0285] <shu>
i see, ok

[12:05:43.0547] <bakkot>
https://github.com/benjamn/immutable-tuple/blob/485b32326349cb0329c749090cebf43f8359fa12/src/tuple.js#L12-L19

[12:06:01.0997] <rbuckton>
Isn't the discussion around `CompositeKey` predicated on R&T *not* having `===` equality? I have concerns about the GC overhead associated with `CompositeKey` using something like weakmaps/maps as either `CompositeKey("a")` leaks forever, or it requires a FinalizationRegistry and the GC overhead for tracking/collection the object.

[12:06:22.0422] <littledan>
> <@rbuckton:matrix.org> Isn't the discussion around `CompositeKey` predicated on R&T *not* having `===` equality? I have concerns about the GC overhead associated with `CompositeKey` using something like weakmaps/maps as either `CompositeKey("a")` leaks forever, or it requires a FinalizationRegistry and the GC overhead for tracking/collection the object.

yes, it's all predicated on === not being supported for R&T

[12:06:31.0243] <shu>
rbuckton: that was also my confusion. the resolution is that CompositeKeys have interning semantics built in, they return deduplicated objects such that === just works like object ===, because it's literally deduplicated

[12:06:39.0950] <bakkot>
or you forbid having a `CompositeKey` that doesn't contain an object, which is what userland does

[12:06:50.0347] <rbuckton>
Interning semantics will have GC overhead

[12:06:55.0760] <shu>
yes indeedy

[12:07:35.0555] <shu>
but it's like, deterministic overhead that's always there, instead of non-deterministic overhead that engines have to tune for and hope they get it right for the largest swath of the code that runs

[12:07:35.0943] <rbuckton>
> <@bakkot:matrix.org> or you forbid having a `CompositeKey` that doesn't contain an object, which is what userland does

`CompsiteKey(obj, "a")` works, but `CompositeKey("a", "b")` does not? That seems like a very unstable design. 

[12:07:45.0699] <shu>
which is a better place to be in, but... definitely still overhead, yes

[12:07:54.0973] <Ashley Claymore>
I dropped it after presenting the slides to some other people, they felt it complicated the question I was asking

[12:08:04.0220] <Mathieu Hofman>
I believe that is NOT was was presented. `#[1] !== #[1] `

[12:08:22.0786] <rbuckton>
I'm concerned about the overhead of 1000s of `map.get(CompositeKey(a, b))` in a loop.

[12:08:34.0530] <eemeli>
I kinda like the idea of being able to do something like 
```
new Map([], { compare: 'duck' })
```
and have that "just work".

[12:08:34.0675] <Mathieu Hofman>
but when used in collections, the equality used is the one supporting R&T equality

[12:08:34.0758] <bakkot>
> <@mhofman:matrix.org> I believe that is NOT was was presented. `#[1] !== #[1] `

CompositeKey was presented, it's just not what was proposed

[12:10:49.0833] <rbuckton>
> <@eemeli:mozilla.org> I kinda like the idea of being able to do something like 
> ```
> new Map([], { compare: 'duck' })
> ```
> and have that "just work".

`@esfx/collections-hashmap` and `@esfx/equatable` does this. You can do, say:

```js
import { HashMap } from "@esfx/collections-hashmap";
import { Uri } from "./uri.js";

const map = new HashMap(undefined, { equaler: Uri.equaler });
```

where `Uri.equaler` is just an object with `{ equals(a, b), hash(obj) }`.

[12:11:35.0237] <Mathieu Hofman>
I'm confused about the discussion about `CompositeKey` here as it's not what was proposed, but presented as background / historical context. A R/T would, unlike CompositeKey, not have `===` equality.

[12:13:14.0203] <rbuckton>
I was under the impression these were discussed as possible directions to consider, with historical context as to prior discussions within TC39.

[12:14:38.0912] <Mathieu Hofman>
rbuckton: I don't want to build R&T on top of a equals / hash mechanism IF there is any way that values can influence the hashing mechanism when added to a collection I created. I am fine if the collection defers to a construction time provided config.

[12:14:45.0185] <Ashley Claymore>
I should have been more clear. I was trying to say `Key(v1, v2) === Key(v1, v2)` is good in that it doesn't introduce a new form of equality. But from what I have heard from engines re R&T and from my own research it seems difficult to make them perform well at scale, the whole app has contention on one global interning table that requires GC hooks to clean up the unused keys.


[12:15:01.0056] <Mathieu Hofman>
 * rbuckton: I don't want to build R&T on top of a equals / hash mechanism IF there is any way that values can influence the hashing mechanism at the time they're added to a collection I created. I am fine if the collection defers to a construction time provided config.

[12:15:16.0519] <Mathieu Hofman>
 * rbuckton: I don't want to build R&T on top of a equals / hash mechanism IF there is any way that values can influence the hashing mechanism or any part of the prohgram at the time they're added to a collection I created. I am fine if the collection defers to a construction time provided config.

[12:16:08.0346] <Mathieu Hofman>
 * rbuckton: I don't want to build R&T on top of a equals / hash mechanism IF there is any way that values can influence the hashing mechanism or any part of the program at the time they're added to a collection I created. I am fine if the collection defers to a construction time provided config.

[12:16:23.0327] <rbuckton>
The upside of equals/hash is that it is a known quantity. Numerous languages and runtimes use this, thus the caveats are known. 

[12:16:41.0141] <rbuckton>
A `CompositeKey` based on equals/hash doesn't require complex GC semantics.

[12:19:01.0375] <rbuckton>
If you have a native `CompositeKey` with equals/hash, you just make the "default equaler" behavior used by a `Map` have a specific case for `CompositeKey` vs `===`. But then you can make that "default equaler" an actual object from which to build other equalers from.

[12:19:04.0017] <Mathieu Hofman>
To be more clear:
`new Map([], {compare: Record.equals})` is fine, and so is `new Map([], {compare: customHashCodeThing}`, but not `new Map([], compareWithHashCode: true)` which would be assuming Records.prototype[Symbol.hashCode]`

[12:20:06.0801] <Mathieu Hofman>
 * To be more clear:
`new Map([], {compare: Record.equals})` is fine, and so is `new Map([], {compare: customHashCodeThing}`, but not `new Map([], compareWithHashCode: true)` which would be assuming looking up a `Records.prototype\[Symbol.hashCode\]\`

[12:20:15.0587] <Mathieu Hofman>
 * To be more clear:
`new Map([], {compare: Record.equals})` is fine, and so is `new Map([], {compare: customHashCodeThing}`, but not `new Map([], compareWithHashCode: true)` which would be assuming looking up a `Records.prototype[Symbol.hashCode]`

[12:21:46.0991] <Ashley Claymore>
In other plenary sessions it has come up that the language should be as close to fully deterministic as we can. e.g. not exposing a browser-sniffing API. `Object.hash` feels like it would need to be fully deterministic across engines to meet these goals.
Perhaps I have mis-read committee comments with this goal.

[12:22:56.0661] <rbuckton>
> <@mhofman:matrix.org> To be more clear:
> `new Map([], {compare: Record.equals})` is fine, and so is `new Map([], {compare: customHashCodeThing}`, but not `new Map([], compareWithHashCode: true)` which would be assuming looking up a `Records.prototype[Symbol.hashCode]`

I've experimented with something like `[Symbol.hashCode]`. In well written applications its perfectly fine and would serve most users well. If you don't trust your inputs, you could opt-out with a custom equaler that doesn't call an `@@hashCode`. That said, I'm more interested in a general purpose `{ equals, hash }` mechanism for `Map`/`Set` and various other methods that do equality checks, than i am with instance-overrideable hash codes.

[12:23:12.0520] <Ashley Claymore>
I also wonder if even string hashing is not as easy to standardize in 262 due to the spec being in wtf-16 and runtimes potentially using different encodings?

[12:32:50.0075] <Mathieu Hofman>
We don't automatically need to expose the result of the internal hashing. We could have special values for `compare`

[12:33:50.0673] <rbuckton>
> <@aclaymore:matrix.org> In other plenary sessions it has come up that the language should be as close to fully deterministic as we can. e.g. not exposing a browser-sniffing API. `Object.hash` feels like it would need to be fully deterministic across engines to meet these goals.
> Perhaps I have mis-read committee comments with this goal.

`Object.hash()` *shouldn't* be fully deterministic, at least not for strings. String hash code generators benefit from randomness as it evens out clumping due to collisions over the course of various app restarts. An implementation would also want to be able to swap from one hash algorithm to another from version to version as hash algorithms improve.

In .NET, you can control whether to use a randomized string hashing algorithm via configuration: https://learn.microsoft.com/en-us/dotnet/framework/configure-apps/file-schema/runtime/userandomizedstringhashalgorithm-element.

[12:34:20.0207] <rbuckton>
> <@mhofman:matrix.org> We don't automatically need to expose the result of the internal hashing. We could have special values for `compare`

I considered describing it as an opaque value, but you need to be able to do math on it.

[12:35:16.0223] <Mathieu Hofman>
To follow up on Ashley Claymore 's comment, I would be opposed to any new APIs to expose non determinism to the program. It's fine for these things to remain internal to the engine, but I don't want them to be observable

[12:37:46.0581] <Mathieu Hofman>
Or should I say, the new API would have to be extremely well motivated, like FR/WeakRef, but I don't think hashcode would clear that line

[12:38:12.0317] <rbuckton>
For example
```js
class Point {
  #x;
  #y;
  constructor(x, y) {
    this.#x = x;
    this.#y = y;
  }
  get x() { return this.#x; }
  get y() { return this.#y; }
  static equaler = {
    equals(a, b) {
      return #x in a && #x in b && a.#x == b.#x && a.#y == b.#y;
    },
    hash(obj) {
      let hc = Object.hash(obj.#x);
      hc = ((hc << 7) | (hc >>> 25)) ^ Object.hash(obj.#y);
      return hc;
    }
  }
}
```

[12:38:16.0030] <Mathieu Hofman>
 * Or should I say, the new API would have to be extremely well motivated and fairly self contained, like FR/WeakRef, but I don't think hashcode would clear that line

[12:38:31.0572] <rbuckton>
 * For example

```js
class Point {
  #x;
  #y;
  constructor(x, y) {
    this.#x = x;
    this.#y = y;
  }
  get x() { return this.#x; }
  get y() { return this.#y; }
  static equaler = {
    equals(a, b) {
      return #x in a && #x in b && a.#x === b.#x && a.#y === b.#y;
    },
    hash(obj) {
      let hc = Object.hash(obj.#x);
      hc = ((hc << 7) | (hc >>> 25)) ^ Object.hash(obj.#y);
      return hc;
    }
  }
}
```

[12:40:02.0241] <Mathieu Hofman>
I honestly don't understand why `hashLike(obj) { return #[obj.#x, obj.#y] }` is not an acceptable approach`. Engines are definitely capable of optimizing this

[12:40:24.0427] <Mathieu Hofman>
 * I honestly don't understand why `hashLike(obj) { return #[obj.#x, obj.#y]; }` is not an acceptable approach. Engines are definitely capable of optimizing this

[12:40:55.0573] <Mathieu Hofman>
 * I honestly don't understand why `hashLike(obj) { return #[Point, obj.#x, obj.#y]; }` is not an acceptable approach. Engines are definitely capable of optimizing this

[12:41:52.0424] <rbuckton>
Capable does not mean willing or likely to do so.

[12:43:20.0808] <rbuckton>
And that still doesn't let me write a hashtable. I need something I can use as a numeric index with good avalanche properties. Maybe 95% of users don't need this, but its a headache for the small percent that do for good reason.

[12:43:33.0007] <rbuckton>
 * And that still doesn't let me write a hashtable. I need something I can use as a numeric index with good avalanche properties. Maybe 95% of users don't need this, but its a headache for the small percent that do need it for a good reason.

[12:48:02.0971] <rbuckton>
For example, I had to do quite a bit to workaround this limitation when experimenting with the shared structs dev trial. I had a very strong need for a concurrent Map, which required implementing a hash table. It would have been far easier if I could actually generate a hash for a string or an object: https://github.com/microsoft/TypeScript/blob/shared-struct-test/src/compiler/sharing/collections/concurrentMap.ts

Yes, maybe we would want to add a `ConcurrentMap` after we add shared structs, but that's certainly not going to be in the MVP. 

[12:55:51.0531] <Mathieu Hofman>
generating a non-deterministic value from a basic value like and object or a string feels like a non starter for me. I'd claim it's not needed by 99.9999% of JS authors

[12:56:24.0171] <rbuckton>
Hash bucket lookup is approximately O(1), while a user-built collection relying on manually comparing tuples is O(n), and if you can't compare tuples using `===`, it's O(n*m) where `m` is the number of keys in the tuple. 

[13:01:49.0975] <rbuckton>
> <@mhofman:matrix.org> generating a non-deterministic value from a basic value like and object or a string feels like a non starter for me. I'd claim it's not needed by 99.9999% of JS authors

Then call the method `Object.nondeterministicHash(obj)` or `Object.randomHash(obj)` or document the non-deterministic nature on MDN. If you were an implementer that built internally used murmur3 for string hashing and found you could speed up all applications by a significant percentage by switching to xxhash64, wouldn't you do so? `Object.hash()` must be explicitly "non-deterministic" from the get-go just so anyone consuming it could reap the same benefits if a better hash algorithm comes along.

[13:02:05.0810] <rbuckton>
> <@mhofman:matrix.org> generating a non-deterministic value from a basic value like and object or a string feels like a non starter for me. I'd claim it's not needed by 99.9999% of JS authors

 * Then call the method `Object.nondeterministicHash(obj)` or `Object.randomHash(obj)` or document the non-deterministic nature on MDN. If you were an implementer that internally used murmur3 for string hashing and found you could speed up all applications by a significant percentage by switching to xxhash64, wouldn't you do so? `Object.hash()` must be explicitly "non-deterministic" from the get-go just so anyone consuming it could reap the same benefits if a better hash algorithm comes along.

[13:03:20.0984] <rbuckton>
Case in point, even if you're using the non-random string hash algorithm in .NET, `Object.GetHashCode()` is still considered to be non-deterministic as upgrading the version can change the hash algorithm to one that is more efficient.

[13:03:27.0652] <Mathieu Hofman>
I just don't think there is sufficient motivation to expose this in the language

[13:09:22.0821] <rbuckton>
I'd argue that the number of times we've discussed mechanisms for customizing equality indicates it *is* sufficient motivation. The main reason I want custom equality for Map/Set at all is related to performance. You can use them as-is as long as you're willing to sacrifice performance and memory at the cost of the overhead introduced by alternatives. I want custom `Map` equality so that I *don't* have to `.toString()` every Uri I use as a key in a `map.get()`. Forcing custom collections to operate at O(n) while native collections can have O(1) because they can cheat and do the hashtable lookup is not the answer when your algorithms are performance-critical.

[13:18:40.0627] <rbuckton>
I'm not saying that `Object.hash()` must return a number, but that you could conceivably do all the things you would need to do to implement a hash table for an alternative to be a reasonable compromise. For example, let's say we had an API like this:

```ts
interface Equaler<T> {
  equals(a: T, b: T): boolean;
  hash(a: T): opaque;
}
```
where `hash` returns an opaque value. I'd need, at a minimum, something like this as well:
```ts
declare const defaultEqualer: Equaler<unknown>;
declare function combineHash(a: opaque, b: opaque): opaque;
interface HashArray<T> {
  length: number;
  [hash: opaque]: T;
  ...
}
interface SharedHashArray<T> {
  length: number;
  [hash: opaque]: T;
  ...
}
```

to have any possibility of achieving similar perf to it being a number.

[13:18:47.0429] <Mathieu Hofman>
You can customize equality using the `hashLike` approach I suggested above. It is also optimizable by engines.

[13:19:46.0383] <Mathieu Hofman>
The combine hash is exactly what creating a R/T with your components does

[13:20:13.0774] <rbuckton>
But not for a custom collection. As I said, native `Map`/`Set` could cheat and unwrap a composite key to do a hashtable lookup for O(1), but a custom collection would be O(n) at best.

[13:21:27.0155] <rbuckton>
I think a design that ignores custom collections is too short sighted. 

[13:22:09.0308] <Mathieu Hofman>
Sorry I don't understand how your opaque hash is any different than a R/T

[13:22:39.0343] <rbuckton>
The opaque hash is just a number you can't actually see in to.

[13:22:55.0324] <rbuckton>
 * The opaque hash is just a number you can't actually see into.

[13:23:21.0962] <rbuckton>
The only reason it would be opaque is so that users can't depend on the actual value.

[13:23:40.0428] <rbuckton>
If it were a tuple, you couldn't use it as an index into an array of hash buckets.

[13:24:03.0324] <rbuckton>
If it were a number, or an opaque value that's actually just a number, then you conceivably could.

[13:24:33.0110] <rbuckton>
Numbers are just far easier to reason over since we already have `Array` and shared structs would have `SharedArray`.

[13:25:42.0475] <rbuckton>
To use a hash code efficiently, I need to be able to compare it using `===`, shift it using `<<` and `>>>`, and combine it using `^`. All of these operations are extremely fast using 32-bit integers.

[13:25:59.0563] <rbuckton>
 * To use a hash code efficiently, I need to be able to compare it using `===`, shift it using `<<` and `>>>`, combine it using `^`, and use it as the index into an array. All of these operations are extremely fast using 32-bit integers.

[13:28:16.0323] <rbuckton>
`#[a, b, c]` has no avalanche properties I can use to ensure proper distribution in a hashtable, and cannot be used as an index, so comparing keys using `#[a, b, c]` in a custom collection is at least O(n*3), since I must compare the elements of every key in the map to the elements in the provided key. It's terribly inefficient.

[13:32:43.0378] <Mathieu Hofman>
> <@rbuckton:matrix.org> If it were a tuple, you couldn't use it as an index into an array of hash buckets.

You could use it as a key in a Map, how is it different?

[13:33:00.0991] <rbuckton>
not across threads

[13:33:29.0336] <Mathieu Hofman>
if the "opaque" number value is actually observable by the program, even indirectly, it defeats the purpose of being opaque

[13:34:29.0428] <rbuckton>
And that assumes that all JS devs will only ever need `Map` and `Set`, and that there are no other collection classes JS does not implement that will ever be needed.

[13:34:47.0291] <Mathieu Hofman>
when you said opaque, I had assumed actually opaque, like a unique symbol

[13:35:05.0532] <Mathieu Hofman>
anything else is not opaque by my definition

[13:35:39.0396] <rbuckton>
I don't need it to be opaque. I'm saying the only way an opaque value would work for me is if it could have the same properties I would need from an integer hash code.

[13:35:41.0782] <Mathieu Hofman>
 * when you said opaque, I had assumed actually opaque, like a unique symbol, or empty object

[13:36:38.0780] <rbuckton>
The problem is that if it's not a 32-bit integer, it becomes a boxed value in most implementations, and those are going to be slower.

[13:49:09.0555] <rbuckton>
Let me summarize my thoughts:
- Any mechanism to customize equality for `Map` and `Set` should be done in a way that could be leveraged by a custom collection. Anything less is too short sighted.
- Using a composite key/tuple will not give me the performance characteristics I would need in a custom collection, as it would result in O(n*m) lookup time.
- Equals/hash can be employed by a hashtable in a custom collection for O(1) lookup time.
- Using a composite key/tuple would not be compatible with custom collections under shared memory multithreading, which are likely to be necessary since concurrent/synchronized collections are not part of the shared structs MVP.
- Composite keys require an allocation that is likely to be repeated for every call to `map.get`. Engines *could* optimize, but likely won't do so immediately, if ever.
- A composite key mechanism can be implemented on top of equals/hash such that a WeakMap/Map-based registry is unnecessary. equals/hash cannot be implemented on top of a composite key.


[13:51:11.0114] <rbuckton>
 * Let me summarize my thoughts:

- Any mechanism to customize equality for `Map` and `Set` should be done in a way that could be leveraged by a custom collection. Anything less is too short sighted.
- Using a composite key/tuple will not give me the performance characteristics I would need in a custom collection, as it would result in O(n\*m) lookup time.
- Equals/hash can be employed by a hashtable in a custom collection for O(1) lookup time.
- Using a composite key/tuple would not be compatible with custom collections under shared memory multithreading, which are likely to be necessary since concurrent/synchronized collections are not part of the shared structs MVP.
- Composite keys require an allocation that is likely to be repeated for every call to `map.get`. Engines _could_ optimize, but likely won't do so immediately, if ever.
- A composite key mechanism can be implemented on top of equals/hash such that a WeakMap/Map-based registry is unnecessary. equals/hash cannot be implemented on top of a composite key.
- Equals/hash can use 32-bit integers, `<<`, `>>>` and `^`, which are all already fast and optimized. Opaque values require boxing, making them slow (see bigint performance as an example)

[13:52:37.0428] <Mathieu Hofman>
I'm saying that any value that is a source of observable non determinism does not seem sufficiently motivated for a "keying" mechanism when there are alternatives that cover most of the use cases except performance, which can be optimized, or shared memory, which is a hypothetical future, and could have its own collections API. JS is a high level language that does not expose low level / internal details of its objects or memory layout. exposing hash code would change that

[13:54:48.0532] <Ashley Claymore>
> Composite keys require an allocation that is likely to be repeated for every call to map.get. Engines could optimize, but likely won't do so immediately, if ever.
The idea with R&T is that, being objects and arrays. In many cases they are the data structure, so there is no extra allocation for these cases

[13:54:57.0037] <Ashley Claymore>
 * > Composite keys require an allocation that is likely to be repeated for every call to map.get. Engines could optimize, but likely won't do so immediately, if ever.

The idea with R&T is that, being objects and arrays. In many cases they are the data structure, so there is no extra allocation for these cases

[13:56:17.0493] <rbuckton>
As I've discovered while discussing array iterator performance, "can be optimized" isn't a useful metric. Implementations won't optimize unless they have very good reason to. Array destructuring has been around for ~9 years and still isn't optimized.

[13:59:13.0053] <rbuckton>
> <@aclaymore:matrix.org> > Composite keys require an allocation that is likely to be repeated for every call to map.get. Engines could optimize, but likely won't do so immediately, if ever.
> 
> The idea with R&T is that, being objects and arrays. In many cases they are the data structure, so there is no extra allocation for these cases

@bakkot's example in matrix earlier shows this to not be true. The keys are often a subset of the data structure, and will very likely be generated on the fly.

[13:59:17.0855] <Ashley Claymore>
If the data model of the application is already using R&T. Inserting these into a map could be the fastest case. Because all the hashing and equality operations are entirely native, with zero entry into userland minimizing guards and allowing JIT.

[13:59:52.0082] <Ashley Claymore>
>  The keys are often a subset of the data structure
If this really is common, then apps could keep those parts of the data structure seperate

[13:59:56.0813] <Ashley Claymore>
 * > The keys are often a subset of the data structure

If this really is common, then apps could keep those parts of the data structure seperatee

[14:00:01.0528] <Ashley Claymore>
 * > The keys are often a subset of the data structure

If this really is common, then apps could keep those parts of the data structure seperate

[14:00:10.0433] <rbuckton>
> <@aclaymore:matrix.org> If the data model of the application is already using R&T. Inserting these into a map could be the fastest case. Because all the hashing and equality operations are entirely native, with zero entry into userland minimizing guards and allowing JIT.

You're only proving my point. `Map` and `Set` can only have O(1) performance for a tuple as a composite key if they use equals/hash internally. Custom collections cannot do the same.

[14:00:36.0340] <Mathieu Hofman>
Custom collections can use Map/Set internally

[14:00:57.0804] <Mathieu Hofman>
 * Custom collections can use Map/Set internally for the vast majority of custom use cases

[14:00:58.0993] <Ashley Claymore>
Yes. I said earlier. The implementations must use hash + equals at some layer. I 100% agree that the pattern is efficent

[14:01:01.0993] <rbuckton>
custom collections aren't an ephemeral thing, there is production code that uses them. The perf hit is likely the only reason they aren't used more.

[14:01:38.0881] <Ashley Claymore>
The custom collections I've needed were wrappers around Maps

[14:01:56.0511] <Ashley Claymore>
I'd be interested in hearing about other cases. I'm familiar with the ConcurrentMap one.

[14:07:58.0577] <rbuckton>
> <@aclaymore:matrix.org> The custom collections I've needed were wrappers around Maps

This is often the case, but these are often still inefficient. You often have to do some type of conversion for every `get`/`set`, which can result in unnecessary allocations. You could build a custom map that does case insensitive string comparisons on keys by passing them through a case folding algorithm, but that's terribly inefficient. For a case insensitive comparison, you might use case folding on the string to compare, but then you're also producing another string in memory. If you want to preserve the input key as written, you have to store both the original key and value as the map entry, resulting in another allocation and duplication, plus the need to wrap `keys()`, `values()`, etc. This is all unnecessary overhead.

[14:09:47.0851] <Ashley Claymore>
Gotcha. That matches my understanding. It's not that lots of custom collections can't be built, but they will need to do more allocations.

[14:11:48.0467] <rbuckton>
> <@aclaymore:matrix.org> Gotcha. That matches my understanding. It's not that lots of custom collections can't be built, but they will need to do more allocations.

Map/Set wrappers can be built with allocation overhead, but only if their keys are easily translated to something that works as an existing key. Complex objects and up requiring O(n)

[14:12:51.0128] <rbuckton>
Even if you are using weakmap/map registries to ensure a composite key has the same identity, that's *still* O(n) if you're writing `map.get(CompositeKey(a, b))`. You're just paying the O(n) cost walking the registry.

[14:13:34.0450] <rbuckton>
i.e., for n steps, you're doing an O(1) operation for each step.

[14:13:44.0773] <Ashley Claymore>
what is n here?

[14:13:52.0855] <rbuckton>
n is the number of elements in the composite key.

[14:14:12.0420] <Ashley Claymore>
ok. I thought you were referring to collection size and got confused

[14:14:17.0041] <rbuckton>
https://docs.google.com/presentation/d/1JfChmW8tQ2_mrFDynosNqa1tjJ2j-qX6WoKm8vc_tkY/edit#slide=id.g2c6eebea946_0_40

[14:14:38.0673] <rbuckton>
Sorry, I should have said m instead of n for that case.

[14:15:56.0824] <rbuckton>
> <@aclaymore:matrix.org> Gotcha. That matches my understanding. It's not that lots of custom collections can't be built, but they will need to do more allocations.

 * Map/Set wrappers can be built with allocation overhead, but only if their keys are easily translated to something that works as an existing key. Complex objects end up requiring O(n)

[14:17:37.0348] <littledan>
> <@rbuckton:matrix.org> Let me summarize my thoughts:
> 
> - Any mechanism to customize equality for `Map` and `Set` should be done in a way that could be leveraged by a custom collection. Anything less is too short sighted.
> - Using a composite key/tuple will not give me the performance characteristics I would need in a custom collection, as it would result in O(n\*m) lookup time.
> - Equals/hash can be employed by a hashtable in a custom collection for O(1) lookup time.
> - Using a composite key/tuple would not be compatible with custom collections under shared memory multithreading, which are likely to be necessary since concurrent/synchronized collections are not part of the shared structs MVP.
> - Composite keys require an allocation that is likely to be repeated for every call to `map.get`. Engines _could_ optimize, but likely won't do so immediately, if ever.
> - A composite key mechanism can be implemented on top of equals/hash such that a WeakMap/Map-based registry is unnecessary. equals/hash cannot be implemented on top of a composite key.
> - Equals/hash can use 32-bit integers, `<<`, `>>>` and `^`, which are all already fast and optimized. Opaque values require boxing, making them slow (see bigint performance as an example)

we actually added Map and Set as built-ins without having a way that what they do could be done in a custom collection. Of course it would be nice to support efficient maps defined in JS if possible given all of the other goals and constraints, but I don't see why it makes sense to say that no advances should be made for Map and Set without managing to support this other goal.

[14:18:40.0207] <littledan>
the composite-ness of composite keys or R&T doesn't actually depend on any new built-in thing, but identity hashcodes continue to not be exposed

[14:20:59.0554] <rbuckton>
> <@littledan:matrix.org> we actually added Map and Set as built-ins without having a way that what they do could be done in a custom collection. Of course it would be nice to support efficient maps defined in JS if possible given all of the other goals and constraints, but I don't see why it makes sense to say that no advances should be made for Map and Set without managing to support this other goal.

We did, and this has continued to come up regularly since. I'm not opposed to things that make `Map` and `Set` more efficient. I'm concerned with choosing an API design that caters to native maps and sets that could never be efficiently implemented in a custom collection. We either end up never improving the story for custom collections, or end up with two independent mechanisms for customizing equality.

[14:22:49.0391] <rbuckton>
A composite key that uses a weakmap registry just to ensure reference identity for equivalent keys is entirely unnecessary with hash/equals. If we were to then implement hash/equals to improve the custom collection story, then composite keys become an evolutionary dead end for the language.

[14:23:40.0314] <littledan>
Is anyone defending CompositeKey?

[14:24:00.0251] <littledan>
Object-based R&T seems like a cleaner mechanism and doesn't do anything which should make things harder for custom collections, I think

[14:24:25.0664] <bakkot>
I'm not sure what distinction between CompositeKey and object-based R&T you're drawing

[14:24:29.0103] <rbuckton>
How is object-based R&T not a composite key?

[14:25:05.0210] <rbuckton>
The distinction I would make would be between a WeakMap-registry based composite key, or a Map/Set privileged CompositeKey.

[14:27:55.0096] <rbuckton>
A Map/Set-privileged CompositeKey has a way forward to equals/hash, but then why not have equals/hash instead (or at the same time).

[14:29:48.0437] <littledan>
> <@bakkot:matrix.org> I'm not sure what distinction between CompositeKey and object-based R&T you're drawing

well, the basic version of R&T that we were discussing is, there isn't support for being keys in WeakMap, so the whole registry thing just goes away

[14:30:01.0835] <littledan>
and there's no support for ===

[14:30:18.0493] <littledan>
I guess the registry was more for ===; WeakMap doesn't actually need it

[14:31:09.0816] <littledan>
so I guess you're calling this Map/Set privileged? But I don't see what Map/Set are doing that other collections couldn't also do

[14:32:18.0237] <littledan>
> <@rbuckton:matrix.org> A Map/Set-privileged CompositeKey has a way forward to equals/hash, but then why not have equals/hash instead (or at the same time).

This is something I have trouble understanding. Even if we do want to generalize to hash, the question of "why not instead" was answered--you want a nice default mechanism for the normal case, as other languages tend to have

[14:32:18.0888] <rbuckton>
I'd also like more details from the folks that are concerned about non-determinism as to why that should matter. It would be guaranteed to be deterministic so long as the app/browser is executing. Assuming no string-random-hash algorithm at the outset, the only thing that would change the hash result would probably be upgrading the browser as a newer runtime could choose a more efficient algorithm.

[14:32:46.0987] <bakkot>
my preferred approach is to allow composite objects (i.e. interned objects, that give you `===`) as keys in WeakMaps iff they contain at least one thing which could itself be in a WeakMap, and to introduce a `canBeWeaklyHeld` predicate so that's easier to determine.

[14:32:54.0591] <littledan>
why not at the same time was also answered: because there is not consensus to expose hashcodes, due to interop risk

[14:33:32.0907] <littledan>
so I guess you want more details... what do you mean by details?

[14:33:49.0191] <rbuckton>
> <@littledan:matrix.org> so I guess you're calling this Map/Set privileged? But I don't see what Map/Set are doing that other collections couldn't also do

No, Map/Set privileged would mean a Map would treat a CompositeKey as a special value and essentially do equals/hash natively. Without runtime support for equals/hash, a custom collection cannot do the same.

[14:34:01.0340] <Mathieu Hofman>
> if you're writing `map.get(CompositeKey(a, b))`. You're just paying the O(n) cost walking the registry.

I do not understand. How is it `O(n)` if there is a Map that supports a native composite keying ?

[14:34:36.0176] <rbuckton>
> <@littledan:matrix.org> This is something I have trouble understanding. Even if we do want to generalize to hash, the question of "why not instead" was answered--you want a nice default mechanism for the normal case, as other languages tend to have

Other languages tend to have equal/hash, with a few built-in equalers you can readily reference. I would certainly want those as well.

[14:34:41.0505] <littledan>
> <@rbuckton:matrix.org> No, Map/Set privileged would mean a Map would treat a CompositeKey as a special value and essentially do equals/hash natively. Without runtime support for equals/hash, a custom collection cannot do the same.

hmm, what kind of custom collection are you imagining? I guess I'm not picturing it properly

[14:35:12.0407] <rbuckton>
> <@mhofman:matrix.org> > if you're writing `map.get(CompositeKey(a, b))`. You're just paying the O(n) cost walking the registry.
> 
> I do not understand. How is it `O(n)` if there is a Map that supports a native composite keying ?

That was in reference to the WeakMap registry mechanism on https://docs.google.com/presentation/d/1JfChmW8tQ2_mrFDynosNqa1tjJ2j-qX6WoKm8vc_tkY/edit#slide=id.g2c6eebea946_0_40

[14:40:28.0160] <Mathieu Hofman>
> <@rbuckton:matrix.org> I'd also like more details from the folks that are concerned about non-determinism as to why that should matter. It would be guaranteed to be deterministic so long as the app/browser is executing. Assuming no string-random-hash algorithm at the outset, the only thing that would change the hash result would probably be upgrading the browser as a newer runtime could choose a more efficient algorithm.

I want a language where I can deterministically reproduce execution. If you exclude I/O (which encompasses Date.now and Math.random), we currently have that language

[14:41:29.0085] <rbuckton>
> <@littledan:matrix.org> hmm, what kind of custom collection are you imagining? I guess I'm not picturing it properly

https://github.com/esfx/esfx/blob/main/packages/collections-hashmap/src/index.ts, though its essentially just a `Map` that takes an `{ equaler }` option, as I'm suggesting.
https://github.com/microsoft/TypeScript/blob/shared-struct-test/src/compiler/sharing/collections/concurrentMap.ts, which is a lock-free concurrent map that cannot use `Map` as a backing store.
https://github.com/microsoft/TypeScript/blob/shared-struct-test/src/compiler/sharing/collections/sharedMap.ts, which is a coarse-grained synchronized map.
to name a few. In other languages you're likely to see custom collections where specific semantics for get/set are necessary, such as with observable collections in .NET.

[14:44:23.0678] <rbuckton>
> <@mhofman:matrix.org> I want a language where I can deterministically reproduce execution. If you exclude I/O (which encompasses Date.now and Math.random), we currently have that language

But for what purpose is this important? Is it for testing? If you're going to exclude `Date.now` and `Math.random`, why would you not exclude `Object.hash`? Could an implementation not have a `--hash-algorithm=...` flag to ensure a stable hash algorithm for tests?

[14:45:25.0011] <rbuckton>
If it's for security, wouldn't a randomized Object.hash be preferred over a deterministic one?

[14:46:22.0153] <rbuckton>
Are there any "implementation defined" behaviors you also have to discount? `Object.hash` would essentially be implementation defined.

[14:48:16.0078] <Mathieu Hofman>
> <@rbuckton:matrix.org> But for what purpose is this important? Is it for testing? If you're going to exclude `Date.now` and `Math.random`, why would you not exclude `Object.hash`? Could an implementation not have a `--hash-algorithm=...` flag to ensure a stable hash algorithm for tests?

We actually use this determinism for replay of program execution, sometimes across engines. Yes we could remove, but then it increases the difference with what programs may expect being in the language.

[14:48:37.0197] <rbuckton>
There's also the possibility we could define hashing as `Object.hash(obj, algorithm?)` where you can optionally specify `"stable"` or `"fast"`.

[14:49:15.0376] <rbuckton>
 * There's also the possibility we could define hashing as `Object.hash(obj, algorithm?)` where you can optionally specify `"stable"` or `"fast"` (or similar).

[14:50:10.0893] <rbuckton>
> <@mhofman:matrix.org> We actually use this determinism for replay of program execution, sometimes across engines. Yes we could remove, but then it increases the difference with what programs may expect being in the language.

And how does this differ from the unique reference identity that a CompositeKey might have at runtime?

[14:52:04.0943] <Mathieu Hofman>
> <@rbuckton:matrix.org> And how does this differ from the unique reference identity that a CompositeKey might have at runtime?

all usages of such unique identity would be deterministic.

[14:52:06.0796] <rbuckton>
It should be clearly called out in documentation that `Object.hash()` is not stable across application restarts and shouldn't be serialized. I would expect that code that respects that would work just fine when replaying execution.

[14:52:19.0197] <rbuckton>
It isn't deterministic.

[14:52:28.0293] <Mathieu Hofman>
how isn't it?

[14:52:47.0712] <Mathieu Hofman>
 * how isn't it? observably ?

[14:52:53.0638] <rbuckton>
It's unobservably non-deterministic. An object reference at runtime can exist in a different memory address each time you execute.

[14:53:23.0911] <Mathieu Hofman>
sure but I don't care about internals of the engine that are not observable

[14:53:33.0517] <rbuckton>
If your code treats a hash as unobservably non-deterministic, there is no difference.

[14:53:54.0575] <Mathieu Hofman>
it's like saying a JS object representation may live at a different pointer, that is just not relevant

[14:53:57.0959] <rbuckton>
The problem is that you can't make a hash code opaque without severely impacting the performance.

[14:54:27.0287] <rbuckton>
And the whole point is the performance.

[14:54:53.0789] <Mathieu Hofman>
I care about what the language exposes, that it not allow JS program to have non deterministic behaviors. I do not control the programs that run in my environment

[14:55:46.0870] <rbuckton>
JS allows programs to have non-deterministic behaviors, hence Date.now(), Math.random(). You can only make that assertion about a subset of the language.

[14:57:20.0452] <rbuckton>
Would control over the algorithm assuage that concern? Be it that from a CLI option or an option to a ShadowRealm, or an optional argument to `Object.hash()`?

[14:57:38.0121] <Mathieu Hofman>
right, and any further non-deterministic behaviors would IMO have to be extremely well motivated, and I am not seeing that from hashCode

[15:13:34.0522] <rbuckton>
I would find a custom equality solution that cannot be implemented efficiently in a pure-JS collection to be a serious design flaw in the language. If Map/Set have privileged support for a composite key, that will end up poisoning other APIs over time. It will inevitably be reused by `groupBy` and `distinct`, or possibly a future `join`/`crossJoin`/`leftJoin` for iterators. We will move further and further away from the ability for the runtime to evolve in userland as no userland implementation could have the same performance characteristics. And we _regularly_ suggest that some proposals instead evolve in userland.

[15:14:55.0068] <rbuckton>
I'd like to point out one specific bit. `Object.hash()` is essentially deterministic for everything *except* strings. The only non-determinism in strings would be if a more efficient hashing algorithm were to come along.

[15:18:16.0247] <rbuckton>
It's possible that we could handle that case with a `subtle`-like  API. Get consensus on a base algorithm for string hashing, and allow users to use a faster algorithm as it comes along. For example, were `Object.hash` to use `mumur3` by default, we could later support xxhash via `Object.hash.xxhash32` or `Object.hash(v, "xxhash32")`.

[15:18:24.0671] <rbuckton>
 * It's possible that we could handle that case with a `subtle`-like  API. Get consensus on a base algorithm for string hashing, and allow users to use a faster algorithm as it comes along. For example, were `Object.hash` to use `mumur3` by default, we could later support xxhash via `Object.hash.xxhash32()` or `Object.hash(v, "xxhash32")`.

[15:20:43.0522] <rbuckton>
Then the program remains deterministic. If randomized string hashing becomes important, make that an option but add that narrow bit to the set of things you don't support if you want determinism instead of throwing out the whole feature.

