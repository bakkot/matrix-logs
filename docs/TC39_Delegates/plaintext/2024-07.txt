2024-07-01
[09:11:20.0025] <Chris de Almeida>
reviewers need write access if you want the green check mark / meet the requirements for reviewer merge approval if desired

[10:40:21.0294] <Rob Palmer>
The interest survey for TC39 Plenary in Tokyo in October is posted üéâ

- [Interest Survey link](https://github.com/tc39/Reflector/issues/534) üáØüáµ

Please respond by Tuesday 9th July. It only takes ~45s to complete.

[10:40:44.0653] <Rob Palmer>
* The interest survey for TC39 Plenary in Tokyo in October is posted üéâ
Interest Survey link üáØüáµ
Please respond by Tuesday 9th July. It only takes ~45s to complete.


[10:41:15.0849] <Rob Palmer>
* The interest survey for TC39 Plenary in Tokyo in October is posted üéâ

- [Interest Survey link](https://github.com/tc39/Reflector/issues/534) üáØüáµ

Please respond by Tuesday 9th July. It only takes ~45s to complete.


2024-07-05
[20:38:47.0429] <bakkot>
not immediately relevant to JS as a language, but the JS promise integration for wasm is an interesting project worth reading about I think https://v8.dev/blog/jspi 

[00:02:43.0671] <Rob Palmer>
This looks like automatic conditional `await` of exported Wasm functions without user intervention. Meaning the JS caller does not need to be an async function, and calls the Wasm function as if it were sync.

If this is true, does it means that we have solved JS sync functions calling JS async function in a sync manner? Because you just need to insert a thin layer of Wasm between them.

[00:23:03.0718] <nicolo-ribaudo>
You still need to await the Wasm function on the JS side. It's implicit only on Wasm.

See `promise_update` in https://github.com/WebAssembly/js-promise-integration/blob/main/proposals/js-promise-integration/Overview.md

[00:23:17.0059] <nicolo-ribaudo>
* You still need to await the Wasm function on the JS side. It's implicit only in Wasm.
See promise_update in https://github.com/WebAssembly/js-promise-integration/blob/main/proposals/js-promise-integration/Overview.md


[08:45:40.0252] <Rob Palmer>
The interest survey for TC39 Plenary in Tokyo in October is posted  üéâ

- [Interest Survey link](https://github.com/tc39/Reflector/issues/534) üáØüáµ

Of 25 replies we have 19 people categorized as likely or certain - which is great progress.  Please respond by Tuesday 9th July. It only takes ~45s to complete.


2024-07-08
[08:18:33.0303] <mgaudet>
I was sad to miss Jaakko J√§rvi's talk at the TG5 meeting before Helsinki (https://github.com/tc39/Reflector/issues/528) -- is there any slides/notes from there that I could follow up with? 

[08:21:32.0137] <Michael Ficarra>
@mgaudet:mozilla.org There were slides, and you'd probably be interested in them. You should send an email to his university email (jaakko.jarvi@utu.fi) for them. The notes are... very light: https://github.com/tc39/tg5/pull/10/files

[08:23:29.0456] <mgaudet>
Thank you for the pointers! 

[10:54:57.0299] <Mikhail Barash>
> <@mgaudet:mozilla.org> I was sad to miss Jaakko J√§rvi's talk at the TG5 meeting before Helsinki (https://github.com/tc39/Reflector/issues/528) -- is there any slides/notes from there that I could follow up with? 

I‚Äôll ask Jaakko to share the slides 

[10:55:10.0315] <mgaudet>
(I sent him an email already too :) ) 

[10:56:48.0345] <Mikhail Barash>
> <@mikbar-uib:matrix.org> I‚Äôll ask Jaakko to share the slides 

You mean the C++ talk? Or the slides on HotDrink?

[10:56:53.0951] <mgaudet>
the C_

[10:56:58.0528] <mgaudet>
 * the C++ talk 

[11:07:09.0996] <Mikhail Barash>
> <@michaelficarra:matrix.org> @mgaudet:mozilla.org There were slides, and you'd probably be interested in them. You should send an email to his university email (jaakko.jarvi@utu.fi) for them. The notes are... very light: https://github.com/tc39/tg5/pull/10/files

notes were not taken during Jaakko's talk on C++, as that part of the TG5 Workshop wasn't formally under Ecma's IPR policy...


2024-07-11
[03:34:51.0060] <Rob Palmer>
Hello delegates,

The TC39 Plenary meeting in Tokyo in October is [confirmed](https://github.com/tc39/Reflector/issues/534#issuecomment-2222579237) üéâ

The invite will be posted shortly.


2024-07-14
[14:23:25.0485] <ljharb>
are there any hotel recs for Tokyo yet? (also a matrix channel for attending delegates?)

[15:36:45.0869] <Rob Palmer>
Not yet. I am working on it. 


2024-07-17
[22:35:38.0874] <Ashley Claymore>
https://workspaceupdates.googleblog.com/2024/07/import-and-export-markdown-in-google-docs.html?m=1
üëÄ we might be able to stop fighting docs when taking notes and use actual bullet points 


2024-07-19
[09:39:36.0296] <Chris de Almeida>
We have passed the agenda deadline, but please add any late-breaking items you may have.

Please indicate on the agenda if there is any possibility that you will ask for stage advancement.

Also, please add any schedule constraints as soon as possible.


2024-07-26
[09:14:04.0758] <Rob Palmer>
Tokyo invite for October is posted:  https://github.com/tc39/Reflector/issues/537

[14:51:39.0165] <Chris de Almeida>
Draft schedule is up:
https://hackmd.io/6dSbhC_RRBuR0-8vZDh7Mg?view


2024-07-27
[06:50:02.0087] <nicolo-ribaudo>
> <@softwarechris:matrix.org> Draft schedule is up:
> https://hackmd.io/6dSbhC_RRBuR0-8vZDh7Mg?view

Nice we get a whole free day


2024-07-29
[08:59:09.0806] <shu>
it's T-1 hours and still no VC link?

[09:14:10.0653] <Michael Ficarra>
@shuyuguo:matrix.org VC link is up now

[09:19:27.0646] <snek>
we have to sign into webex?

[09:19:44.0150] <Chris de Almeida>
 * Draft schedule is up:
https://github.com/tc39/Reflector/issues/536

[09:19:51.0543] <Chris de Almeida>
no

[09:21:06.0084] <snek>
oh i see. the screen saying sign in with existing account got me üòÑ

[09:22:55.0071] <Chris de Almeida>
and you don't have to use the app either -- you can use browser 

[09:48:45.0327] <Rob Palmer>
The meeting will begin in 11 minutes.  There are seven of us in the call now.

[09:48:58.0636] <Aki>
i'm here! hi!

[09:49:09.0591] <Aki>
i'm in the self-imposed lobby bc i'm on the phone

[09:49:43.0302] <Rob Palmer>
Is the lobby music good?  Do you need any any help progressing?

[09:50:17.0082] <Aki>
lol thank you webex, i noticed: https://snaps.akiro.se/2407_ua0hr.jpg

[09:50:59.0140] <snek>
could just have the meeting in the lobby

[09:57:11.0856] <Rob Palmer>
3 minutes... encounting

[09:57:46.0769] <Aki>
_encounting_ ?

[09:58:53.0979] <Rob Palmer>
(I will find you the relevant movie clip soon)

[10:03:41.0690] <snek>
rob you're roboting a lot

[10:04:34.0825] <snek>
 maybe turn your video off?

[10:10:18.0185] <Rob Palmer>
I am getting a new router delivered tomorrow.

[10:17:09.0413] <shu>
my webex cuts out for like 5s every 2 mins or so

[10:17:22.0991] <shu>
i wonder if it's a web version problem or a corp wifi problem...

[10:17:23.0999] <jkup>
Wow 4 new members üöÄ

[10:18:33.0982] <snek>
i think its a web version problem

[10:20:05.0012] <shu>
i don't want to install the native client but all right

[10:40:35.0160] <kriskowal>
But we can say, Welcome Back *Editor* Ben.

[10:41:07.0699] <Michael Ficarra>
Chip had me in the first half

[10:41:31.0078] <shu>
i got a new coin you gotta hear about then

[10:52:33.0228] <nicolo-ribaudo>
fomo

[10:54:52.0541] <nicolo-ribaudo>
I wanted to say something funny but my mic is not working

[10:54:57.0383] <nicolo-ribaudo>
Thanks everybody!

[10:55:15.0149] <nicolo-ribaudo>
Somebody say that I say thanks :P

[11:13:11.0455] <peetk>
should there be a `String.prototype.chars` for when you really do want to iterate over a string's characters

[11:13:52.0376] <bakkot>
"characters" is a wildly overloaded term

[11:14:05.0275] <bakkot>
there should be a `String.prototype.codepoints` to iterate over a string's codepoints

[11:14:24.0889] <bakkot>
I'm less convinced of a `.graphemes` because that's a 402 thing but it could perhaps be done

[11:14:51.0478] <bakkot>
I am not sure there's any use cases for a `.codeunits` but if you have a strong use case that could be done as well

[11:15:09.0875] <snek>
my brain assumed it would be `.values`

[11:15:27.0411] <snek>
but i guess [Symbol.iterator]() is a better way to spell that

[11:16:58.0301] <peetk>
yea mb i meant codepoints

[11:24:27.0152] <nicolo-ribaudo>
My mic keeps not working in webex even with different browsers and after rebooting üò≠

[11:28:04.0906] <nicolo-ribaudo>
Oh it works on my ipad

[11:28:06.0444] <nicolo-ribaudo>
Good

[11:28:44.0858] <keith_miller>
When we decide that we want to change the behavior of spec operations like `toFixed` do we comment or rename them to say that they're legacy?

[11:29:47.0166] <keith_miller>
If we don't, would it be worthwhile to do that so we don't accidentally slip in new uses in the future? Or we could have a spec linter rule, idk if such a tool exists?

[11:30:33.0844] <bakkot>
yeah, probably we should rename the existing ones and add new stricter ones

[11:30:42.0416] <bakkot>
or add a "looseness" parameter, I guess

[11:32:10.0572] <littledan>
Are there other changes that we would make to Temporal if we wanted to apply all the conventions?

[11:32:21.0792] <bakkot>
not doing any coercions at all :)

[11:32:29.0498] <bakkot>
which would save a lot of tests, among other things

[11:32:44.0530] <littledan>
I meant for the conventions that we already adopted

[11:32:56.0039] <bakkot>
we already adopted "don't do any coercions"

[11:33:03.0692] <littledan>
Oh right

[11:33:19.0204] <littledan>
I am in favor of applying this to Temporal

[11:34:08.0148] <littledan>
I think it is much more likely that we can apply this change to 402.

[11:34:22.0023] <littledan>
We aren‚Äôt talking about 262 overall, just those three methods

[11:35:27.0453] <ptomato>
FWIW for Temporal.Duration we already rejected non-integral inputs because of people putting in values like `Temporal.Duration.from({ hours: 1.5 })` 

[11:37:28.0463] <ptomato>
I'm open to going back and changing other things like `roundingIncrement`, `fractionalSecondDigits`, and `Temporal.PlainDate.from({ year: 2024.5, month: 7.5, day: 29.5 })` to reject non-integral inputs but I'd like us to explicitly approve that now, rather than me coming back to a following meeting with a PR

[11:38:23.0817] <littledan>
> <@pchimento:igalia.com> I'm open to going back and changing other things like `roundingIncrement`, `fractionalSecondDigits`, and `Temporal.PlainDate.from({ year: 2024.5, month: 7.5, day: 29.5 })` to reject non-integral inputs but I'd like us to explicitly approve that now, rather than me coming back to a following meeting with a PR

What about the other conventions?

[11:38:54.0222] <ptomato>
I don't know off the top of my head how much deviation there is from the other conventions, I'd have to check

[11:39:14.0988] <rbuckton>
IMO, it makes sense that year, month, and day require integral inputs, but not hour/minute/second. Given one of the goals of Temporal is to make date and time math easier, not being able to write `Temporal.Duration.from({ hours: 1.5 })` is unfortunate. 

[11:41:25.0193] <ptomato>
should `Temporal.Duration.from({ hours: 1.15 })` be 1.15 hours or 1.1499999999999999112 hours? those are distinct nanosecond values

[11:41:57.0556] <bakkot>
> <@littledan:matrix.org> What about the other conventions?

Are there any? Other than the new strings-aren't-iterable one I guess. https://github.com/tc39/how-we-work/blob/main/normative-conventions.md

[11:42:46.0006] <littledan>
Well I was wondering if ptomato had an opinion on the ‚Äúnot coercing at all‚Äù one with respect to Temporal

[11:43:05.0143] <rbuckton>
I regularly want to be able to easily scale a duration to implement backoff, and there's already no convenient way to scale a fixed duration (e.g., hours and smaller). 

[11:44:11.0491] <ptomato>
> <@littledan:matrix.org> Well I was wondering if ptomato had an opinion on the ‚Äúnot coercing at all‚Äù one with respect to Temporal

I don't have much of an opinion, but what I don't want is to have to come back to the next meeting with a PR

[11:45:32.0438] <littledan>
> <@pchimento:igalia.com> I don't have much of an opinion, but what I don't want is to have to come back to the next meeting with a PR

I agree, we should be able to agree on the conclusion in principle and then you should just be able to land it with some async review

[11:45:36.0539] <rbuckton>
for backoff I'm more likely to convert a `Duration` input into ms or ns via `total` and just work with the single unit that I can scale appropriately.

[11:46:16.0165] <littledan>
Rbuckton: you are making a very different feature request from this coercion discussion. Probably this is best for the temporal v2 bucket

[11:47:05.0737] <ptomato>
rbuckton: we considered a `Temporal.Duration.prototype.multiply` at one point but decided it was out of scope. if you have an idea for how it should work, could you open an issue on https://github.com/js-temporal/proposal-temporal-v2/? I think the use case would be helpful

[11:47:35.0296] <rbuckton>
> <@littledan:matrix.org> Rbuckton: you are making a very different feature request from this coercion discussion. Probably this is best for the temporal v2 bucket

Perhaps. It started as commentary related to the statement that Temporal rejects non-integral values.

[11:48:11.0154] <ptomato>
oh actually we already have one: https://github.com/js-temporal/proposal-temporal-v2/issues/7

[11:51:38.0985] <bakkot>
littledan ptomato this meeting has some extra time if you want to put together a last-minute item for dropping coercion from temporal, though it is very far past the deadline so it would need to be conditional approval

[11:55:15.0450] <littledan>
Why not stage 4 today for import attributes?

[11:55:47.0656] <littledan>
> <@bakkot:matrix.org> littledan ptomato this meeting has some extra time if you want to put together a last-minute item for dropping coercion from temporal, though it is very far past the deadline so it would need to be conditional approval

Conditional on what?

[11:57:06.0404] <bakkot>
no one subsequently raising an objection at the next meeting once they'd had time to review, I guess

[11:58:09.0853] <shu>
waldemar: what's the issue with the spec text?

[11:58:27.0440] <littledan>
OK, this is a different way of using conditional advancement than we usually do, which is more about conditions which can be met async 

[13:01:07.0443] <Ben>
I'm having trouble with my microphone,  but I'll get in on notes again

[13:03:36.0248] <saminahusain>
Hat's are still available

[13:03:42.0072] <Justin Ridgewell>
I can help in 5ish min

[13:04:52.0095] <Andreu Botella>
I can help until AsyncContext

[13:07:35.0863] <Chengzhong Wu>
How can I register for one? ü§†

[13:08:35.0016] <Michael Ficarra>
I don't recall a linearity consensus

[13:08:44.0228] <Michael Ficarra>
monotonicity only, which is what we have

[13:10:48.0144] <littledan>
I thought exponential backoff was waiting longer and longer (I don't have background in this area)

[13:11:09.0152] <nicolo-ribaudo>
> <@littledan:matrix.org> I thought exponential backoff was waiting longer and longer (I don't have background in this area)

I also thought the same, but wikipedia clearly shows it's the other way around

[13:11:20.0316] <snek>
depends on what you're talking about

[13:11:24.0784] <nicolo-ribaudo>
For some reason I always assumed that pause was monotonically increasing, and not monotonically decreasing

[13:11:28.0951] <snek>
in this case it gets shorter and shorter until falling back to the slow path

[13:11:45.0164] <Chris de Almeida>
> SYG: Okay, understood, I would document that, that the input number is intended to increase linearly.

[13:11:52.0430] <nicolo-ribaudo>
> <@littledan:matrix.org> I thought exponential backoff was waiting longer and longer (I don't have background in this area)

 * I also thought the same, ~~but wikipedia clearly shows it's the other way around~~

[13:11:58.0701] <nicolo-ribaudo>
 * I also thought the same, <del>but wikipedia clearly shows it's the other way around</del>

[13:12:32.0574] <Michael Ficarra>
wait, that's still not talking about the relationship

[13:12:55.0809] <Michael Ficarra>
yes the input can increase linearly, but that doesn't mean it is linearly proportional to the time waited

[13:15:04.0270] <littledan>
saying "the spec is not intelligible" is not an effective way to communicate because it is very unspecific.

[13:15:22.0303] <littledan>
It would be better to separate the discussions of what *should* happen, from how we encode this in the words

[13:15:37.0673] <Michael Ficarra>
also there is no editorial issue with the spec as far as I can tell

[13:15:53.0536] <Michael Ficarra>
we were very careful with the phrasing in this proposal

[13:17:12.0437] <Rob Palmer>
This is reminding me of the coffee `filter` in/out discussion in Nov 2019.  Folk are seeing the pause N from both sides.  Shu wants small N to mean a longer pause.

[13:17:37.0256] <peetk>
i agree with justin that note 3 does not say what shu was saying it should say

[13:18:07.0548] <littledan>
> <@robpalme:matrix.org> This is reminding me of the coffee `filter` in/out discussion in Nov 2019.  Folk are seeing the pause N from both sides.  Shu wants small N to mean a longer pause.

the two discussions are being mixed together, the editorial and normative

[13:18:10.0692] <Michael Ficarra>
note 1 literally says that this means a pause instruction on such architectures lol

[13:18:14.0923] <littledan>
so it is confusing; we need to separate and order them

[13:20:11.0517] <nicolo-ribaudo>
My reading of step 2 is the opposite of what shu is saying, and it's not just the note being the opposite. Assuming that "a signal is sent" means "wait a little bit", for larger Ns it waits for a little bit more times

[13:20:42.0523] <littledan>
I am also confused by the wording, but let's first focus on, what *should* the thing do, and then we can fix/disambiguate the wording

[13:21:15.0690] <Rob Palmer>
I think we have agreement on the normative:  the pauses between spins get bigger and bigger before going to sleep.

[13:21:29.0420] <littledan>
no it was the opposite :)

[13:21:30.0669] <nicolo-ribaudo>
> <@robpalme:matrix.org> I think we have agreement on the normative:  the pauses between spins get bigger and bigger before going to sleep.

Didn't Shu say the opposite?

[13:21:43.0789] <littledan>
also we don't have agreement; Justin is disagreeing on substance

[13:22:44.0011] <littledan>
what is it that Shu is proposing?

[13:22:50.0606] <kriskowal>
We must now decide whether to spin in session or yield to the agenda :P

[13:23:02.0704] <kriskowal>
Context switches are expensive

[13:23:19.0474] <Justin Ridgewell>
Having the smaller-i-longer-wait sematnics is fine with me if it‚Äôs really how other implemenations have done it.

[13:23:35.0543] <snek>
pauses get bigger and smaller in mature implementations. ideally you want to have the behavior that kris explained, but implementations like linux for example also have a signal of "starvation" which can cause the delay to get longer as well.

[13:23:42.0510] <Justin Ridgewell>
The current semantics with reworded text and note would be fine with me.

[13:24:11.0512] <Justin Ridgewell>
The current semantics reads as the opposite of the current spec/note to me.

[13:24:34.0860] <saminahusain>
will you be in Tokyo? I will bring a bunch.

[13:24:57.0379] <littledan>
> <@devsnek:matrix.org> pauses get bigger and smaller in mature implementations. ideally you want to have the behavior that kris explained, but implementations like linux for example also have a signal of "starvation" which can cause the delay to get longer as well.

yeah let's just not give this semantics

[13:25:27.0492] <snek>
yeah i think it would be best if we simply don't constrain it

[13:25:33.0711] <littledan>
this will need an overflow item, there's too much overflow to get through it

[13:25:36.0631] <littledan>
we have a lot to say

[13:26:27.0475] <bakkot>
if we don't give it semantics, then someone will ship (wlog) "longer iteration number is short wait", and then some application be written in such a way that depends on that behavior for performance, and now it is web-reality and can't be changed without negative performance impact

[13:26:36.0404] <bakkot>
so I don't see much benefit from not giving it semantics

[13:26:39.0465] <rbuckton>
spin locks use the counter to make a determination as to whether you've been spinning often enough to justify a context switch/kernel transition. The counter is used to indicate frequency and sometimes introduce and reduce contention. not all counter values are guaranteed to pause in some implementations

[13:26:49.0033] <bakkot>
I guess it allows implementations to specialize for specific scripts, which they do sometimes do, but... ugh

[13:26:58.0995] <bakkot>
 * I guess it allows implementations to give special behavior for specific scripts, which they do sometimes do, but... ugh

[13:27:20.0607] <littledan>
well, this is a lot like tuning GC

[13:28:07.0330] <rbuckton>
Most spinlock/spinwait implementations are very handwavy on specifics because it's CPU architecture dependent

[13:28:46.0517] <Chengzhong Wu>
Likely will be there, thanks!

[13:32:06.0345] <rbuckton>
iteration count is used more to determine `pause` request frequency, not how much time to wait.

[13:34:27.0066] <rbuckton>
If the iteration count is high and you're approaching a context switch, you want to wait less and less time to give the high-iteration spin a chance to attain the lock. But many spin wait operations will decide that it may only pause for any length of time when `iterationCount % 10 === 0` or `iterationCount % 100 === 0`, etc., and return immediately in other cases.

[13:35:52.0627] <rbuckton>
The purpose of the argument is indicate spin frequency and to not always pause.

[13:37:05.0518] <shu>
i am just confused what there is to disagree on, there is literally no observable behavior

[13:37:39.0285] <nicolo-ribaudo>
> <@shuyuguo:matrix.org> i am just confused what there is to disagree on, there is literally no observable behavior

How is the number of signals related to the pause length in nanoseconds?

[13:37:53.0105] <shu>
it's implementation-defined

[13:38:27.0812] <rbuckton>
My understanding of the concerns are that the spec text that is either over detailed, or uses the confusing terminology.

[13:38:51.0431] <shu>
i will remove the text about the backoff and any particular relation between the pause length and the iterationNumber argument

[13:39:28.0445] <shu>
there's another design constraint in play which waldemar and michael saboff seem to be saying: if there is no observable behavior, there should be no argument

[13:39:54.0874] <Justin Ridgewell>
> <@shuyuguo:matrix.org> i will remove the text about the backoff and any particular relation between the pause length and the iterationNumber argument

I think that‚Äôll upset @msaboff ?

[13:40:05.0408] <shu>
Justin Ridgewell: how so?

[13:40:17.0563] <shu>
he said JSC will likely ignore it, which is certainly fine

[13:40:35.0669] <shu>
my personal intention is that until the code is in the optimizing JIT and inlined, it _is_ ignored

[13:40:47.0892] <Justin Ridgewell>
His final statement was that if there‚Äôs no note, the param will just be ignored.

[13:40:49.0505] <littledan>
> <@shuyuguo:matrix.org> he said JSC will likely ignore it, which is certainly fine

presumably it'd be better for the web if you can align on this...

[13:41:02.0133] <shu>
i don't think i do...?

[13:41:13.0703] <shu>
presumably JSC will do the right thing for M-chips

[13:41:25.0322] <shu>
and V8 might do a more generic thing?

[13:41:40.0341] <littledan>
OK sure

[13:42:04.0381] <littledan>
but "just ignore it" doesn't sound like something tuned for M-chips; it sounds like not engaging with the question

[13:42:27.0170] <shu>
> <@littledan:matrix.org> but "just ignore it" doesn't sound like something tuned for M-chips; it sounds like not engaging with the question

fair, but it's intended to be a hint

[13:42:34.0004] <shu>
why would we try to align on how to interpret a hint?

[13:42:39.0511] <shu>
it's supposed to give freedom to implementations!

[13:42:47.0592] <nicolo-ribaudo>
(I don't know if this is actually implementable given the perf constraints)

What if instead of the iteration number we passed an object, and the engine internally counts how many times it sees that object? So that there is no possible expectation connected to "big number" vs "small number"

[13:42:58.0682] <shu>
no thanks...

[13:43:00.0520] <kriskowal>
I approve of every possible steam (locomotive, motor) metaphor as we can cram into this language.

[13:43:04.0386] <littledan>
> <@shuyuguo:matrix.org> why would we try to align on how to interpret a hint?

well, we'd want to align on, engines feeling like they can interpret this as a hint, rather than that it's just something to ignore

[13:43:30.0853] <shu>
> <@littledan:matrix.org> well, we'd want to align on, engines feeling like they can interpret this as a hint, rather than that it's just something to ignore

yes, i agree. but ignoring is a valid interpretation of a hint, do we agree on that?

[13:44:00.0490] <Justin Ridgewell>
I assume the CPU architecture has some semantic meaning for the hint?

[13:44:03.0943] <littledan>
yes, it is valid, but I hope that JS engines can get past the philosophical disagreement that seems to exist right now and agree that this is a potentially usable hint if it makes sense for the architecture

[13:44:17.0629] <Justin Ridgewell>
We can tell engines to ignore it, but how do they map our hint‚Äôs intention to the arch‚Äôs intention?

[13:44:22.0807] <littledan>
since msaboff's statement was not about the architecture

[13:44:40.0700] <shu>
> <@jridgewell:matrix.org> I assume the CPU architecture has some semantic meaning for the hint?

not the CPU arch per se, more the VM

[13:45:05.0377] <rbuckton>
`Atomics.pause` is purely a CPU architecture dependent operation. A conforming implementation is welcome to ignore `iterationCount` and return immediately if it so chooses, though that is the least efficient approach as it most likely results in thread starvation and does not improve contention.
An efficient implementation of `pause` will use the `iterationCount` to avoid thread starvation and optimize contention by *periodically* introducing an asm `pause` or similar instruction based on whatever information is relevant for that architecture. The main goal is to avoid spinning longer than you would have had to wait for a context switch/kernel transition. These optimizations can include, but are not limited to:
- Only `pausing` every *n* iterations
- issuing a `pause` more or less frequently the longer we've been spinning
- issuing a `pause` more or less frequently based on how frequently we've been spinning
- issuing a `pause` more or less frequently as you approach an amount of time since you started spinning that would be equivalent to the time spent waiting for a context switch.

[13:46:06.0892] <Justin Ridgewell>
> <@rbuckton:matrix.org> `Atomics.pause` is purely a CPU architecture dependent operation. A conforming implementation is welcome to ignore `iterationCount` and return immediately if it so chooses, though that is the least efficient approach as it most likely results in thread starvation and does not improve contention.
> An efficient implementation of `pause` will use the `iterationCount` to avoid thread starvation and optimize contention by *periodically* introducing an asm `pause` or similar instruction based on whatever information is relevant for that architecture. The main goal is to avoid spinning longer than you would have had to wait for a context switch/kernel transition. These optimizations can include, but are not limited to:
> - Only `pausing` every *n* iterations
> - issuing a `pause` more or less frequently the longer we've been spinning
> - issuing a `pause` more or less frequently based on how frequently we've been spinning
> - issuing a `pause` more or less frequently as you approach an amount of time since you started spinning that would be equivalent to the time spent waiting for a context switch.

Is this the interpretation you‚Äôre proposing, or is this a written behavior somewhere?

[13:46:07.0180] <rbuckton>
Most implementations of a `pause`-like method I've seen are heavily optimized based on OS, CPU Arch, runtime, clock speed, and other factors and as such can't be easily expressed in an algorithmic form.

[13:46:41.0382] <rbuckton>
This is my observation from looking at spin-wait mechanisms in several languages and runtimes.

[13:46:52.0118] <rbuckton>
This isn't precise copy that I would use in the spec.

[13:47:33.0218] <rbuckton>
This is more to argue that we should put a lot less into the algorithm steps and NOTEs than we currently are.

[13:49:12.0568] <shu>
i think there are only two realistic options:

1. drop the hint argument entirely
2. accept an integer as an hint and say it is implementation-defined how it is used to determine how long to pause

i still think 2 is uncontroversial but clearly it _is_ controversial but not in a way i understand how to make progress on

[13:49:51.0248] <rbuckton>
We should not drop the hint argument. 

