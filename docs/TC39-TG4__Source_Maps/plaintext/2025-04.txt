2025-04-01
[23:26:53.0209] <Simon Z√ºnd>
Holger Benl: FYI, I updated the scopes codec library with the most recent proposal changes


2025-04-07
[10:27:15.0367] <James>
hello üëÄ one thing I was talking about recently as part of e18e.dev efforts was the idea of a sourcemaps server (like how c#/.net has symbol servers)
maybe its worth bringing up here and seeing what people think

something like npm but which hosts sourcemaps and nothing else. at build time we point all of our sources at that server (inject the domain into the sourcemaps url) rather than shipping sourcemaps

has anyone ever thought about that?

[10:27:59.0055] <James>
could we build that today with existing sourcemaps or would we not be able to reference another host?

[13:00:12.0210] <Nic>
I have no knowledge about .net and c# ‚Äî what would that be? Like a CDN for source maps?

[13:00:35.0378] <Nic>
Or a package registry for them?

[13:00:49.0790] <Nic>
What are the advantages/disadvantages over the current approaches?


2025-04-08
[21:18:20.0169] <Simon Z√ºnd>
To answer the last question first: You'd be able to achieve this already with the current source map format. The sourceMappingURL is allowed to be cross-origin.

The closest thing I can think of are artifact servers for cloud providers. E.g. MS Azure allows you to host source maps (and original source files) for you behind some OAuth, so you can securely debug an app without making the source/source maps publicly available (https://learn.microsoft.com/en-us/microsoft-edge/devtools-guide-chromium/javascript/consume-source-maps-from-azure).

AFAIK there is no package registry purely for source maps yet.

[05:01:46.0008] <littledan>
should we work together to build one? It could make source maps available in practice more of the time, reduce the incentive for doing a data URL for the source map (which slows down loading time), and reduce the size of npm packages (for installation time)

[06:15:16.0499] <James>
ah nice! i didn't realise map URLs can be cross-origin

[06:16:44.0607] <James>
Nic: the benefit .net and various other languages doing this have is that they don't need to ship debug symbols
think of a compiled language, you want to ship the cut down production binary with no debug symbols etc. 
you then pull those symbols from a separate source if you want to debug said binary

we could do the same by having a sourcemap registry and pull sourcemaps from there instead of shipping them in our packages

[06:17:25.0272] <James>
e.g. cloudflare recently removed sourcemaps and halved their package size. great for everyone except the couple of people who want to debug it nicely. but if they could pull those maps from some other source, that'd solve it for both sides

[06:19:05.0900] <James>
we could do this now by having a build-time transform which sets the sourcemap URL to a remote one and uploads them to the server

[06:34:48.0587] <Nic>
Could it be something like we have `@types/foo`, e.g. `@source-map/foo`?

[06:41:45.0040] <James>
i think so yes

[06:43:14.0872] <James>
though maybe its more like unpkg or something. as it isn't something you'd pull from npm. if you did host it on npm though, i suppose you could use something like unpkg/jsdelivr/etc to retrieve it

[06:43:52.0654] <James>
i.e. if we publish our map to `@source-map/foo`, our sources link to `somecdn.com/@source-map/foo/lib/index.js.map`

[06:44:10.0873] <James>
maybe thats how you avoid needing a whole new registry/host

[09:17:32.0179] <ljharb>
`@types` works because DT manages all those packages - i don't think you'd want to have to manage everyone's source maps and keep them in sync

[11:43:54.0498] <littledan>
yeah having your source maps centralized on some cdn seems less risky than actually loading your source from there

[11:58:56.0211] <kriskowal>
I would like to see it to become common for the stock source map URL to be a content address of the preceding text, and eventually, implicit, so an IDE could be configured to find the sourcemap in whatever storage. At Agoric, we‚Äôve been working toward a solution where our bundler drops source maps in a conventional XDG caches directory, keyed on content address. We believe there‚Äôs a solution you can rig up WebPack this way and, in a VSCode launch.json, map content addresses to local physical files, but I simply haven‚Äôt found credible documentation for it.

[11:59:11.0544] <kriskowal>
Consider `source-map://${hash}.map.json`.

[13:27:45.0104] <rbuckton>
Do you mean using `"sourceMapPathOverrides"`? https://code.visualstudio.com/docs/nodejs/nodejs-debugging#_overriding-source-map-paths

[13:32:18.0198] <kriskowal>
There it is!

[13:35:29.0570] <kriskowal>
So, I believe this is the thing we would use to make `source-map://${hash}.map.json` just work. It doesn‚Äôt look particularly fancy, so it‚Äôd probably look more like `source-map://b0/b5c0ffeefacade.map.json` so we don‚Äôt end up with intractable `readdir` expenses.

[13:36:31.0852] <kriskowal>
If that practice became the norm, bundlers, LSP, and registries could conspire to their hearts‚Äô content.

[13:44:12.0046] <rbuckton>
IIRC, there was an internal hackathon to make sure VSCode supported remote sourcemaps and this kind of wire up so it could use them somewhat like a symbol server. In lieu of a bundler, even tsc lets you specify a URL as the base to use for `sourceMappingURL=` via the `"mapRoot"` option, as well as a URL for sources using the `"sourceRoot"` option, assuming you don't just use `"inlineSources": true`

[13:57:15.0349] <kriskowal>
We find that we have to tolerate certain compromises in order to ensure that our bundles produce consistent content regardless of the parent path and as insensitive as possible to the layout of the node_modules tree. We tend to inject a source URL like `.../${nameOfPackageParentDirectory}/${pathWithinPackage}` and tolerate the occasional collision due to ‚Äúeval twin‚Äù packages under `node_modules` or the occasional divergence between the name of the package and the name of the directory containing the package. And, consistent hashes have their own vagaries.

[14:04:23.0966] <littledan>
kriskowal: Is that a content hash of the source map you're referencing?

[14:08:03.0532] <kriskowal>
That‚Äôs an open design question. That probably wouldn‚Äôt work for our case, because of fully qualified file URLs in the source map varying between users and host systems, which would frustrate the consistency of the hash of the bundle.

[14:10:54.0021] <kriskowal>
Hash of the original source works in many but not all cases, and we can safely carry that in-band (embedded in the sourceMapURL comment of the bundled code).

[14:11:41.0489] <kriskowal>
The original source hash tends to converge when you get close to empty, and everything about an empty sourcemap is fine except the `sources` array being different for each.

[14:15:20.0089] <kriskowal>
At the end of the day, the protocol just requires a consistent, collision-free, decentralized namespace that the bundler and the IDE can converge into, so the specifics of how the hash get generated can vary. Like, a probably sufficient mitigation for collisions is to hash the package name and version, the module specifier within the package, and the content of the original sources. You could certainly go so far as to use the path names through the package dependency tree to obviate node_modules twins and discrepancies between the package name and package parent directory name.

[14:15:41.0369] <littledan>
content hashes are pretty cool

[14:15:51.0442] <littledan>
I mean content hash-based addressing

[14:16:22.0973] <kriskowal>
They‚Äôre a sort of big deal :-)


2025-04-09
[21:02:59.0362] <Simon Z√ºnd>
kriskowal: Wouldn't the debug ID / build ID solve a similar problem. As proposed now it would add a `//#sourceMapDebugId` field alongside the url in bundles.

[21:41:17.0580] <Simon Z√ºnd>
Then you an load source maps via URL + debug ID. On top you can actually verify after that you loaded the right source map (without rehashing)

[21:41:27.0654] <Simon Z√ºnd>
* Then you can load source maps via URL + debug ID. On top you can actually verify after that you loaded the right source map (without rehashing)

[03:01:43.0555] <Simon Z√ºnd>
Lets get this started https://github.com/tc39/ecma426/pull/196 :)

[09:01:15.0057] <asumu>
TG4 meeting starting now!

[15:45:14.0216] <kriskowal>
Having a bundler generate only a `//#debugId` with a UUID v5 (SHA1 of whatever combination of relevant, convergent things) instead of hacking the `//#sourceMappingURL` with a consistent hash seems like the way to go, to me. Thanks for the link. Hope that goes well.


2025-04-10
[07:29:00.0446] <littledan>
IMO it'd be best to work on standing up a service which handles things well within the current URL-based system (but integrating hashes for this next step), and then we can consider conventions to make this independent of a particular host

[07:29:21.0352] <littledan>
jumping straight to content-addressed hashes is kind of a lot


2025-04-13
[04:47:04.0211] <James>
tiny update on where i got to with my sourcemap publishing/externals idea. it seems chrome does have some trouble requesting external sourcemaps
do any of you know if there's any particular rules browsers follow when loading a sourcemap url?

[04:47:07.0202] <James>
cross origin stuff etc

[16:13:43.0772] <Chris de Almeida>
NRO is down for 5m TG4 report tomorrow.  lmk if delta

[16:16:05.0365] <jkup>
I'll be doing the update! 5m is good though it's a short one


2025-04-14
[21:00:00.0432] <Simon Z√ºnd>
Chrome attempts to load the source map via the inspected page itself at first. So if the page fails to `fetch` the source map, so will Chrome DevTools

[00:52:38.0664] <James>
interesting. the error isn't of any use really ("unexpected error" or some such thing). but im guessing its a cross-origin thing then

[00:54:40.0747] <James>
in this case im also using devtools for node, so there is no 'page'. not sure what the rules are then, i.e. what is the origin etc

[00:58:30.0103] <James>
i imagine debug IDs will make this a lot easier one day if someone hosts a server to look them up üòÖ

[01:03:51.0371] <Nic>
The problems that debug IDs are solving is distinguishing two different source maps that are hosted at the same URL (for example, because you updated your code and rebuild the source map). With the default devtools behavior, if you are already including the version of the file in the URL you are fetching then also having the ID is probably not super helpful.

[01:04:18.0838] <Nic>
If Chrome devtools have problems fetching those source maps however, you might take a look at the extensions API mentioned in https://github.com/tc39/ecma426/issues/185

[01:04:32.0292] <Nic>
It's possible you might just do the fetching by yourself through a browser extension¬†

[01:05:04.0413] <Nic>
What's asked in the last question there seems to be exactly what you are trying to do

[01:10:31.0664] <James>
pretty much. we have a tool now which transforms sourcemap urls to CDN hosted ones. if devtools were capable of loading them, all would be solved (and made easier one day by standards ideally)

[01:12:06.0305] <James>
ill see if i can pester someone who knows more about node devtools than i do. i.e. any limits on requests etc, what origin it is

[01:55:06.0575] <Simon Z√ºnd>
DevTools basically first attempts to call the `Network.loadNetworkResource` CDP method https://chromedevtools.github.io/devtools-protocol/tot/Network/#method-loadNetworkResource

[01:55:14.0537] <Simon Z√ºnd>
So it depends whether Node implements that or not

[01:55:43.0477] <Simon Z√ºnd>
If that fails, we try a different approach by attempting to fetch it ourselves but with some of the target permissions applied

[01:55:49.0222] <Simon Z√ºnd>
Let me dig up the code

[01:56:37.0101] <Simon Z√ºnd>
https://source.chromium.org/chromium/chromium/src/+/main:chrome/browser/devtools/devtools_ui_bindings.cc;l=1116;drc=e005c381337ad6a2312cafa0202f80b7950afbe1

[01:56:48.0843] <Simon Z√ºnd>
That is the fallback if going through the inspected page fails

[01:57:03.0656] <Simon Z√ºnd>
e.g. DevTools can load source maps from `file:///` URLs and it uses the fallback for that

[01:57:27.0952] <Simon Z√ºnd>
I imagine that because Node.js only recently started implementing the CDP `Network` domain, we always used the fallback for node.js debugging

[02:01:27.0244] <Simon Z√ºnd>
Note that cross-origin source maps are somewhat common, but the server serving the source maps needs to have CORS configured to allow fetching from cross-origins

[02:04:11.0524] <James>
so its possible node/devtools just never attempts to load external maps? thanks so much for the info too. was looking for that c file for a while üòÖ

[02:06:44.0504] <James>
i basically get the same error as these folks:
https://github.com/Adobe-CEP/CEP-Resources/issues/448

and yes im currently using jsdelivr which has the right CORS headers, content type, etc. but this error makes it seem more like devtools just isn't even trying to request it in the first place

[02:09:00.0931] <James>
once i get this working, longer term it does feel like we should have a standard symbol server some day. one of the various orgs would need to own/host it, but it'd get rid of the need for anyone shipping sourcemaps anymore

[02:09:25.0137] <James>
im kinda hacking around it by hosting them on npm under a special tag, but i can see a future where there's an actual sourcemap server somewhere

[03:40:49.0414] <Simon Z√ºnd>
If you have a small repro, feel free to file a bug on crbug.com. I can take a look at why DevTools fails to fetch the source map.

[03:43:38.0309] <Simon Z√ºnd>
Ah, note that remote debugging is different depending on how DevTools is opened. The fallback path only exists if you use a "real" Chrome DevTools opened either via right-click "inspect" or via `chrome://inspect`. Otherwise the fallback path doesn't exist.

