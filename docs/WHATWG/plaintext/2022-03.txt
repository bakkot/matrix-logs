2022-03-01
[07:35:57.0792] <ntim>
annevk: Thanks for the review! I wonder if I should remove "The user agent may ignore the node for the purposes of text search
   (commonly known as "find in page")." altogether. No implementation currently does this (unless aria-hidden nodes are ignored in some contexts).

[08:22:55.0849] <ntim>
annevk: also, about "This data-x-href needs to move to where the other data-x-hrefs are.", where are the other data-x-hrefs typically?

[08:23:11.0862] <Ms2ger üíâüíâ>
"dependencies" section?

[08:23:50.0586] <ntim>
ah makes sense thank you

[08:45:15.0888] <annevk>
ntim: I don't have a strong opinion, how do UAs deal with it then? Wouldn't searching result in selection?

[09:00:50.0182] <ntim>
annevk: searching results in highlighting, not necessarily selection

[09:02:15.0852] <ntim>
(anyway, I addressed all your comments)

[09:06:22.0020] <annevk>
Ah yeah, for some reason I thought you could copy-and-paste the currently highlighted one, but that's not a thing

[09:06:41.0343] <annevk>
Still might be frustrating if you can search and find, but not select and copy

[09:11:59.0901] <annevk>
Thanks ntim! Reviewed again. I suspect we'll wait with landing until next week btw as it's a somewhat big change so Domenic should probably be around.

[09:17:15.0774] <ntim>
> Can you edit without selection? Are execCommand() calls prohibited? How does this actually affect the Selection API, come to think of it?

Not sure how to spec this formally aside from this matches `user-select: none` + `-webkit-user-modify: readonly`

[09:17:26.0094] <ntim>
annevk: ^

[09:18:38.0726] <ntim>
https://github.com/web-platform-tests/wpt/blob/master/inert/inert-and-contenteditable.tentative.html

[09:18:59.0453] <ntim>
it would be like execCommand on a non-editable node

[09:19:37.0294] <ntim>
I guess it would reasonable to reference user-select

[09:21:49.0042] <annevk>
That would help. Do we have some tests around this? Creating a Selection object and trying to assign it nodes from an inert tree?

[09:22:28.0896] <annevk>
It's unfortunate none of these specs are defined to that level of detail, but I guess making it clear they should behave the same is a start...

[09:22:37.0199] <annevk>
emilio thoughts on the above?

[09:22:47.0489] <ntim>
https://github.com/web-platform-tests/wpt/blob/master/inert/inert-node-is-unselectable.tentative.html

[09:22:59.0121] <ntim>
uses execCommand("selectAll")

[09:29:21.0228] <ntim>
annevk: The "The user agent may ignore the node for the purposes of text search (commonly known as
   "find in page")." bit, is there more from an a11y standpoint I think, e.g. inert should behave like aria-hidden

[09:29:46.0993] <ntim>
and the UA may choose to ignore aria-hidden nodes from text search if they want

[09:30:05.0180] <annevk>
Okay, let's keep it then, no?

[09:30:05.0359] <ntim>
(It was there before my PR fwiw)

[09:30:10.0595] <ntim>
sounds good

[09:36:30.0987] <ntim>
annevk: I clarified the bits around editing and selection

[09:42:46.0084] <annevk>
ntim: cool, looks good to me modulo nit about using data-x="" instead of dfn

[09:43:36.0723] <ntim>
annevk: <code data-x=""> by itself seems to complain too

[09:45:05.0055] <ntim>
like "none" needs to be defined at least once

[09:45:06.0480] <ntim>
Error: missing <dfn> for topic "inert-css-property-value-none" from 2 sites including explicitly from <code> element containing "none"; previous heading contents are "6.3 Inert subtrees"
Error: missing <dfn> for topic "inert-css-property-value-none" from 2 sites including explicitly from <code> element containing "none"; previous heading contents are "6.3 Inert subtrees"
Error count: 2


[09:47:20.0309] <annevk>
ntim: that means you still use `inert-css-property-value-none` somewhere

[09:47:35.0921] <annevk>
ntim: instead you should have `<code data-x="">none</code>`

[09:48:09.0237] <ntim>
oh empty string

[09:50:15.0748] <ntim>
thanks! that does seem to work

[09:53:06.0886] <ntim>
annevk: something I was wondering is putting the "blocked by a modal dialog" stuff in its own subsection before or after the "inert attribute" one.

[09:53:35.0016] <ntim>
but it's fine as it is too I guess

[09:56:25.0188] <annevk>
/me looks

[09:58:33.0456] <annevk>
ntim: up to you, I agree it could work

[10:00:04.0787] <annevk>
I wonder if inert only applying to Text/Element has implications elsewhere; I guess Text includes CDATASection and Comment/ProcessingInstruction/ShadowRoot are never rendered, so it prolly doesn't matter

[10:55:11.0201] <Seirdy>
(not asking to ask, just asking for future reference) is WCAG discussion relevant here, or is there a better place? doesn't have to be on matrix.

[11:03:03.0641] <aja>
> <@seirdy:seirdy.one> (not asking to ask, just asking for future reference) is WCAG discussion relevant here, or is there a better place? doesn't have to be on matrix.

perhaps ask in https://matrix.to/#/#accessibility:mozilla.org 

[11:10:17.0049] <Seirdy>
thanks, might have some questions later today

[13:06:12.0240] <Domenic>
Yoav Weiss: Noam Rosenthal : what is the cross-origin redirects case for unload timing protecting against? It's basically saying if you go x.com -> y.com --redirects to-> x.com/bar, x.com/bar does not get unload timing for x.com. Why? No information about y.com leaked.

[13:08:24.0291] <Domenic>
Hmm maybe it's because unloadTimeEnd is an absolute time so you can use it to infer how much time was spent on y.com by comparing it to x.com/bar load time.

[13:43:09.0203] <Noam Rosenthal>
> <@domenicdenicola:matrix.org> Yoav Weiss: Noam Rosenthal : what is the cross-origin redirects case for unload timing protecting against? It's basically saying if you go x.com -> y.com --redirects to-> x.com/bar, x.com/bar does not get unload timing for x.com. Why? No information about y.com leaked.

It‚Äôs a good question,I think it‚Äôs superfluous. Not sure this protection exists in implementations, will check tomorrow. Since it‚Äôs the same origin the unload time is anyway known as x.com can save performance.now() somewhere and send it over to be used by x.com/bar

[13:43:24.0958] <Domenic>
Yeah...

[13:43:32.0306] <Domenic>
Thanks for checking!

[13:51:28.0172] <Doug Conmy>
Is there a way to determine if a company (aka Entity) is a whatwg participant/member?   
    That is, they have signed the agreement,  https://participate.whatwg.org/agreement , and have a point of contact.

I am trying to find out internally in my orgnaization, but if this information is public, or if I could ask a member to check, that could save some time in hunting down the right person from my end.

[14:16:33.0141] <Domenic>
> <@dconmy:matrix.org> Is there a way to determine if a company (aka Entity) is a whatwg participant/member?   
>     That is, they have signed the agreement,  https://participate.whatwg.org/agreement , and have a point of contact.
> 
> I am trying to find out internally in my orgnaization, but if this information is public, or if I could ask a member to check, that could save some time in hunting down the right person from my end.

Ctrl+F through https://github.com/whatwg/participant-data/blob/main/entities.json

[14:41:26.0296] <shu>
got a webidl question: i can't seem to find the definition of what it means "to convert a sequence of values of type T to an ECMAScript value", like in step 1 here: https://webidl.spec.whatwg.org/#es-frozen-array

[14:43:42.0995] <Mattias Buelens>
> <@shuyuguo:matrix.org> got a webidl question: i can't seem to find the definition of what it means "to convert a sequence of values of type T to an ECMAScript value", like in step 1 here: https://webidl.spec.whatwg.org/#es-frozen-array

That should be in https://webidl.spec.whatwg.org/#es-sequence

[14:45:41.0730] <shu>
tyvm


2022-03-02
[17:07:46.0284] <sideshowbarker>
annevk: https://stackoverflow.com/questions/71311305/how-to-prevent-safari-from-dropping-the-authorization-header-when-following-a-re
> Safari seems to drop the `Authorization` header when following a [same-origin] 301 redirect... Chrome (98) and Firefox (97) both follow the redirect and include the `Authorization` header in the subsequent `GET` request.

Wonder what behavior the spec requires here

[17:09:09.0809] <sideshowbarker>
and https://stackoverflow.com/questions/57974176/safari-does-not-persist-the-authorization-header-on-redirect is another 2-year-old question about the same thing

[21:12:15.0255] <Noam Rosenthal>
> <@domenicdenicola:matrix.org> Yoav Weiss: Noam Rosenthal : what is the cross-origin redirects case for unload timing protecting against? It's basically saying if you go x.com -> y.com --redirects to-> x.com/bar, x.com/bar does not get unload timing for x.com. Why? No information about y.com leaked.

I checked, and the specific scenario (same->cross->same redirect, check that unload is not available) is tested in WPT and passes all 3 browsers... https://github.com/web-platform-tests/wpt/blob/master/navigation-timing/unload-event-same-origin-check.html#L57
https://wpt.fyi/results/navigation-timing/unload-event-same-origin-check.html?label=experimental&label=master&aligned

[21:13:09.0653] <Noam Rosenthal>
to me it seems like an unnecessary security measure or I don't understand it. Yoav Weiss ?

[21:35:56.0574] <Yoav Weiss>
It's possible that this is overly strict. It used to be TAO protected and have the same rules as TAO, but at some point we realized that it's not really protecting anything (it's not the origin which information was exposed that was opting in), so moved to a same origin check. The same=>cross=>same scenario was one that we protected against in TAO, so maybe that logic sticked around through the move to same origin checks.

[21:37:30.0182] <Yoav Weiss>
Maybe annevk has reasons as to why we should keep it, but I tend to agree with y'all that if the previous origin is the same as the destination origin, we could expose the data 

[23:48:27.0553] <annevk>
I think Referer and Sec-Fetch-Site are impacted so I think this ought to be impacted as well. What might leak is if y.com does a further redirect based on a cookie. Now x.com could conspire with subsequent x.com, but given that Referer and Sec-Fetch-Site are impacted it might not entirely be clear whether it's the result of a redirect or a subsequent visit. Especially with more navigation tracking mitigation down the line.

[23:48:42.0817] <annevk>
Noam Rosenthal: Yoav Weiss: Domenic: ^^

[23:48:57.0667] <annevk>
 * I think Referer and Sec-Fetch-Site are impacted so I think this ought to be impacted as well. What might leak is if y.com does a further redirect based on a cookie. Now x.com could conspire with subsequent x.com, but given that Referer and Sec-Fetch-Site are impacted it might not entirely be clear whether it's the result of a redirect or a subsequent visit. Especially with more navigation tracking mitigation down the line.

[23:50:49.0582] <Noam Rosenthal>
> <@annevk:mozilla.org> I think Referer and Sec-Fetch-Site are impacted so I think this ought to be impacted as well. What might leak is if y.com does a further redirect based on a cookie. Now x.com could conspire with subsequent x.com, but given that Referer and Sec-Fetch-Site are impacted it might not entirely be clear whether it's the result of a redirect or a subsequent visit. Especially with more navigation tracking mitigation down the line.

OK so this hides the fact that the unload and the new document are the same visit, which is otherwise a hidden fact. This also brings back the https://github.com/w3c/navigation-timing/issues/160 thing...

[23:56:38.0240] <annevk>
Noam Rosenthal: yeah, though I'd argue that case is worse.

[23:57:01.0077] <annevk>
sideshowbarker: left a reply. Not sure if Safari has an open bug for this, maybe you want to file one?

[23:58:41.0459] <sideshowbarker>
> <@annevk:mozilla.org> sideshowbarker: left a reply. Not sure if Safari has an open bug for this, maybe you want to file one?

I'll ask the OP if they can file a bug

[07:28:49.0654] <devsnek>
any webkit/gecko people feeling inspired? https://github.com/whatwg/websockets/issues/20

[07:29:25.0324] <devsnek>
annevk: you seemed to not hate this, in the past at least. do you think mozilla would accept contribution for this?

[07:31:45.0486] <annevk>
devsnek: yeah probably, but will need spec + tests


2022-03-03
[23:56:40.0596] <Noam Rosenthal>
Welcome bashi!  a question to you and Yoav Weiss about early hints: do they survive same-origin redirects?

[23:58:07.0866] <bashi>
Noam Rosenthal: Our implementation is that they don't survive redirects including same-origin.

[00:01:25.0790] <Noam Rosenthal>
I personally think this could be useful - even if it's not implemented yet. e.g. you submit a form which is going to do some heavy processing and then redirect you to somewhere - might as well start sending the 103s beforehand

[00:01:34.0014] <Noam Rosenthal>
 * I personally think this could be useful - even if it's not implemented yet. e.g. you submit a form which is going to do some heavy processing and then redirect you to somewhere - might as well start sending the 103s beforehand

[00:03:23.0296] <bashi>
I think changing the behavior isn't difficult. I think we can update our implementation if that's preferable and there is consensus.

[00:06:40.0326] <Noam Rosenthal>
bashi: OK, since the reserved client survives same-origin redirects, for now we'll leave it in the draft PR and we can discuss the specifics on Github

[00:37:05.0359] <annevk>
I guess the question is whether the preloads are preserved?

[00:39:49.0667] <Noam Rosenthal>
annevk: exactly, if you started preloading something and then redirected to somewhere else in the same origin, should you continue those preloads and then transfer them to the document

[00:41:25.0346] <Noam Rosenthal>
... I think it's useful to allow that, but not sure if that has further implications

[00:43:23.0481] <annevk>
Nothing comes to mind, but you might get rather involved sequences... 103 302 103 401 103 200

[00:44:00.0203] <annevk>
Speaking of which, I guess those questions apply to 401/407 too.

[00:45:03.0095] <Noam Rosenthal>
yea I believe we'll have only the first or last (most likely first) 103 in the sequence apply

[00:45:41.0219] <annevk>
Ooh, I didn't realize that. Is that also according to the 103 spec?

[00:47:47.0409] <Noam Rosenthal>
annevk: no, we're discussing that as part of the HTML implementation of what 103 means

[00:48:33.0492] <Noam Rosenthal>
the RFC also allows sending 103 103 103 200

[00:49:07.0106] <annevk>
Right, I kinda expected that would work, but I don't have a strong opinion I think. I asked someone in our networking team.

[00:49:15.0731] <Noam Rosenthal>
(working on a draft spec which would make this a bit easier to discuss)

[07:30:08.0094] <annevk>
TabAtkins: known that api.csswg.org is down?

[08:54:21.0051] <annevk>
Domenic: so I think that in Gecko in the "global view" for browsing contexts that have a parent it's not represented by a browsing context, but rather a specific Window (called a WindowContext), which unless we make that explicit would be more clearly represented by an element than what we have today I think

[08:55:00.0818] <Domenic>
Hmm.

[08:55:48.0937] <Domenic>
I think Chromium is the opposite, but I really need to think about the specific bad case you mention...

[09:00:45.0125] <Domenic>
annevk: if you could double-check my reasoning on https://github.com/whatwg/html/issues/7676 that would be very appreciated; if it's correct I'll need to do some serious surgery as part of the session history rewrite, but if I'm missing something and the current setup is OK that'd be great to know first.

[09:30:14.0378] <annevk>
Domenic: so having read that I'm not entirely sure where we end up with the wrong state

[09:30:28.0513] <annevk>
Domenic: the initial about:blank is wasteful, but it doesn't seem wrong

[09:30:35.0352] <Domenic>
annevk: the creation URL being about:blank seems most worrying to me

[09:30:42.0799] <Domenic>
Or is that a normal thing that happens?

[09:30:52.0201] <Domenic>
But I thought we did like security stuff with creation URL

[09:31:35.0133] <annevk>
Domenic: we do, but only when we're loading something, and by that time the creation URL will be the "final" URL, no?

[09:31:47.0618] <Domenic>
Does something later update creation URL?

[09:32:06.0028] <Domenic>
I thought it would only be set on creation... maybe that is the wrong assumption.

[09:32:18.0087] <annevk>
Domenic: as in, we'll create a new environment for the URL this new BC is being navigated to (that will replace the initial about:blank environment)

[09:32:44.0962] <Domenic>
I don't think we will? Because we have an initial about:blank so we'll just reuse the newly-created Window/ESO

[09:33:02.0650] <annevk>
No, it'll be cross-origin so it cannot reuse.

[09:33:43.0204] <Domenic>
Ohhh

[09:33:57.0564] <annevk>
(Creation URL is used by Fetch and is indeed security sensitive, but it's only used when the thing would fetch stuff, which this won't.)

[09:34:00.0485] <Domenic>
OK then yes I think everything is great. So glad I asked.

[09:34:14.0188] <Domenic>
I will add a big <p class="note">!

[09:34:21.0884] <annevk>
Fair üôÇ

[09:35:17.0339] <Domenic>
bakkot: logs are not working anymore? :( https://matrixlogs.bakkot.com/WHATWG/

[09:56:06.0716] <bakkot>
Domenic: hmmm

[09:56:33.0888] <bakkot>
odd, they're working for other channels

[09:56:48.0449] <bakkot>
I'll take a look later today, thanks for the ping

[10:09:16.0277] <bakkot>
Domenic: should be fixed, sorry about that

[10:29:01.0300] <Domenic>
Awesome, thanks!

[10:55:14.0901] <TabAtkins>
annevk: Looks like the server went down real hard; I can't access the control panels either. Pinged plinss about it.

[15:18:11.0481] <shu>
Domenic: who should i be tagging for webidl PR reviews?

[15:18:28.0112] <shu>
(or anyone)

[15:19:08.0388] <Domenic>
shu: timothygu is good but busy, same as me; this week I'm in particular not doing reviews


2022-03-04
[17:00:07.0133] <crowlkats>
Whats the status of https://github.com/whatwg/streams/pull/1145? Deno is extremely interested in it

[17:00:38.0114] <Luca Casonato>
We're happy to do any necessary spec or integration work to get this landed.

[19:32:38.0366] <Domenic>
Waiting on implementer interest I believe. Might be similar to Response.json(), and a good candidate for https://github.com/whatwg/js-hosts/ while we wait.

[00:28:48.0510] <annevk>
It seems plinss turned it off and on again \o/

[00:43:45.0657] <Andreu Botella>
For the record, I set up https://github.com/andreubotella/csswg-auto-build as an auto-building and auto-updating mirror for the CSS specs

[03:11:45.0117] <sideshowbarker>
> <@abotella:igalia.com> For the record, I set up https://github.com/andreubotella/csswg-auto-build as an auto-building and auto-updating mirror for the CSS specs

Beautiful. Have you shared that with Peter Linss or TabAtkins yet?

[03:13:21.0902] <Andreu Botella>
I think bkardell shared it with Peter Linss

[04:33:27.0006] <stephanluis>
Inspired by a discussion on this chat, I've developed a time only input for use in HTML.  Difference is that my input deals with time in HMSmS, which provides greater browser consistency.  I want to confirm that all the functionality of the element as rendered by Chrome is included in my control, but cannot find a function spec.   Does anyone on this board know where I might find it? 

[04:47:22.0175] <annevk>
stephanluis: is https://html.spec.whatwg.org/ what you are looking for? (Though there is some stuff beyond that I suppose, such as supporting a variety of input methods, supporting multiple locales, etc.)

[05:15:58.0452] <stephanluis>
I've seen that thanks, I know it's now whatwg remit, but I'm hoping to be pointed in the right direction on how chrome or firefox implement the input.  For example what the up and down arrow keys do when hours are selected.  That way I can replicated the control more precisely.  Now I think I have most of it, but would rather be more sure.  Guessing their functional specs would be greatest help?

[05:16:40.0775] <stephanluis>
 * I've seen that thanks, I know it's now whatwg remit, but I'm hoping to be pointed in the right direction on how chrome or firefox implement the input.  For example what the up and down arrow keys do when hours are selected.  That way I can replicated the control more precisely.  Now I think I have most of it, but would rather be more sure.  Guessing their functional specs would be greatest help?

[05:26:21.0719] <annevk>
I see, I'm not sure if those exist or where to find them (other than looking at source code)

[05:26:33.0520] <annevk>
 * I see, I'm not sure if those exist or where to find them (other than looking at source code)

[06:05:59.0965] <stephanluis>
I even had a look at the source code but the documentation wasn't clear enough to use.  Seemed like there is other documentation / specs to work from.  Maybe I can try looking for Firefox specs, if their user interaction is close to chrome as people are most exposed to chrome.

[10:53:58.0854] <Timo Tijhof>
I could use a hand on proving/confirming that the behaviour I'm looking for from the URL constructor (in modern browsers, but not in the FT polyfill), is in fact a bug in the polyfill and not an spec bug or implemetnation bug. https://github.com/Financial-Times/polyfill-library/issues/4#issuecomment-1059423248

[10:55:08.0958] <Timo Tijhof>
The URL version of this, is I think https://url.spec.whatwg.org/#percent-decode

[10:55:12.0565] <Timo Tijhof>
which seems almost too simple to be true

[10:55:30.0465] <Timo Tijhof>
compared to http://es5.github.io/#x15.1.3.2 and the whole Decode complexity and its URIError handling etc.

[11:07:32.0915] <TabAtkins>
Timo Tijhof: At a quick glance, it appears the ES algo might be implementing UTF-8 decoding by hand, thus the complexity.

[11:10:15.0002] <TabAtkins>
Andreu Botella: Btw, you can tell Bikeshed to output to any filename you want, so you don't have to do the rename to index.html manually. 

[11:10:48.0373] <Andreu Botella>
oh, that's right

[11:11:11.0909] <Andreu Botella>
someone could try visiting the `Overview.html` directly, I guess

[11:11:14.0693] <Domenic>
> <@timotijhof:matrix.org> I could use a hand on proving/confirming that the behaviour I'm looking for from the URL constructor (in modern browsers, but not in the FT polyfill), is in fact a bug in the polyfill and not an spec bug or implemetnation bug. https://github.com/Financial-Times/polyfill-library/issues/4#issuecomment-1059423248

We are reasonably confident in the "reference implementation" in jsdom/whatwg-url, which says that such URLs are parsed like browsers do. https://jsdom.github.io/whatwg-url/#url=aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvU3BlY2lhbDpCbGFua3BhZ2U/ZnJvbT1lbiZ0bz1lcyZjYW1wYWlnbj1hcnRpY2xlLXJlY29tbWVuZGF0aW9uJnBhZ2U9QXBvbGxvJTk2U295dXpfVGVzdF9Qcm9qZWN0&base=YWJvdXQ6Ymxhbms=

[12:28:32.0993] <Timo Tijhof>
Thanks, that helps. I've traced it down to https://github.com/jsdom/whatwg-url/blob/a4cb13309246ca9ecf03404fdbf0d23ecaf114dd/lib/urlencoded.js#L10-L33 and https://github.com/jsdom/whatwg-url/blob/a4cb13309246ca9ecf03404fdbf0d23ecaf114dd/lib/percent-encoding.js#L20 which indeed is doing the critically important thing of ignoring things outside the known valid range and leaving them in-tact, whereas the ES decodeURIComponent throws an error for anything unexpected after a % sign.

[12:28:57.0455] <Timo Tijhof>
I'll see if I can port that over to the FT polyfill in a somewhat standalone and minimal fashion.

[15:49:08.0992] <Domenic>
üëÄ look at the list of issues fixed in https://github.com/whatwg/html/pull/6315#issue-790233208

[15:58:14.0545] <Seirdy>
Besides search engines, what are some known working applications of microdata (and other related formats)? I've seen article extraction implementations (including DOM Distiller, Trafilatura) make use of it, for instance.

[15:58:32.0826] <sideshowbarker>
> <@domenicdenicola:matrix.org> üëÄ look at the list of issues fixed in https://github.com/whatwg/html/pull/6315#issue-790233208

Wild ‚Äî ~40 issues, looks like. I can‚Äôt recall ever having seen that the part of the GitHub UI that lists the linked issues shows a **See more** control when there‚Äôs more than a certain number of linked issues ‚Äî 5, I guess ‚Äî¬†but even if you do **See more**, it still limits the list to just 10 issues.
>This monster completely rewrites everything to do with navigation and traversal.

Bravo Jake Archibald 


2022-03-05
[16:00:10.0053] <Seirdy>
> <@seirdy:seirdy.one> Besides search engines, what are some known working applications of microdata (and other related formats)? I've seen article extraction implementations (including DOM Distiller, Trafilatura) make use of it, for instance.

interested in using microdata as an alternative to e.g. a REST API for a website, providing all the data structured in the HTML markup. Knowing some working applications could help me.

[16:06:52.0547] <Seirdy>
* interested in using microdata as an alternative to e.g. a REST API for a website, providing all the data structured in the same HTML. Knowing some working applications could help me.

[21:26:21.0207] <Seirdy>
Can microdata use namespaces intended for RDFa like Dublin Core, FOAF, and Creative Commons?

[21:27:28.0178] <Seirdy>
 * interested in using microdata as an alternative to e.g. a REST API for a website, providing all the data structured in the same HTML. Knowing some working applications for consuming (rather than creating) microdata (or other semantic markup syntaxes) could help me.


2022-03-07
[15:31:27.0797] <cyberakuma>
Is there a proper place to discuss WebIDL? Specifically creating an extended attribute to declare a modified default behavior of toJSON() to base64(url) encode BufferSource/ArrayBuffer


2022-03-08
[16:08:39.0052] <TabAtkins>
This is generally where we discuss webidl stuff, yeah

[16:09:08.0380] <TabAtkins>
Or just in the issue tracker itself, which is probably better for a design discussion like what you seem to be talking about

[01:58:48.0998] <ÂæêÈ´òÈäò>
hi,all
I found an accident
https://github.com/mdn/browser-compat-data/issues/15096


[04:45:13.0370] <zcorpan>
How are we using the "impacts documentation" label? Should the label be removed after fixing MDN? (I guess maybe not, since MDN is probably not the only interested party for documentation)

[04:46:00.0656] <zcorpan>
Should there be a separate "needs edits on MDN" label?

[04:48:53.0500] <sideshowbarker>
yeah, I use/follow the ‚Äúimpacts documentation‚Äù label to keep track of changes that will require updates to MDN

[04:49:52.0233] <sideshowbarker>
in theory it could affect other docs, but in practice I don‚Äôt know of any docs affected other than MDN

[04:50:21.0117] <sideshowbarker>
and personally I have never removed that label from anything, even after changes to MDN have been made

[04:51:08.0315] <sideshowbarker>
IMHO we don‚Äôt need a separate "needs edits on MDN" label, because that‚Äôs what "impacts documentation" already is in practice

[04:52:13.0416] <zcorpan>
ok. so leaving the label means there may be closed issues with the label that still needs MDN edits, and some that don't

[04:52:23.0788] <sideshowbarker>
yeah

[04:52:40.0712] <sideshowbarker>
(incidentally, note that we also have the @whatwg/documentation team that can be Cc‚Äôd on issues and PRs)

[04:54:58.0012] <zcorpan>
Removing the label seems nice though since then 0 closed issues with the label = good code health

[04:55:17.0099] <sideshowbarker>
yeah, I agree it would

[04:55:42.0079] <sideshowbarker>
one wrinkle in general is that somebody would need to remember to actually remove the label

[04:56:54.0967] <zcorpan>
The documentation team can have a regular triage of closed issues

[04:57:20.0970] <sideshowbarker>
yeah I would certainly be happy to participate in that

[05:01:10.0104] <zcorpan>
/me finds https://github.com/whatwg/meta/issues/111

[05:04:32.0610] <sideshowbarker>
I guess we‚Äôve been doing this for too long‚Ä¶ I think I can‚Äôt remember stuff we did in 2018 any more clearly than I can 2006 üòÜ

[05:05:19.0371] <zcorpan>
recent years is a blur

[12:04:57.0524] <ntim>
Domenic: I've updated https://github.com/whatwg/html/pull/7134 

[15:18:34.0542] <Luca Casonato>
It looks like api.csswg.org may be having some issues. My CI runs are failing on the fetch spec: https://github.com/whatwg/fetch/runs/5472598698?check_suite_focus=true

[15:19:27.0040] <Luca Casonato>
 * It looks like api.csswg.org may be having some issues. My CI runs are failing on the fetch spec: https://github.com/whatwg/fetch/runs/5472598698?check_suite_focus=true


2022-03-09
[17:01:07.0941] <sideshowbarker>
> <@lucacasonato:matrix.org> It looks like api.csswg.org may be having some issues. My CI runs are failing on the fetch spec: https://github.com/whatwg/fetch/runs/5472598698?check_suite_focus=true

https://drafts.csswg.org/ was wedged again for hours yesterday, so I reopened https://github.com/w3c/csswg-drafts/issues/6528#issuecomment-1061553682 ‚Äî which hasn‚Äôt been re-closed yet, so I don‚Äôt know if that means they‚Äôre expecting it to break again or what. Anyway I guess http://api.csswg.org/ and https://drafts.csswg.org/ are likely using the same backend.

[00:16:53.0392] <sideshowbarker>
Do we anywhere have in any spec a normative definition of the term _‚Äúsame-site‚Äù_?

[00:20:20.0464] <sideshowbarker>
I thought https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-site-header used to have at least a clear normative definition for  the `same-site` value of the `Sec-Fetch-Site` header ‚Äî and used that when I wrote up https://stackoverflow.com/questions/66115532/what-does-the-sec-fetch-site-header-mean-why-is-the-origin-header-undefined/66228794#66228794 ‚Äî but now even that spec no longer seems to make clear what it means by ‚Äúsame-site‚Äù (at least it‚Äôs not clear for developers reading the spec, in contrast to anybody who might be implementing it)

[00:20:43.0931] <Andreu Botella>
https://html.spec.whatwg.org/multipage/origin.html#same-site

[00:22:24.0002] <sideshowbarker>
Andreu Botella: OK thanks yeah I had seen that. So I guess that‚Äôs the best we‚Äôve got ‚Äî but I doubt it‚Äôs going to mean much to the average web developer reading it.

[00:22:54.0227] <Andreu Botella>
That seems to be the normative definition. I agree that it's not great for average devs

[00:22:55.0318] <sideshowbarker>
‚Ä¶it doesn‚Äôt even directly reference _‚Äúregistrable domain‚Äù_

[00:23:00.0837] <sideshowbarker>
yeah

[00:24:40.0777] <sideshowbarker>
I think the concept of ‚Äúregistrable domain‚Äù is very clear and intuitive to everybody, so I‚Äôm glad that was coined and we have that defined in (the URL spec) at least ‚Äî it‚Äôs been a big improvement over directly mentioning the public-suffix list and the ‚ÄúeTLD+1‚Äù term

[00:30:06.0469] <sideshowbarker>
by the way, I‚Äôm confused a bit by https://html.spec.whatwg.org/multipage/origin.html#sites, where we have the term ‚Äúsite‚Äù defined as this:
> A site is an opaque origin or a scheme-and-host

‚Ä¶while ‚Äúobtain a site‚Äù, in the common case, reduces defined as this:
> origin's scheme, origin's host's registrable domain

[00:30:20.0487] <sideshowbarker>
 * by the way, I‚Äôm confused a bit by https://html.spec.whatwg.org/multipage/origin.html#sites, where we have the term site defined as this:
> A site is an opaque origin or a scheme-and-host

 ‚Ä¶while ‚Äúobtain a site‚Äù, in the common case, reduces defined as this:

> origin's scheme, origin's host's registrable domain

[00:32:06.0507] <sideshowbarker>
I would have expected instead that the term ‚Äúsite‚Äù were defined as ‚ÄúA site is an opaque origin or a **scheme-and-registrable-domain**‚Äù

[00:32:39.0693] <sideshowbarker>
 * by the way, I‚Äôm confused a bit by https://html.spec.whatwg.org/multipage/origin.html#sites, where we have the term _‚Äúsite‚Äù_ defined as this:
> A site is an opaque origin or a scheme-and-host

‚Ä¶while ‚Äúobtain a site‚Äù, in the common case, reduces defined as this:
> origin's scheme, origin's host's registrable domain

[00:32:50.0115] <sideshowbarker>
 * by the way, I‚Äôm confused a bit by https://html.spec.whatwg.org/multipage/origin.html#sites, where we have the term ‚Äúsite‚Äù defined as this:
> A site is an opaque origin or a scheme-and-host

‚Ä¶while ‚Äúobtain a site‚Äù, in the common case, reduces defined as this:
> origin's scheme, origin's host's registrable domain

[00:59:00.0388] <annevk>
sideshowbarker: I think that's because an IP address is not a registrable domain

[00:59:55.0654] <annevk>
That is, I think I did it that way because of that, but as has been said above, it's all a blur üôÇ

[01:29:12.0874] <sideshowbarker>
 * by the way, I‚Äôm confused a bit by https://html.spec.whatwg.org/multipage/origin.html#sites, where we have the term ‚Äúsite‚Äù defined as this:
> A site is an opaque origin or a scheme-and-host

‚Ä¶while ‚Äúobtain a site‚Äù, in the common case, reduces to being defined as this:
> origin's scheme, origin's host's registrable domain

[05:00:14.0511] <Yoav Weiss>
The infra spec no longer seem to have a definition for pair: https://infra.spec.whatwg.org/#pair

[05:00:40.0881] <Yoav Weiss>
Is there something I should use instead? Or should I simply unlink uses for pair in specs?

[05:00:55.0601] <Jake Archibald>
https://infra.spec.whatwg.org/#tuples ?

[05:02:21.0534] <Yoav Weiss>
yeah, that kinda works

[05:13:02.0076] <Yoav Weiss>
Hmm, is bikeshed broken on the bots for other folks as well? Or am I holding it wrong? https://github.com/w3c/largest-contentful-paint/runs/5480497271?check_suite_focus=true

[05:47:56.0014] <sideshowbarker>
To find out which other specs reference the term ‚Äúsame site‚Äù from the HTML spec, is there some way I can do that? Shepard or Webref?

[05:49:23.0143] <Ms2ger üíâüíâ>
sideshowbarker: https://dontcallmedom.github.io/webdex/s.html

[05:49:30.0251] <Ms2ger üíâüíâ>
> Referenced in Cookies: HTTP State Management Mechanism, The Storage Access API, URL, Attribution Reporting, SMS One-Time Codes, Fetch Metadata

[05:49:42.0228] <sideshowbarker>
/me looks

[05:50:18.0283] <Ms2ger üíâüíâ>
(How cool is that, btw.)

[05:50:24.0863] <sideshowbarker>
> <@ms2ger:igalia.com> sideshowbarker: https://dontcallmedom.github.io/webdex/s.html

ah excellent ‚Äî thanks. I‚Äôm embarrassed I didn‚Äôt already know about this

[05:50:39.0682] <sideshowbarker>
> <@ms2ger:igalia.com> (How cool is that, btw.)

Indeed

[05:52:15.0579] <Ms2ger üíâüíâ>
I've only known about it for two weeks myself: https://www.w3.org/mid/e6cfe633-a041-e5ba-c12d-9ed7fce59e51@w3.org :)

[05:54:22.0959] <Yoav Weiss>
The CSSOM links from HTML (e.g. https://drafts.csswg.org/cssom-view/#run-the-resize-steps) seem broken..

[06:01:45.0378] <Ms2ger üíâüíâ>
https://github.com/w3c/csswg-drafts/issues/6725

[06:01:57.0758] <Ms2ger üíâüíâ>
They're down mostly every day at this point

[06:02:43.0081] <Ms2ger üíâüíâ>
You can try https://andreubotella.com/csswg-auto-build/

[06:08:18.0165] <annevk>
Yoav Weiss: I folded pair into tuple a while back as it had a syntax that people found confusing; sorry for the breakage

[06:08:40.0945] <annevk>
Yoav Weiss: context at https://github.com/whatwg/infra/pull/413 and linked issue

[06:09:39.0276] <Yoav Weiss>
No worries! tuple seems like a better fit for what LCP was doing anyway

[06:09:51.0757] <annevk>
TabAtkins: do you know about the Bikeshed breakage?

[06:10:25.0853] <annevk>
TabAtkins: `ImportError: cannot import name 'Literal' from 'typing' (/usr/local/lib/python3.7/typing.py)`

[06:21:09.0658] <Luca Casonato>
`make local` still works for me, but it seems CI runs are completely down now

[06:48:13.0827] <annevk>
Luca Casonato: did you get the latest Bikeshed though?

[06:48:32.0174] <annevk>
https://github.com/tabatkins/bikeshed/commit/c24e3ab95e18afe1ca9ee7e4a12269defbb5de0a is a pretty recent commit and seems related to the error above

[06:48:52.0693] <Luca Casonato>
updating now

[06:49:13.0021] <Luca Casonato>
yup, still works for me

[06:49:48.0910] <Luca Casonato>
I'm on Python 3.8.10. CI / build server looks to be on pyton 3.7.xx. maybe that makes a difference?

[08:01:31.0501] <Domenic>
OMG WebDex I've been looking for this for years.

[08:15:18.0800] <Fut Nada>
Hello. Is there anyone here who has access to a bookmaker site? I'm looking for one

[09:21:06.0320] <TabAtkins>
Yes, I knew about the issue; CI reported it to me right at the end of the day. Unfortunately the API server runs tip-of-tree Bikeshed (and is running 3.7, the version that was having problems), so it was broken until just now when I fixed it.

[09:24:48.0779] <TabAtkins>
(Anything running pip-installed Bikeshed should, to the best of my ability, always work great; at minimum, I verify it cycles green before I push new versions, and try to push versions soon after new fixes or features.)

[09:27:05.0078] <DerekNonGeneric>
Fut Nada: hello, this is not the channel for questions like that; this channel is for questions about specifications and has generally been about specification development and sometimes implementation

[10:00:00.0927] <annevk>
TabAtkins: thanks for the update!

[10:00:53.0128] <annevk>
It's so weird that GitHub doesn't jump to the latest attempt when you retrigger CI

[10:01:21.0986] <annevk>
 * It's so weird that GitHub doesn't jump to the latest attempt when you retrigger CI


2022-03-10
[01:33:04.0439] <sideshowbarker>
https://drafts.csswg.org/ currently wedged again

[01:35:24.0317] <sideshowbarker>
seriously considering to propose that for MDN and BCD we switch over to using https://andreubotella.com/csswg-auto-build/ URLs instead

[01:37:43.0522] <Andreu Botella>
That's maybe making it more official than I'm comfortable with atm üòÖ

[01:39:31.0653] <sideshowbarker>
Andreu Botella: well I was next gonna ask if you wouldn‚Äôt mind if I forked it to make https://github.com/w3c/css-specs/ üòÜ But I take it that you‚Äôd probably rather I didn‚Äôt do that

[01:43:49.0780] <Andreu Botella>
Before making it a W3C thing, we should definitely ask Peter Linss and see who is willing to fund work for the current server

[01:48:20.0740] <sideshowbarker>
well if the current server is broken by design, and we have an existence proof that we can achieve the same end result serving from GitHub pages ‚Äî as we do for specs for every single other W3C working group ‚Äî then I‚Äôm not sure it‚Äôs even very principled to encourage anybody to fund work on the current server. It‚Äôs not even clear to me what the money would be spent on, or how throwing more money at it would fix the underlying design problems. The money would be spent on completely rewriting it all? Or what?

[01:48:59.0954] <sideshowbarker>
 * well if the current server is broken by design, and we have an existence proof that we can achieve the same end result serving from GitHub pages ‚Äî as we do for specs for every single other W3C working group ‚Äî than I‚Äôm not sure it‚Äôs even very principled to encourage anybody to fund work on the current server. It‚Äôs not even clear to me what the money would be spent on, or how throwing more money at it would fix the underlying design problems. The money would be spent on completely rewriting it all? Or what?

[01:49:38.0971] <sideshowbarker>
 * well if the current server is broken by design, and we have an existence proof that we can achieve the same end result serving from GitHub pages ‚Äî as we do for specs for every single other W3C working group ‚Äî then I‚Äôm not sure it‚Äôs even very principled to encourage anybody to fund work on the current server. It‚Äôs not even clear to me what the money would be spent on, or how throwing more money at it would fix the underlying design problems. The money would be spent on completely rewriting it all? Or what?

[01:57:43.0822] <Andreu Botella>
I'm worried about making this setup serve the specs at their official‚Ñ¢ URLs, because Bikeshed's xref database is built by scraping the specs with Shepherd, so commits that introduce xrefs to a newly introduced term in a different spec will not show up until the next build

[01:58:00.0424] <Andreu Botella>
but I'm not sure if plinss's server handles this at all currently

[01:58:12.0642] <sideshowbarker>
I see

[04:49:43.0591] <Luca Casonato>
Could I get some reviews on https://github.com/whatwg/webidl/pull/1098 ?

[07:20:07.0189] <ntim>
annevk: hi, can you please merge/review https://github.com/whatwg/html/pull/7134 when you have time?

[07:20:22.0599] <ntim>
 * annevk: hi, can you please merge/review https://github.com/whatwg/html/pull/7134 when you have time?

[08:27:53.0426] <Dominic Farolino>
Is https://html.spec.whatwg.org/#dom-location-reload the only place that POST resubmission is defined in HTML?

[08:42:24.0838] <annevk>
Dominic Farolino: sounds plausible

[08:42:42.0407] <annevk>
Dominic Farolino: user-initiated navigations aren't really covered yet

[08:51:15.0951] <annevk>
ntim: nice catch from Domenic on the IDL attribute. Oops üôÇ

[08:54:23.0860] <Domenic>
I plan to make user-initiated navigations a bit more covered when merging https://wicg.github.io/navigation-api/#user-initiated-patches into HTML


2022-03-11
[03:15:19.0692] <annevk>
Sigh, GitHub moderation is the worst. When you get spam on a PR you cannot delete the comment. If you block the person before editing the comment to remove the spam, you cannot edit the comment until you first unblock the person. And reporting the comment still takes you through a needlessly long software wizard I'm no longer interested in using.

[03:21:13.0905] <Luca Casonato>
I wish there was a feature like in Discord, where when you block someone it asks you if the all comments that person posted in the last 1hr/24hrs/7d should be deleted/hidden. That'd be really useful

[03:40:20.0623] <annevk>
Matrix/Element does that too

[06:19:30.0681] <Timo Tijhof>
> <@domenicdenicola:matrix.org> We are reasonably confident in the "reference implementation" in jsdom/whatwg-url, which says that such URLs are parsed like browsers do. https://jsdom.github.io/whatwg-url/#url=aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvU3BlY2lhbDpCbGFua3BhZ2U/ZnJvbT1lbiZ0bz1lcyZjYW1wYWlnbj1hcnRpY2xlLXJlY29tbWVuZGF0aW9uJnBhZ2U9QXBvbGxvJTk2U295dXpfVGVzdF9Qcm9qZWN0&base=YWJvdXQ6Ymxhbms=

Thanks, that helps. With this, I traced it down to https://github.com/jsdom/whatwg-url/blob/a4cb13309246ca9ecf03404fdbf0d23ecaf114dd/lib/urlencoded.js#L10-L33 and https://github.com/jsdom/whatwg-url/blob/a4cb13309246ca9ecf03404fdbf0d23ecaf114dd/lib/percent-encoding.js#L20 which indeed is doing the critically important thing of ignoring things outside the known valid range and leaving them in-tact, whereas EcmaScript's decodeURIComponent throws an error for anything unexpected after a % sign.

I did actually (briefly) consider using jsdom originaly, but found that it (understandably) kind of makes maximum use of other internals. It seems it goes down to the level of code points and then brings all of TextEncoder into it all as well, and UintArray, etc. I struggled to find a minimal way to port that over.

I managed to make currently-failing test cases pass by replacing the blanket decodeURIComponent call with a loop over the string and then if the two chars after % are in-range, call decodeURIComponent on just But then found that this doesn't work for multi-byte characters, e.g. decoding `%7F%C3%BF` is only accepted when done at once, not when done chunk by chunk. The URL spec doesn't say that, but then again, the URL spec doesnt say to use decodeURI of course anyway, it says to work on bytes and code points and not return to UTF-8 strings until all the way done, which I can't do within ES5 I think, or at least not without a ton of other emulation code.

I did try forcing it by using String.fromCharCode(parseInt(chunk.slice(1), 16));`, but that just produced garbage.

I hate myself for this, but I managed to get all tests passing both old and new cases, by using a regex. That seemed simpler than trying to eagerly buffer up multiple %- chunks or re-implemenitng lower level code point mapping for multi-bytes.

The regex looks only for valid in-range percent encoded chunks and eagerly repeats this so that we always pass decodeURI as many at once as possible.

```
	function percent_decode(bytes) {
			return bytes.replace(/((%[0-9A-Fa-f]{2})*)/g, function(m, p1) {
				return decodeURIComponent(p1);
			});
	
	}
```

I feel dirty now, but it seems to hold up in my testing so far. Curious if anyone here knows of a better minimal way to get the multi-byte code points to work in ES5 without "a lot of code" and/or can poke holes in the above, preferably holes that didn't already exist in the previous version of the FT polyfill (which simply calls decodeURIComponent on the whole thing).

[08:57:31.0597] <annevk>
Ms2ger üíâüíâ: why is it synthetic settings objects/realms and not shadow settings objects/realms?

[09:01:28.0364] <annevk>
Ms2ger üíâüíâ: I'd also still like some kind of answer to the question I raised in my overall review comment

[09:03:16.0957] <annevk>
I'll leave these questions on the PR.

[09:30:58.0143] <annevk>
Timo Tijhof: that was a fun read. I'm bad at reading regexp, maybe add a comment, but that looks reasonable. It does look like it will fall over if folks are not using UTF-8 bytes, which is allowed. But perhaps that's acceptable in your case. Might also want to denote that.

[09:51:45.0268] <Timo Tijhof>
Thanks, that gives me a bit more confidence. The use case that led me to discover this bug in the FT polyfill is actually very much related to bytes that are not UTF-8 bytes.

Wikipedia uses UTF-8 for canonical URLs everywhere now and has for almost two decades now. But some of the earliest language editions (Specifically en.wikipedia, pl.wikipedia, and zh.wikipedia) used to use a different encoding, which our backend web server (MediaWiki PHP) continues to support to ensure URLs don't break. If the decoded string isn't valid UTF-8, it will on those wikis fallback to a legacy encoding. For en.wikipedia that is windows-1252, for pl.wikipedia iso-8859-2 and for zh.wikipeida/zh-hans windows-936 and zh/zh-hant windows-950.  As per https://codesearch.wmcloud.org/core/?q=fallback8bitEncoding%20%3D

For example, this URL is still supported: https://en.wikipedia.org/w/index.php?title=Apollo%96Soyuz_Test_Project

While we don't have any need to read the "correct" value of the title parameter in JavaScript, we do have many other query params we sometimes read client-side, and so having `new mw.Uri` (our in-house library) or `new URL` (polyfiled) throw unconditionally on those pages is a problem. It's fine if we can't read `searchParams.get('title')` correctly, so long as we can still do other things with it.

Our downstream task (which was meant to be closed by using the URL API) - https://phabricator.wikimedia.org/T106244

My PR (with docs now): https://github.com/Financial-Times/polyfill-library/pull/1173.

I'm still looking into improving the handling of incomplete multi-byte. We are unlikely to encounter those for any "valid" URLs, not even legacy ones, but it still seems better not to crash on those but do a replacement indeed like the standard does.

[09:53:56.0444] <Timo Tijhof>
> <@annevk:mozilla.org> Timo Tijhof: that was a fun read. I'm bad at reading regexp, maybe add a comment, but that looks reasonable. It does look like it will fall over if folks are not using UTF-8 bytes, which is allowed. But perhaps that's acceptable in your case. Might also want to denote that.

 * Thanks, that gives me a bit more confidence. The use case that led me to discover this bug in the FT polyfill is actually very much related to bytes that are not UTF-8 bytes.

Wikipedia uses UTF-8 for canonical URLs everywhere now and has for almost two decades now. But some of the earliest language editions (Specifically en.wikipedia, pl.wikipedia, and zh.wikipedia) used to use a different encoding, which our backend web server (MediaWiki PHP) continues to support to ensure URLs don't break. If the decoded string isn't valid UTF-8, it will on those wikis fallback to a legacy encoding. For en.wikipedia that is windows-1252, for pl.wikipedia iso-8859-2 and for zh.wikipeida/zh-hans windows-936 and zh/zh-hant windows-950.  As per https://codesearch.wmcloud.org/core/?q=fallback8bitEncoding%20%3D

For example, this URL is still supported: https://en.wikipedia.org/w/index.php?title=Apollo%96Soyuz_Test_Project

While we don't have any need to read the "correct" value of the title parameter in JavaScript, we do have many other query params we sometimes read client-side, and so having `new mw.Uri` (our in-house library) or `new URL` (polyfiled) throw unconditionally on those pages is a problem. It's fine if we can't read `searchParams.get('title')` correctly, so long as we can still do other things with it.

Our downstream task (which was meant to be closed by using the URL API) - https://phabricator.wikimedia.org/T106244

My PR (with docs now): https://github.com/Financial-Times/polyfill-library/pull/1173.

I'm still looking into improving the handling of incomplete multi-byte. We are unlikely to encounter those for any "valid" URLs, not even legacy ones, but it still seems better not to crash on those but do a replacement indeed like the standard does.

[09:54:05.0364] <annevk>
Timo Tijhof: so shouldn't you handle failure in that case and just return the input?

[09:54:37.0616] <annevk>
Timo Tijhof: and maybe rename to utf8_percent_decode

[09:54:59.0011] <Timo Tijhof>
> <@annevk:mozilla.org> Timo Tijhof: and maybe rename to utf8_percent_decode

Ack, yeah, I'm aware calling these bytes is wrong.

[09:55:05.0451] <annevk>
Timo Tijhof: e.g., consider %FF which can never decode as UTF-8

[09:55:38.0170] <Timo Tijhof>
> <@annevk:mozilla.org> Timo Tijhof: and maybe rename to utf8_percent_decode

 * Ack, yeah, I'm aware calling these bytes is wrong (though pre-existing name in the code).

[09:57:16.0540] <Timo Tijhof>
> <@annevk:mozilla.org> Timo Tijhof: and maybe rename to utf8_percent_decode

Hm.. so the issue there is that if you have %FF%20, my eager regex will feed them all (as it should for multibyte) and then fail in its entirely still. Returning that as literal or as replacement character would both be different from the spec. But I don't mind a bit of difference with the spec. This is meant to be a relatively loose polyfill I think, and not a full virtual machine :)

[09:59:39.0543] <annevk>
Yeah I mainly meant that you don't seem to handle failure at all at the moment. Other than rethrowing. You're right that sequences such as that make it trickier.

[10:00:00.0134] <Timo Tijhof>
Ack yeah, I'll add a localised try-catch if nothing else. Good point. 


2022-03-12
[21:02:56.0070] <Nicolae Vasile>
Hi. I've just joined and haven't used this webapp before. Where is the best place to ask a question?

[21:06:31.0483] <Andreu Botella>
You can ask here

[21:07:03.0098] <Andreu Botella>
But this room isn't very active outside of European and American working hours/days

[21:10:39.0197] <Nicolae Vasile>
Great, thanks! I'm hosting a Tomcat web server and I need it to send  "Cross-Origin-Opener-Policy" "Cross-Origin-Embedder-Policy" headers in the response. The documentation on how to configure Tomcat's web.xml references [this specification](https://fetch.spec.whatwg.org/) (I got here by clicking the chat link üòÄ) which includes those headers. but the documentation doesn't tell me how to actually implement those headers in the web.xml.

[21:12:22.0816] <Andreu Botella>
If the question is how to configure Tomcat to send those headers, it's not really the scope of this room. But if it's to what value to set them, then yeah.

[21:14:00.0958] <Nicolae Vasile>
Understood. I at the very least know what values I need fortunately.

[21:14:26.0044] <Nicolae Vasile>
I'll take my search somewhere else, thanks for your attention though!

[21:14:52.0233] <Andreu Botella>
you're welcome


2022-03-14
[05:16:44.0813] <weh_>
Hello

[07:35:42.0674] <Domenic>
annevk: I'd love to get resolution on https://github.com/whatwg/html/issues/2771#issuecomment-1063914309 (DOM insertion steps ordering). Do you really think having a centralized insertion steps algorithm for all of HTML is the best end state? I agree it's the most theoretically pure but I think it's a bit hard for readers, and doesn't seem to match implementations (which generally have some per-element override, e.g. https://source.chromium.org/chromium/chromium/src/+/main:third_party/blink/renderer/core/html/media/html_media_element.cc;l=818;drc=30309877d4b10434eeaa9f85e8ba00ca91c7d731

[07:39:59.0606] <annevk>
Domenic: yeah I could see dispatching to specific localname/namespace algorithms for the node being inserted, I'm not sure that tackles all scenarios and it would require rewriting of some logic as well I think

[07:40:31.0611] <annevk>
Domenic: in my mind the bigger issue around insertion is the stuff around <script> that nox was working on

[07:40:46.0885] <Domenic>
Hmm I see so more exactly match the implementations, and make the fact that we put it in a given section more reasonable instead of sketchy

[07:40:48.0347] <Domenic>
I like that

[07:51:57.0597] <Ms2ger üíâüíâ>
Domenic: I think you've been involved longer, so if you have a moment to check if my last comment in https://github.com/whatwg/html/pull/5339 makes sense, that'd be appreciated

[13:12:30.0990] <r3st>
Howdy all, I was wondering if anyone can point me to the specification about using the JavaScript pseudo-protocol in an href attribute ( forgive me if the terms are incorrect).

[13:13:01.0882] <r3st>
For example, 

<a href="javascript:...."></a>

[13:13:18.0798] <Andreu Botella>
https://html.spec.whatwg.org/multipage/browsing-the-web.html#javascript-protocol

[13:13:36.0854] <r3st>
Truly, you are a blessing

[13:13:51.0459] <r3st>
How did you find it? Teach a man to fish, etc etc

[13:14:24.0828] <Andreu Botella>
I've looked a few times through the navigation sections of the HTML spec, and I remember it being around there

[13:14:43.0889] <r3st>
Ah I see! A million thank yous for your help


2022-03-15
[18:23:56.0811] <iamanoobatwhatwg>
Hi

[18:23:58.0698] <iamanoobatwhatwg>
:)

[18:35:12.0264] <iamanoobatwhatwg>
what is webidl?

[07:02:33.0364] <bkardell>
> <@iamanoobatwhatwg:matrix.org> what is webidl?

https://en.wikipedia.org/wiki/Web_IDL

[07:16:55.0615] <Domenic>
https://webidl.spec.whatwg.org/#introduction

[12:39:40.0077] <Timo Tijhof>
> <@bkardell:igalia.com> https://en.wikipedia.org/wiki/Web_IDL

I noticed this article lacks an image. I'd like to upload one but a bit unsure about the license of the logo. The whatwg/whatwg.org repo defaults to CC-BY-4.0, but the subdirectory for resources defaults to public domain instead. The file was added by annevk last year, I think from the whatwg/webidl which again defaults to CC-BY-4.0 (ref https://github.com/whatwg/webidl/issues/1016). Could someone confirm which it is? Then I can upload it to Wikimedia Commons and add it to the article.

[12:42:38.0700] <Andreu Botella>
The logo was created with the express purpose of being placed in resources.whatwg.org, so I think public domain can be assumed


2022-03-16
[17:44:24.0309] <sideshowbarker>
Since the image sources are in https://github.com/whatwg/whatwg.org/ I guess the license that applies is https://github.com/whatwg/whatwg.org/blob/main/LICENSE, which is CC BY 4.0

