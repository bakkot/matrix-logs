2024-03-03
[06:01:34.0614] <annevk>
zcorpan: I vaguely recall there's an issue tracking something like that? I think there's also some things around navigation that are not being tracked accurately, such as the changes people want to make around bounce-tracking.


2024-03-04
[23:38:45.0022] <annevk>
PSA: https://whatwg.org/stages is live (might have to hard refresh for better table styling)

[05:26:46.0427] <farre>
so, I now have tests, and I checked epiphany (which should be webkit, right?), and load events for cross origin navigation of iframes is done there as well

[05:45:12.0303] <annevk>
That makes sense. That's been the behavior in browsers for literally decades and I think it's also what HTML still requires.

[05:46:10.0171] <annevk>
I don't really have a good idea for how to solve the issue here apart from not dispatching anything at all. Or maybe only dispatching for the initial load, but that will likely break things.

[05:49:12.0194] <farre>
I'm looking at aligning gecko to do this as well. it still leaves the timing issue, but at least it will be the same

[05:58:09.0393] <annevk>
Gecko doesn't fire an event currently?

[06:18:44.0864] <farre>
not when updating #hash, no

[07:08:25.0409] <annevk>
Wait what, firing a load event for that case doesn't sound right. I guess I missed something.

[07:08:35.0790] <annevk>
Looking forward to the tests. :-)

[07:33:47.0821] <farre>
np, I'll ping you a phabricator link tomorrow when I've run try. I'm planning on letting the tests get upstreamed from the gecko repo if you don't object

[07:45:34.0970] <annevk>
That seems fine. But if they don't match the specification please make sure they have `.tentative` in the name.


2024-03-06
[02:27:44.0703] <annevk>
emilio mfreed: I think the CSS WG should probably come up with the native appearance story as it should be the same for all form controls, no? We want something with intrinsic width and height that uses the border-box. There's a number of things that should continue to work, such as transform, positioning, visibility, but there's also a number of things that shouldn't, such as background, font, etc. However, both of those lists are continuously evolving and it seems unreasonable for HTML to be in charge of that?

I will file an issue later today to get the conversation started.

[06:27:19.0457] <Ms2ger>
annevk: hey, I was wondering if you have an idea when we could get a review of the shadowrealms pr

[06:34:15.0798] <annevk>
Ms2ger: last I heard implementers are skeptical on it. Has that changed? It's really hard to get a sense of the amount of buy-in this has beyond a handful of interested parties. Are there recent statements from Chromium and Gecko available?

[06:36:19.0151] <Ms2ger>
I can try to get statements if I can't find any

[06:38:44.0360] <annevk>
Ms2ger: thanks! For instance, https://github.com/tc39/proposal-shadowrealm/issues/401 is the latest I saw from mgaudet. Which I guess is not really saying no, but it's not an enthusiastic endorsement either and perhaps something we need more clarity on to prevent a future `setTimeout()` issue.

[06:41:06.0491] <Ms2ger>
That's fair

[06:49:37.0475] <annevk>
yulia | sick: for when you feel better ^^ (hope that's soon!)

[09:46:52.0702] <annevk>
emilio mfreed: https://github.com/w3c/csswg-drafts/issues/10039


2024-03-07
[17:11:55.0661] <Domenic>
Could use editor review on https://github.com/whatwg/html/pull/10043 (easy) and https://github.com/whatwg/html/pull/10168 (bigger)

[17:13:00.0495] <akaster>
Is it expected that cryptographic keys created by SubtleCrypto are stored in a fun and secure place like a Trusted Platform Module or Secure Enclave? 

[17:13:12.0704] <akaster>
Or would that just be a quality of implementation bonus

[00:56:52.0341] <freddy>
it's not expected and afaiu subtlecrypto predates wide availability and adoption of TPM / enclaves

[00:58:54.0939] <annevk>
Domenic: I'll leave the bigger one for zcorpan.

[01:23:24.0559] <annevk>
yulia | sick: https://github.com/w3c/trusted-types/issues/471 is probably of interest to you. Maybe also to littledan.

[01:24:10.0887] <annevk>
freddy: you too I suppose. Some of the research participants could really use a built-in sanitizer.

[01:24:19.0909] <emilio>
annevk: jarhar: Do you know what kind of styling differences do we want for the `<select>` case in https://github.com/w3c/csswg-drafts/issues/5998?

[01:25:04.0903] <emilio>
Basically, I think the main thing we really need is the non-replaced box stuff, but I'm not aware of all the intended differences between `base` and `none`

[01:25:07.0336] <annevk>
emilio: essentially we want to build something from the ground up, irrespective of auto/none styling.

[01:25:28.0194] <yulia | sick>
wow thats great

[01:25:29.0318] <emilio>
annevk: why? It seems virtually all the default `select` styles would be applicable to the "base" case

[01:26:17.0818] <yulia | sick>
(not really back yet)

[01:26:18.0951] <annevk>
emilio: the mechanism has to work for all form controls, not just `select`. So over-indexing on `select` doesn't seem useful.

[01:26:20.0224] <emilio>
annevk: modulo the `!important` stuff which right now can't be overridden by authors, but maybe we should just fix that

[01:27:00.0831] <emilio>
annevk: I guess I'm looking for a counter-example where it doesn't work. I've thought mostly about `<select>` and `<input switch>`, and seems not overcomplicating stuff would work for those at least

[01:27:55.0547] <emilio>
annevk: that is, the default styles for form controls are sorta reasonable, what is not customizable is the stuff inside them. And _that_ is fixable with appearance: base without weird hacks / internal mechanisms which are generally unsound

[01:33:12.0313] <annevk>
emilio: I don't think people want the base style to match the none style. They want something closer to the auto style, except not platform bound.

[01:35:39.0842] <annevk>
emilio: Also `select` like other form controls is currently undefined, except for like 3 properties?

[01:35:52.0404] <emilio>
annevk: I thought the point of `base` was basically give you control over the inner bits of the control. `none` already gives you something that is a functional control, and the system colors used there are in control of the UA, so can be changed. `border-radius` is the only tricky thing IMO

[01:36:11.0390] <emilio>
annevk: it doesn't have to be that way, select styles are fairly interoperable iirc?

[01:36:34.0841] <annevk>
No the point of `base` is to give somewhat unified cross-browser controls that are fully stylable, but also accessible, etc.

[01:37:06.0285] <annevk>
 * No the point of `base` is to give unified cross-browser controls that are fully stylable, but also accessible, etc.

[01:37:38.0502] <annevk>
I would expect some sort of consistency across `base` controls.

[01:37:44.0726] <emilio>
annevk: well, sure, my point is that `appearance: none` is that, except it doesn't let you style the stuff inside the control

[01:38:21.0753] <emilio>
and the "doesn't let you style stuff inside the control" part is solvable without weird shenanigans

[01:38:54.0884] <annevk>
It's not for checkboxes and it's also not really for other controls? Some of that might be fixable, but I don't think `none` always meets the bar. (And I'd rather `none` going forward actually mean `none`.)

[01:39:56.0338] <annevk>
(The stuff inside the control also has to be described in terms of CSS already for `base`, to be clear.)

[01:40:50.0774] <emilio>
Sure, but that's not an issue because we can do whatever in the UA sheet for inner elements / pseudos inside `base`, and have it not affect `none` / `auto`

[01:41:10.0354] <emilio>
You're right that checkboxes are an issue here, but those are the exception rather than the rule

[01:46:15.0732] <annevk>
emilio: I think the pseudo elements should also work for `none`.

[01:47:10.0786] <emilio>
annevk: that doesn't match how `none` behaves right now, but maybe, if we can get away with it? But that means that we should make the `none` behavior also describable via css.

[02:00:48.0332] <annevk>
emilio: the solution has to work for checkboxes too though. But I also think we want the freedom to be able to change certain things (such as the default size) for `base` to make them really good defaults for people to build on.

[02:01:46.0283] <annevk>
As such I don't really believe in trying to shoehorn it into the existing mess (which I do agree we should clean up as well, but I think we're more limited there in what can be done).

[02:06:35.0610] <emilio>
annevk: I don't see why it wouldn't work for checkboxes fwiw, assuming checkboxes gain some pseudo tree (which they'd need to, right), you could style that however you want. You'd need some special code to not render that tree in the `none` case, to match existing behavior, but that seems feasible

[02:08:00.0015] <emilio>
annevk: I don't think we want css magic, because whatever that magic is we're going to need to explain it to authors. And this is exactly the kind of magic that we don't want to expose to the web (https://wiki.csswg.org/faq#selectors-that-depend-on-layout)

[02:09:02.0741] <emilio>
Anyways I need to go do some work, but I think we can get away without CSS magic.

[02:37:39.0827] <annevk>
I think it's fine to have "magic" when it's constrained. This wouldn't really become a generic thing, it's just for form controls. You want the magic to be more tightly scoped it seems, but I'd rather have it a little wider to decouple things a little more.

[06:54:53.0415] <jarhar>
for appearance:base select as i am trying to implement it, most of the actual new styles are on the button and the datalist children, not the select itself, which makes it easier to put in the UA stylesheet. It looks kind of bad imo to still have the border and other stuff there from the appearance:auto select around the parent element of the button, but maybe once i finish implementing appearance:base and demo it to some more people then maybe nobody will care that much and we can just leave the UA rules in there.

[06:55:14.0179] <jarhar>
if you look at the "actual" and "expected" pictures of this test output, you can see what difference the built-in borders make: https://chromium-layout-test-archives.storage.googleapis.com/results.html?json=chromium/try/linux-rel/1729863/blink_wpt_tests%20%28with%20patch%29/full_results_jsonp.js

[06:55:53.0010] <jarhar>
also it should probably be completely the same across browsers by default when using appearance:base, and if we aren't using the same UA border rule for select then that wouldn't be the case anymore

[09:01:03.0560] <jub0bs>
Hey all. I have some more thoughts about CORS...

[09:04:14.0077] <jub0bs>
A common misunderstanding (dispelled by annevk [long ago](https://twitter.com/annevk/status/948831079649169408)) about CORS is that it is some kind of defence. I think some overeager middleware libraries can be blamed for this, but I'm starting to wonder whether CORS error messages in Chrome specifically could be improved:

> Access to fetch at 'https://example.org' from origin 'https://example.com' has been _blocked by CORS policy_. [...]

My emphasis.


[09:06:03.0131] <jub0bs>
The phrase "blocked by CORS policy" seems to mislead some practitioners into conflating the effects of the SOP and CORS. How about something like the following message instead?

> Access to fetch at 'https://example.org' from origin 'https://example.com' has been blocked because the requested resource's CORS policy is insufficiently permissive. [...]

[09:06:49.0810] <jub0bs>
 * A common misunderstanding (dispelled by annevk [long ago](https://twitter.com/annevk/status/948831079649169408)) about CORS is that it is some kind of defence. I think some overeager middleware libraries can be blamed for this, but I'm starting to wonder whether CORS error messages in Chrome specifically could be improved:

> Access to fetch at 'https://example.org' from origin 'https://example.com' has been _blocked by CORS policy_. \[...\]

(my emphasis)

[09:07:06.0363] <jub0bs>
 * The phrase "blocked by CORS policy" seems to mislead some practitioners into conflating the effects of the SOP and CORS. How about something like the following message instead?

> Access to fetch at 'https://example.org' from origin 'https://example.com' has been blocked _because the requested resource's CORS policy is insufficiently permissive_. \[...\]

(my emphasis)

[09:07:44.0328] <jub0bs>
 * A common misunderstanding (dispelled by annevk [long ago](https://twitter.com/annevk/status/948831079649169408)) about CORS is that it is some kind of defence. I think some overeager middleware libraries can be blamed for this, but I'm starting to wonder whether CORS error messages (in Chrome specifically) could be improved:

> Access to fetch at 'https://example.org' from origin 'https://example.com' has been _blocked by CORS policy_. \[...\]

(my emphasis)

[09:07:50.0053] <jub0bs>
 * A common misunderstanding (dispelled by annevk [long ago](https://twitter.com/annevk/status/948831079649169408)) about CORS is that it is some kind of defence. I think some overeager middleware libraries can be blamed for this, but I'm starting to wonder whether CORS error messages (in Chromium specifically) could be improved:

> Access to fetch at 'https://example.org' from origin 'https://example.com' has been _blocked by CORS policy_. \[...\]

(my emphasis)

[09:08:26.0705] <jub0bs>
 * A common misunderstanding (dispelled by annevk [long ago](https://twitter.com/annevk/status/948831079649169408)) about CORS is that it is some kind of defence. I think some overeager middleware libraries can be blamed for this confusion, but I'm starting to wonder whether CORS error messages (in Chromium specifically) could be improved:

> Access to fetch at 'https://example.org' from origin 'https://example.com' has been _blocked by CORS policy_. \[...\]

(my emphasis)

[09:10:02.0756] <jub0bs>
More verbose, but clearer IMHO.

[09:10:21.0322] <jub0bs>
 * 1. A common misunderstanding (dispelled by annevk [long ago](https://twitter.com/annevk/status/948831079649169408)) about CORS is that it is some kind of defence. I think some overeager middleware libraries can be blamed for this confusion, but I'm starting to wonder whether CORS error messages (in Chromium specifically) could be improved:

> Access to fetch at 'https://example.org' from origin 'https://example.com' has been _blocked by CORS policy_. \[...\]

(my emphasis)

[09:10:37.0164] <jub0bs>
 * One: A common misunderstanding (dispelled by annevk [long ago](https://twitter.com/annevk/status/948831079649169408)) about CORS is that it is some kind of defence. I think some overeager middleware libraries can be blamed for this confusion, but I'm starting to wonder whether CORS error messages (in Chromium specifically) could be improved:

> Access to fetch at 'https://example.org' from origin 'https://example.com' has been _blocked by CORS policy_. \[...\]

(my emphasis)

[09:17:59.0468] <jub0bs>
Two: Some folks attempt to solve their CORS issues by including an `Origin` header in their request. Of course, because `Origin` is a [forbidden request-header name](https://fetch.spec.whatwg.org/#forbidden-request-header), user agents deny clients' attempts to include such a header in a request. The XHR API is vocal about it and issues an error message:

```
httpRequest = new XMLHttpRequest();
httpRequest.open('GET', 'https://www.example.com', true);
httpRequest.setRequestHeader("Origin", "http://localhost")
httpRequest.send(null);
```

> Refused to set unsafe header "Origin"

However, the Fetch API denies such attempts silently:

```
fetch('https://example.com', {headers: {origin: 'http://localhost'}});
```
(no error message about Origin being unsafe)

[09:18:41.0764] <jub0bs>
Shouldn't the Fetch Api be more vocal about attempts to include unsafe headers in requests?

[09:18:49.0528] <jub0bs>
 * Shouldn't the Fetch API be more vocal about attempts to include unsafe headers in requests?

[09:19:02.0199] <jub0bs>
 * Shouldn't the Fetch API be more vocal about those misguided attempts to include unsafe headers in requests?

[09:23:03.0508] <jub0bs>
Three: Some folks also attempt to solve their CORS issues by including CORS _response_ headers (such as `Access-Control-Allow-Origin`) in their request, which may in fact make their CORS issues worth if the requested resource's CORS policy doesn't allow arbitrary request headers. In connection to [my second point above](https://matrix.to/#/!AGetWbsMpFPdSgUrbs:matrix.org/$2ipzTHms8MptHtnnrbf9PtwDdqpv0bObDd5yJGIFYc8?via=matrix.org&via=mozilla.org&via=igalia.com), I think there is a case for adding CORS response headers to the list of forbidden request-header names. I'm conscious that this could break existing clients, but including such CORS response headers to a request is almost always a mistake anyway.

[09:23:15.0747] <jub0bs>
 * Three: Some folks also attempt to solve their CORS issues by including CORS _response_ headers (such as `Access-Control-Allow-Origin`) in their request, which may in fact make their CORS issues worse if the requested resource's CORS policy doesn't allow arbitrary request headers. In connection to [my second point above](https://matrix.to/#/!AGetWbsMpFPdSgUrbs:matrix.org/$2ipzTHms8MptHtnnrbf9PtwDdqpv0bObDd5yJGIFYc8?via=matrix.org&via=mozilla.org&via=igalia.com), I think there is a case for adding CORS response headers to the list of forbidden request-header names. I'm conscious that this could break existing clients, but including such CORS response headers to a request is almost always a mistake anyway.

[09:23:28.0373] <jub0bs>
 * Three: Some folks also attempt to solve their CORS issues by including CORS _response_ headers (such as `Access-Control-Allow-Origin`) in their request, which may in fact make their CORS issues worse if the requested resource's CORS policy doesn't allow arbitrary request-header names. In connection to [my second point above](https://matrix.to/#/!AGetWbsMpFPdSgUrbs:matrix.org/$2ipzTHms8MptHtnnrbf9PtwDdqpv0bObDd5yJGIFYc8?via=matrix.org&via=mozilla.org&via=igalia.com), I think there is a case for adding CORS response headers to the list of forbidden request-header names. I'm conscious that this could break existing clients, but including such CORS response headers to a request is almost always a mistake anyway.

[09:24:07.0036] <jub0bs>
 * Three: Some folks also attempt to solve their CORS issues by including CORS _response_ headers (such as `Access-Control-Allow-Origin`) in their request, which may in fact make their CORS issues worse if the requested resource's CORS policy doesn't allow arbitrary request-header names. In connection to [my second point above](https://matrix.to/#/!AGetWbsMpFPdSgUrbs:matrix.org/$2ipzTHms8MptHtnnrbf9PtwDdqpv0bObDd5yJGIFYc8?via=matrix.org&via=mozilla.org&via=igalia.com), I think there is a case for adding all CORS response headers (`Access-Control-Allow-*` and `Access-Control-Max-Age`) to the list of forbidden request-header names. I'm conscious that this could break existing clients, but including such CORS response headers to a request is almost always a mistake anyway.

[09:24:22.0362] <jub0bs>
 * Three: Some folks also attempt to solve their CORS issues by including CORS _response_ headers (such as `Access-Control-Allow-Origin`) in their request, which may in fact make their CORS issues worse if the requested resource's CORS policy doesn't allow arbitrary request-header names. In connection to [my second point above](https://matrix.to/#/!AGetWbsMpFPdSgUrbs:matrix.org/$2ipzTHms8MptHtnnrbf9PtwDdqpv0bObDd5yJGIFYc8?via=matrix.org&via=mozilla.org&via=igalia.com), I think there is a case for adding all CORS response headers (`Access-Control-Allow-*` and `Access-Control-Max-Age`) to the list of forbidden request-header names. I'm conscious that such a change could break existing clients, but including such CORS response headers to a request is almost always a mistake anyway.

[09:26:13.0351] <jub0bs>
 * Two: Some folks attempt to solve their CORS issues by including an `Origin` header in their request. Of course, because `Origin` is a [forbidden request-header name](https://fetch.spec.whatwg.org/#forbidden-request-header), user agents deny clients' attempts to include such a header in a request. The XHR API is vocal about it and issues an error message:

```
httpRequest = new XMLHttpRequest();
httpRequest.open('GET', 'https://www.example.com', true);
httpRequest.setRequestHeader("Origin", "http://localhost")
httpRequest.send(null);
```
In Chrome:
> Refused to set unsafe header "Origin"


However, the Fetch API denies such attempts silently:

```
fetch('https://example.com', {headers: {origin: 'http://localhost'}});
```

(no error message about Origin being unsafe)

[09:26:28.0507] <jub0bs>
 * Two: Some folks attempt to solve their CORS issues by including an `Origin` header in their request. Of course, because `Origin` is a [forbidden request-header name](https://fetch.spec.whatwg.org/#forbidden-request-header), user agents deny clients' attempts to include such a header in a request. The XHR API is vocal about it and issues an error message:

```
httpRequest = new XMLHttpRequest();
httpRequest.open('GET', 'https://www.example.com', true);
httpRequest.setRequestHeader("Origin", "http://localhost")
httpRequest.send(null);
```

In Chrome:

> Refused to set unsafe header "Origin"

And in Firefox:

> Attempt to set a forbidden header was denied: Origin

However, the Fetch API denies such attempts silently:

```
fetch('https://example.com', {headers: {origin: 'http://localhost'}});
```

(no error message about Origin being unsafe)

[09:27:57.0444] <jub0bs>
 * Two: Some folks attempt to solve their CORS issues by including an `Origin` header in their request. Of course, because `Origin` is a [forbidden request-header name](https://fetch.spec.whatwg.org/#forbidden-request-header), user agents deny clients' attempts to include such a header in a request. The XHR API is vocal about it and issues an error message:

```
httpRequest = new XMLHttpRequest();
httpRequest.open('GET', 'https://www.example.com', true);
httpRequest.setRequestHeader("Origin", "http://localhost")
httpRequest.send(null);
```

In Chrome:

> Refused to set unsafe header "Origin"

And in Firefox:

> Attempt to set a forbidden header was denied: Origin

However, the Fetch API denies such attempts silently:

```
fetch('https://example.com', {headers: {origin: 'http://localhost'}});
```

(no error message about `Origin` being unsafe, [per the Fetch standard](https://fetch.spec.whatwg.org/#headers-validate))

[09:28:50.0012] <jub0bs>
 * Two: Some folks attempt to solve their CORS issues by including an `Origin` header in their request. Of course, because `Origin` is a [forbidden request-header name](https://fetch.spec.whatwg.org/#forbidden-request-header), user agents deny clients' attempts to include such a header in a request. The XHR API is vocal about it and issues an error message:

```
httpRequest = new XMLHttpRequest();
httpRequest.open('GET', 'https://www.example.com', true);
httpRequest.setRequestHeader("Origin", "http://localhost")
httpRequest.send(null);
```

In Chrome and Safari:

> Refused to set unsafe header "Origin"

And in Firefox:

> Attempt to set a forbidden header was denied: Origin

However, the Fetch API denies such attempts silently:

```
fetch('https://example.com', {headers: {origin: 'http://localhost'}});
```

(no error message about `Origin` being unsafe, [per the Fetch standard](https://fetch.spec.whatwg.org/#headers-validate))

[09:30:20.0272] <jub0bs>
 * Three: Many people also attempt to solve their CORS issues by including CORS _response_ headers (such as `Access-Control-Allow-Origin`) in their request, which may in fact make their CORS issues worse if the requested resource's CORS policy doesn't allow arbitrary request-header names. In connection to [my second point above](https://matrix.to/#/!AGetWbsMpFPdSgUrbs:matrix.org/$2ipzTHms8MptHtnnrbf9PtwDdqpv0bObDd5yJGIFYc8?via=matrix.org&via=mozilla.org&via=igalia.com), I think there is a case for adding all CORS response headers (`Access-Control-Allow-*` and `Access-Control-Max-Age`) to the list of forbidden request-header names. I'm conscious that such a change could break existing clients, but including such CORS response headers to a request is almost always a mistake anyway.

[09:35:06.0451] <annevk>
jub0bs: for 1/2, improving warning messages is probably best filed directly with web browsers. Maybe sideshowbarker has done some work on these in the past perhaps. I'd certainly be open to reviewing WebKit patches that improve this. For 3, I think that's also best done as a warning message by web browsers. I wouldn't want to constrain what people can do with HTTP at the API level, but giving them a hint they're likely making a mistake seems reasonable.

[09:39:17.0034] <jub0bs>
annevk: Thanks. I was hoping to catch some browser folks here, actually. As for 3, I believe a warning would be a good middle ground.

[15:51:29.0827] <Luke Warlow>
Could I get bug edit permissions on whatwg/html for labelling issues?


2024-03-08
[16:32:52.0996] <Domenic>
> <@lwarlow:igalia.com> Could I get bug edit permissions on whatwg/html for labelling issues?

Invite sent

[16:50:03.0046] <sideshowbarker>
jub0bs: If you raise bugs and Cc me, I would be happy to write browser patches for adding warnings or improving existing ones.

And while we‚Äôre at it, I think we should also try to get a patch landed to make Chrome stop emitting the _‚ÄúIf an opaque response serves your needs, set the request's mode to 'no-cors' to fetch the resource with CORS disabled"_ message.

‚Ä¶because to 99.99% or whatever of web developers, that message is in practice the complete opposite of being helpful to them.

[01:29:02.0220] <jub0bs>
sideshowbarker: True. Many people believe that setting the request's mode to `'no-cors`' will magically resolve their CORS issues.

[01:30:14.0072] <jub0bs>
 * sideshowbarker: Thanks for your reply. I'll open a couple of bugs asap.
True about `'no-cors'`: many people believe that setting the request's mode to `'no-cors`' will magically resolve their CORS issues. Perhaps this part of the error message is more harmful than helpful.

[01:30:24.0340] <jub0bs>
 * sideshowbarker: Thanks for your reply. I'll open a couple of bugs asap.
True about `'no-cors'`: many people believe that setting the request's mode to `'no-cors`' will magically resolve their CORS issues. Perhaps this part of the error message is more misleading than helpful.

[01:31:04.0121] <jub0bs>
 * sideshowbarker: Thanks for your reply. I'll open a couple of bugs asap.
True about `'no-cors'`: many people believe that setting the request's mode to `'no-cors'` will magically resolve their CORS issues. Perhaps this part of the error message is more misleading than helpful.

[01:31:19.0221] <jub0bs>
 * sideshowbarker: Thanks for your reply. I'll open a couple of bugs asap.
True about `'no-cors'`: many people believe that setting their request's mode to `'no-cors'` will magically resolve their CORS issues. Perhaps this part of the error message is more misleading than helpful.

[02:07:28.0680] <zcorpan>
jub0bs: yeah, saying it was blocked by the same-origin policy would make more sense

[02:08:45.0835] <zcorpan>
But in the end the message should probably suggest reasonable options

[03:55:32.0711] <smaug>
https://html.spec.whatwg.org/multipage/common-dom-interfaces.html#reflecting-content-attributes-in-idl-attributes:reflected-idl-attribute-31 is somehow oddly written

[04:27:54.0466] <smaug>
first there are some items, and after them actual getter and setter steps. But what is for example the first item? Is that part of some algorithm or is it not?

[05:12:31.0223] <annevk>
smaug: the first list item is introducing a shorthand, used in the remaining list items for defining infrastructure

[05:13:46.0167] <annevk>
I do agree it's a bit strange, but I also wasn't sure how to refactor it when I last fixed some reflecting stuff.

[06:32:47.0877] <Dominic Farolino>
https://html.spec.whatwg.org/C#becomes-connected happens when the insertion steps for an element are called *and* it is "connected". But can the insertion steps ever be called for an element that's _disconnected_?

[07:44:24.0592] <Jake Archibald>
Folks who are familiar with `delegatesFocus`‚Ä¶ what are the use-cases? Is it much different to putting everything in the shadow root in a `<label>` pointing to the field?

[09:15:04.0715] <keithamus>
Jake Archibald: or a custom button or similar.

[09:17:27.0723] <keithamus>
https://github.com/muan/input-duration-element an example in the real world.

[09:21:52.0084] <Jake Archibald>
Yeah, support for `.focus()` is nice. I guess I don't always want the "clicking anything in the shadow root delegates focus to one element" thing


2024-03-09
[22:10:02.0761] <Domenic>
IIRC it was mainly added because we knew built-in controls like `<input type=date>` had that behavior.


2024-03-10
[19:28:37.0598] <dean.highpower>
Hello, does anyone know about the "willful violation of RFC 5322" note in section 4.10.5.1.5 Email state of the whatwg HTML spec? The comment raises some concern for me, since RFC-5322 is not the appropriate standard to find the syntax of email addresses as used on the public Internet today to route email. The correct standard is RFC-5321, which defines the SMTP protocol and includes a grammar for Mailbox which is what most people think of as an email address. This is what people sometimes call the "envelope" address.

The RFC-5322 document specifies the format of the email message content, not the protocol used to transport mail.

So, yeah: you should not follow RFC-5322, but you should follow RFC-5321.


[23:40:55.0276] <annevk>
dean.highpower: there's a long discussion in https://github.com/whatwg/html/issues/4562 without much progress, though someone from the i18n WG might make another attempt this year.

[04:27:18.0288] <judekeyser>
Hello, I badly apologize if the question does not fit this room, but I'm having trouble understanding a piece of JavaScript code and no one could help me in regular javascript servers. The code I'm concerned with is the following (ready to use):
```js
(async () => {
    const stream = (function* chunks(json) {
        const jsonString = JSON.stringify(json);
        const jsonBytes = new TextEncoder().encode(jsonString);
    
        let index = 0;
        while(index < jsonBytes.length) {
            const i = index;
            const j = Math.min(jsonBytes.length, i + 10);
    
            const slice = jsonBytes.slice(i, j);    // LINE (A)
            index = j;
            yield slice;
        }
    })({"Hello!": [2023, 2024 ]});
    
    const jsonBack = await new Response(new ReadableStream({
        type: "bytes",
        start: function(controller) {
            for(const chunk of stream) {
                controller.enqueue(chunk);
            }
            controller.close();
        }
    })).json();
    
    console.log(jsonBack);
})()
```
this code works as expected (google chrome, firefox; latest versions). However, when I replace in line A, `.slice` with `.subarray`, I get different kind of issues, telling me the JSON ends abnormally (in both browsers). I've crawled the official specification of the different API's, and I couldn't find a single clue about whether or not the version with `.subarray` violates the specification. 

For what is worth, turning `.json()` to `.text()` confirms that in the `.subarray` case, only the first chunk seems to be taken into account. I assume (but not sure about it) the same happens for `.json()`.

My question, to make it clear, is: is the current code with `.slice` already violating a point of the specification; and is the version with `.subarray` violates it and how? Could it be a browser bug, common to both Firefox and Google Chrome? Many thanks in advance! This issue puzzles me a lot for some days now

[04:56:06.0470] <judekeyser>
 * Hello, I badly apologize if the question does not fit this room, but I'm having trouble understanding a piece of JavaScript code and no one could help me in regular javascript servers. The code I'm concerned with is the following (ready to use):

```js
(async () => {
    const stream = (function* chunks(json) {
        const jsonString = JSON.stringify(json);
        const jsonBytes = new TextEncoder().encode(jsonString);
    
        let index = 0;
        while(index < jsonBytes.length) {
            const i = index;
            const j = Math.min(jsonBytes.length, i + 10);
    
            const slice = jsonBytes.slice(i, j);    // LINE (A)
            index = j;
            yield slice;
        }
    })({"Hello!": [2023, 2024 ]});
    
    const jsonBack = await new Response(new ReadableStream({
        type: "bytes",
        start: function(controller) {
            for(const chunk of stream) {
                controller.enqueue(chunk);
            }
            controller.close();
        }
    })).json();
    
    console.log(jsonBack);
})()
```

this code works as expected (google chrome, firefox; latest versions). However, when I replace in line A, `.slice` with `.subarray`, I get different kind of issues, telling me the JSON ends abnormally (in both browsers). I've crawled the official specification of the different API's, and I couldn't find a single clue about whether or not the version with `.subarray` violates the specification.

For what is worth, turning `.json()` to `.text()` confirms that in the `.subarray` case, only the first chunk seems to be taken into account. I assume (but not sure about it) the same happens for `.json()`.

My question, to make it clear, is: is the current code with `.slice` already violating a point of the specification; and is the version with `.subarray` violating it and how? Could it be a browser bug, common to both Firefox and Google Chrome? Many thanks in advance! This issue puzzles me a lot for some days now

[07:07:32.0548] <jub0bs>
> <@zcorpan:mozilla.org> But in the end the message should probably suggest reasonable options

Do you mean "reasonable options" for fixing the CORS error? I'm not sure I can think of more than what I've already suggested, tbh. One difficulty is that browsers are often left with insufficient contextual information about a preflight failure to produce a helpful error message. For a typical example, see https://jub0bs.com/posts/2023-02-08-fearless-cors/#9-ease-troubleshooting-by-eschewing-shortcuts-during-preflight

[07:09:07.0425] <jub0bs>
> <@zcorpan:mozilla.org> But in the end the message should probably suggest reasonable options

 * Do you mean "reasonable options" for fixing the CORS error? I'm not sure I can think of more than what I've already suggested, tbh. One difficulty is that browsers are often left with insufficient contextual information about a preflight failure to produce a helpful CORS error message. For a typical example, see https://jub0bs.com/posts/2023-02-08-fearless-cors/#9-ease-troubleshooting-by-eschewing-shortcuts-during-preflight

[08:11:15.0991] <judekeyser>
> <@judekeyser:matrix.org> Hello, I badly apologize if the question does not fit this room, but I'm having trouble understanding a piece of JavaScript code and no one could help me in regular javascript servers. The code I'm concerned with is the following (ready to use):
> 
> ```js
> (async () => {
>     const stream = (function* chunks(json) {
>         const jsonString = JSON.stringify(json);
>         const jsonBytes = new TextEncoder().encode(jsonString);
>     
>         let index = 0;
>         while(index < jsonBytes.length) {
>             const i = index;
>             const j = Math.min(jsonBytes.length, i + 10);
>     
>             const slice = jsonBytes.slice(i, j);    // LINE (A)
>             index = j;
>             yield slice;
>         }
>     })({"Hello!": [2023, 2024 ]});
>     
>     const jsonBack = await new Response(new ReadableStream({
>         type: "bytes",
>         start: function(controller) {
>             for(const chunk of stream) {
>                 controller.enqueue(chunk);
>             }
>             controller.close();
>         }
>     })).json();
>     
>     console.log(jsonBack);
> })()
> ```
> 
> this code works as expected (google chrome, firefox; latest versions). However, when I replace in line A, `.slice` with `.subarray`, I get different kind of issues, telling me the JSON ends abnormally (in both browsers). I've crawled the official specification of the different API's, and I couldn't find a single clue about whether or not the version with `.subarray` violates the specification.
> 
> For what is worth, turning `.json()` to `.text()` confirms that in the `.subarray` case, only the first chunk seems to be taken into account. I assume (but not sure about it) the same happens for `.json()`.
> 
> My question, to make it clear, is: is the current code with `.slice` already violating a point of the specification; and is the version with `.subarray` violating it and how? Could it be a browser bug, common to both Firefox and Google Chrome? Many thanks in advance! This issue puzzles me a lot for some days now

okay for what's worth, I understood what happened here. When enqueuing, the buffer is detached. This forces the length to go down to 0, which abruptly terminates my emission loop and I never emit more than 1 chunk, which is the cause of all issues. That's why I don't have the expected TypeError, since actually I never pass a detached buffer, as the loop terminates after.

I must say debugging this was kind of an adventure! Not sure if it's all clear for everyone that enqueue detaches the buffer, while reading the documentation. but I eventually found it, collecting all the pieces together

[09:12:52.0213] <dean.highpower>
That issue is regarding the extension of the Mailbox grammar in RFC-5321 to support Unicode, which is done in RFC-6531, section 3.3 Extended Mailbox Address Syntax. I should note that the analogous extensions of all the the RFC-5322 grammars is done in RFC-6532.
So yeah, get the basic US-ASCII syntax right by using the grammar in 5321, then extend for Unicode using 6531.


[09:15:24.0015] <dean.highpower>
The way the JSON Schema Validation standard handles this is to recognize two types: "email" for the US-ASCII style, and "idn-email" for an Mailbox address supporting Unicode.

[15:07:12.0598] <dean.highpower>
annevk: I put in my $0.02 in the github issue. Does anyone take the position that RFC-5322 (+RFC-6532) is the relevant standard for email address syntax? (As implied by the "willful violation" comment?)

[15:53:45.0357] <Tomz_plug>
Hello sorry for bothering Y'all, just wanna find out if anyone interested in cannabis and psychedelics products?

 I‚Äôm a supplier of quality cannabis and psychedelics products like shrooms, DMT, Lsd, Mdma, ketamine, chocolate bars, cart vapes,Clone cards, buds, wax, shatter, Edibles,distillates and some chill pills, Cashapp flip and many more products prescribed for patients as well. Let me know if you‚Äôre interested  by DMüî•üçÅ see products in our channel üëáüëáüëáüëá
https://t.me/hightime_markert


2024-03-11
[00:31:58.0118] <sideshowbarker>
Per https://html.spec.whatwg.org/multipage/common-microsyntaxes.html#rules-for-parsing-floating-point-number-values, when parsing floating-point number values should implementation return Infinity and NaN if that‚Äôs the number value a string parses to ‚Äî or instead should implementations treat Infinity and NaN be treated as errors ?

In that HTML spec algorithm itself, there‚Äôs nothing explicit about handling Infinity and NaN ‚Äî but in the WebIDL spec at https://webidl.spec.whatwg.org/#ref-for-idl-float‚ë†, I see:
> `Infinity`, `-Infinity` and `NaN` must not be used as the value of a `float` or `double`

[00:32:17.0859] <sideshowbarker>
 * Per https://html.spec.whatwg.org/multipage/common-microsyntaxes.html#rules-for-parsing-floating-point-number-values, when parsing floating-point number values: Should implementation return Infinity and NaN if that‚Äôs the number value a string parses to ‚Äî or instead should implementations treat Infinity and NaN be treated as errors ?

In that HTML spec algorithm itself, there‚Äôs nothing explicit about handling Infinity and NaN ‚Äî but in the WebIDL spec at https://webidl.spec.whatwg.org/#ref-for-idl-float‚ë†, I see:

> `Infinity`, `-Infinity` and `NaN` must not be used as the value of a `float` or `double`

[00:32:24.0521] <sideshowbarker>
 * Per https://html.spec.whatwg.org/multipage/common-microsyntaxes.html#rules-for-parsing-floating-point-number-values, when parsing floating-point number values: Should implementations return Infinity and NaN if that‚Äôs the number value a string parses to ‚Äî or instead should implementations treat Infinity and NaN be treated as errors ?

In that HTML spec algorithm itself, there‚Äôs nothing explicit about handling Infinity and NaN ‚Äî but in the WebIDL spec at https://webidl.spec.whatwg.org/#ref-for-idl-float‚ë†, I see:

> `Infinity`, `-Infinity` and `NaN` must not be used as the value of a `float` or `double`

[00:34:19.0030] <Domenic>
sideshowbarker: the HTML algorithm treats strings like "Infinity" or "NaN" as errors, if that's what you're asking. It's completely separate from the Web IDL algorithm, and has different call sites.

[00:38:02.0335] <annevk>
I'm not sure, but I think there's definitely a worry about changing the existing contract drastically as it'll impact many websites.

[00:38:25.0109] <sideshowbarker>
So I guess the only way that algorithm would ever return Inifinity or NaN is if it were given "Infinity" or "NaN"  as input? If so then I guess another way to state it is: The algorithm never returns "Infinity" or "NaN" ‚Äî it always returns either an actual number, or any error?

[00:38:39.0287] <sideshowbarker>
 * So I guess the only way that algorithm would ever return Inifinity or NaN is if it were given "Infinity" or "NaN"  as input? If so then I guess another way to state it is: The algorithm never returns "Infinity" or "NaN" ‚Äî it always returns either an actual number, or an error?

[00:39:54.0999] <annevk>
That looks correct, from a quick glance.

[00:43:53.0623] <Domenic>
The latter statement seems correct. But the former doesn't. If the algorithm were given "Infinity" or "NaN" as an input, then it would return error, not Infinity or NaN.

[00:45:41.0791] <sideshowbarker>
Right, sorry ‚Äî I misspoke there. I guess meant to say something more like, The only way something would end up getting _evaluated_ (not returned) by the algorithm as Inifinity or NaN would be if it the algorithm were given the strings "Infinity" or "NaN"  as input.

[03:42:41.0855] <hsivonen>
The ZWNJ and ZWJ rules at https://www.iana.org/assignments/idna-tables-12.0.0/idna-tables-12.0.0.xhtml#idna-tables-context affect whether a URL is fetchable, but the middle dot rule seems to affect only the URL bar display the domain. Has anyone researched what the effect of this list should be on browser behavior? https://www.iana.org/assignments/idna-tables-12.0.0/idna-tables-12.0.0.xhtml#idna-tables-context CC annevk 

[04:12:14.0154] <hsivonen>
> <@hsivonen:mozilla.org> The ZWNJ and ZWJ rules at https://www.iana.org/assignments/idna-tables-12.0.0/idna-tables-12.0.0.xhtml#idna-tables-context affect whether a URL is fetchable, but the middle dot rule seems to affect only the URL bar display the domain. Has anyone researched what the effect of this list should be on browser behavior? https://www.iana.org/assignments/idna-tables-12.0.0/idna-tables-12.0.0.xhtml#idna-tables-context CC annevk

Ooh. I noticed the "lookup" column just now. That explains fetchability vs. display.

[05:38:59.0688] <hsivonen>
annevk: I'm looking at the unit tests of the IDNA crate and have trouble believing what I'm seeing. Is it really intentional that empty DNS labels are allowed in URLs as long as the domain as a whole isn't empty? (Somehow I imagined that only a trailing empty label was allowed.) Browsers don't seem to treat hsivonen.fi.xn-- as equivalent to hsivonen.fi. , but I fail to find spec text that says so. What am I missing?

[05:42:21.0971] <annevk>
So `https://example..com/` parses. I think I was surprised by that as well. Not sure about `xn--` though.

[05:48:05.0652] <annevk>
hsivonen: I guess what's not clear is where decoding `xn--` fails. It does seem good for it to fail though as it would normalize away, which seems bad.

[05:48:59.0125] <hsivonen>
> <@annevk:matrix.org> hsivonen: I guess what's not clear is where decoding `xn--` fails. It does seem good for it to fail though as it would normalize away, which seems bad.

When reading the RFC, I don't see `xn--` failing at all.

[05:49:21.0422] <hsivonen>
annevk: But are other empty labels supposed to be allowed. Is hsivonen..fi really supposed to be allowed?

[05:49:45.0343] <annevk>
hsivonen: I think it has worked in all browsers since forever?

[05:50:36.0460] <annevk>
If we just did DNS there's a whole bunch of things we could ban, but we don't and therefore it's trickier.

[05:51:33.0997] <hsivonen>
> <@annevk:matrix.org> hsivonen: I think it has worked in all browsers since forever?

Ah, in Firefox the URL bar behavior depends on the URL scheme being there

[05:53:54.0222] <annevk>
I think per https://www.unicode.org/reports/tr46/#ProcessingStepPunycode and https://www.rfc-editor.org/rfc/rfc3492.html `xn--` is indeed expected to become the empty string. That seems like a bug though.

[05:57:35.0343] <annevk>
hsivonen: r? https://github.com/whatwg/encoding/pull/328

[06:58:17.0674] <zcorpan>
> <@jub0bs:matrix.org> Do you mean "reasonable options" for fixing the CORS error? I'm not sure I can think of more than what I've already suggested, tbh. One difficulty is that browsers are often left with insufficient contextual information about a preflight failure to produce a helpful CORS error message. For a typical example, see https://jub0bs.com/posts/2023-02-08-fearless-cors/#9-ease-troubleshooting-by-eschewing-shortcuts-during-preflight

I haven't checked closely what the status quo is, but the message can include a link at least. It seems Firefox currently links to https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS/Errors/CORSMissingAllowOrigin but Chrome doesn't have a link

[07:42:03.0913] <hsivonen>
> <@annevk:matrix.org> I think per https://www.unicode.org/reports/tr46/#ProcessingStepPunycode and https://www.rfc-editor.org/rfc/rfc3492.html `xn--` is indeed expected to become the empty string. That seems like a bug though.

More generally, it seems like a bug not to require Punycode decode to output at least one non-ASCII code point.

[07:43:04.0088] <dean.highpower>
The existing HTML spec respects no RFC (5321 or 5322), instead invents a new syntax for email addresses. This new syntax rejects perfectly valid us-ascii mailbox addresses that are and have been valid (since at least 1982) with no apparent basis. This is harmful. I have seen this new syntax used by other projects, citing the HTML spec as the authority for their "willful violation of RFC 5322" -- with no mention of the standard they *should* be looking at, RFC-5321.
I understand the practical considerations of wanting a simple grammar to check against. Could we specify a simple syntax check that would not reject any mailbox address considered valid by RFC-5321?
A strict check could be used to test *exact* adherence to the RFC, such checkers exist for many languages. (https://www.npmjs.com/package/smtp-address-parser for JavaScript.)
The HTML spec is a "living standard" so should be open to change. Please can we fix it?


[07:49:35.0258] <annevk>
hsivonen: that would probably be a good property, yeah!

[07:52:01.0750] <annevk>
It's not about wanting a simple grammar, it's a worry about breaking existing websites.

[07:55:45.0618] <dean.highpower>
> <@annevk:matrix.org> It's not about wanting a simple grammar, it's a worry about breaking existing websites.

Well, *changing* them -- I would say they're broken now, so fixing them.

[07:56:10.0933] <dean.highpower>
üòÄ

[07:58:30.0831] <annevk>
Right, I'm well familiar with both sides of this debate. You asked why people might be reluctant so I attempted to explain.

[08:05:25.0753] <dean.highpower>
Okay, does anybody think that RFC-5322 is the right standard to be looking to for mailbox address syntax?
I think this is the underlying mistake (not recognizing RFC-5321 as the relavent document) that lead the HTML spec into inventing it's own syntax. (That's like swallowing a spider to catch the fly...)


[08:11:25.0833] <dean.highpower>
no blame here, email standard are complex

[08:11:56.0575] <dean.highpower>
it's easy to get confused

[08:12:25.0321] <dean.highpower>
this is the count of RFC related to DNS and mail

[08:14:37.0550] <Andreu Botella>
I'm taking a look at which parts of event handling in the DOM spec server-side runtimes and other non-DOM implementations need to implement and which don't

[08:15:15.0032] <Andreu Botella>
and I'm wondering about the behavior of an event's path if the same event gets dispatched from an event listener

[08:17:03.0168] <Andreu Botella>
in dispatch 5.3, before running the listeners, an item is added to the event's path, and then after running the listeners in step 8 the path is cleared

[08:17:30.0029] <Andreu Botella>
but if you have an event dispatch inside a listener, any "outer" listeners that haven't yet run will have an empty path

[08:17:52.0390] <Andreu Botella>
am I reading this right?

[08:19:37.0044] <Andreu Botella>
annevk:

[08:26:33.0130] <annevk>
I guess I don't think that's a relevant question here. Pretty much everyone is in agreement that this should change. The question is really how, what the processing model is going to be, and what the impact of that change will be (which likely requires some amount of testing and perhaps incremental rollout in some browser).

[08:29:38.0952] <Andreu Botella>
oh, I just realized that the dispatch flag is meant to avoid this kind of thing

[08:30:12.0633] <Andreu Botella>
but it doesn't seem to prevent dispatches from `el.click()`

[08:30:25.0856] <Andreu Botella>
oh, never mind, that's of course a new event

[08:32:11.0912] <Andreu Botella>
I'm working on a PR that adds a few assertions and notes to indicate which parts of event handling are not needed for implementers like server-side runtimes

[08:32:44.0304] <Andreu Botella>
and it seems like for such runtimes, an event's path can be simplified into an `EventListener` or null, rather than a list

[08:38:55.0977] <annevk>
Why would a path ever be an `EventListener`? That seems weird. That also wouldn't work once we add path support to the `EventTarget` constructor, as has been requested for a while (mainly needs someone to write down a design).

[08:40:29.0309] <Andreu Botella>
 * and it seems like for such runtimes, an event's path can be simplified into an `EventTarget` or null, rather than a list

[08:40:34.0133] <Andreu Botella>
my bad, an `EventTarget`

[08:43:40.0976] <Andreu Botella>
> <@annevk:matrix.org> Why would a path ever be an `EventListener`? That seems weird. That also wouldn't work once we add path support to the `EventTarget` constructor, as has been requested for a while (mainly needs someone to write down a design).

By "adding path support to the `EventTarget` constructor", I assume you mean letting custom `EventTarget`s define tree structures?

[08:44:56.0773] <Andreu Botella>
I didn't know that was being worked on, or in people's todo list

[08:51:23.0393] <Andreu Botella>
there's still a number of event handling-related things that implementations without a native DOM wouldn't need to support, such as things related to shadow trees or touch target lists

[08:52:05.0636] <Andreu Botella>
so that PR might still be useful after all, but it's better to wait until the path support is ready

[09:19:59.0135] <zcorpan>
> <@sideshowbarker:matrix.org> Right, sorry ‚Äî I misspoke there. I guess meant to say something more like, The only way something would end up getting _evaluated_ (not returned) by the algorithm as Inifinity or NaN would be if it the algorithm were given the strings "Infinity" or "NaN"  as input.

No, those strings are treated as garbage and return an error in step 10. Numbers that are greater than 2^1024 or less than -2^1024 are "like +Infinity and -Infinity" and return an error in step 17

[09:27:20.0853] <hsivonen>
> <@annevk:matrix.org> hsivonen: that would probably be a good property, yeah!

Looks like Firefox and Safari already enforce this. Time to file UTS 46 feedback, I guess. As for genuinely empty labels, at least the error messages in both Firefox and Safari suggest that those cases fail on the DNS resolution layer. It's unclear to me how useful that is. Are there cases where an empty label (in non-final position) actually resolves?

[09:28:25.0643] <annevk>
hsivonen: see the DNS vs host parser issue on non-DNS systems. They are rather opaque to me.

[12:44:23.0039] <dean.highpower>
So will the HTML spec going forward define the syntax of email address according to the <Mailbox> ABNF rule from RFC 5321, as extended by RFC 6531? I believe this would be consistent with the vast majority of operational email systems on the public Internet. (Including gmail, outlook, etc.) How is a "processing model" involved in this? (Please forgive my ignorance.)


[15:24:49.0129] <dean.highpower>
Bonus: once you're citing the correct RFC, there is no need to publish any "willful violation" notice about any irreverent RFCs.


2024-03-12
[20:42:32.0405] <sideshowbarker>
Is the https://html.spec.whatwg.org/multipage/common-microsyntaxes.html#rules-for-parsing-floating-point-number-values algorithm known to differ in any way from the behavior of [`strtod`](https://en.cppreference.com/w/c/string/byte/strtof)?

[03:38:17.0946] <Ms2ger>
I assume you could find any number of differences if you looked, if those are even consistent between platforms

[03:51:41.0391] <sideshowbarker>
Well the thing is, as far as I can see, in practice none of Blink, Gecko, Servo, or WebKit actually implement that algorithm ‚Äî at least not intentionally.

Instead, as far as I can see, Blink and Gecko use https://github.com/google/double-conversion ‚Äî and until a year ago, WebKit did too. WebKit now uses https://github.com/fastfloat/fast_float ‚Äî which is functionally equivalent to `strtod` ‚Äî as a drop-in replacement for the double-conversion it had also been using previously.

So if our goal is interoperability, it seems like what we‚Äôd ideally need to specify is, functional equivalence with double-conversion ‚Äî which essentially seems to mean functional equivalence with `strtod`.

[03:52:34.0223] <sideshowbarker>
And for the case of Servo, as far as I can see, it just uses the Rust standard library‚Äôs `parse()`

[03:53:25.0463] <sideshowbarker>
The only engine implementation I have found that seems to attempt to implement its own double parser is the one in Ladybird.

[03:55:32.0338] <sideshowbarker>
But by attempting implement what‚Äôs in the spec rather than just using double-conversion or fast_float, it seems like the Ladybird implementation risks lack of interoperability with the other engines.

[04:58:39.0176] <Ms2ger>
Oh, hmm. I seem to recall that all the integer ones were handcrafted, at least; but maybe floats are too hard

[07:26:19.0439] <akaster>
I suspect Ladybird will have quite a few Interop concerns like that, seeing as implementing the spec as written before trying to optimize is a project goal/strategy. And that pulling in a third party dependency would be against the project's... Identity? Ethos? Something like that. 

If the status quo is that everyone uses an implementation that "matches strtod" then perhaps the spec should have a normative reference to ISO C rather than define the float parsing algorithm itself.

[08:14:14.0758] <annevk>
Hmm, has anyone actually identified any differences? Also, it's unclear to me if ISO C is a suitable reference. I thought most ISO standards were not freely accessible.

[09:12:57.0393] <Jeffrey Yasskin>
Both strtod and HTML start with a computation of the exact mathematical value of the number, and then round to a nearby representation. strtod's rounding is: " If the subject sequence has the decimal form and at most DECIMAL_DIG (defined in
<float.h>) significant digits, the result should be correctly rounded. If the subject
sequence D has the decimal form and more than DECIMAL_DIG significant digits,
consider the two bounding, adjacent decimal strings L and U, both having
DECIMAL_DIG significant digits, such that the values of L, D, and U satisfy L ‚â§ D ‚â§ U.
The result should be one of the (equal or adjacent) values that would be obtained by
correctly rounding L and U according to the current rounding direction, with the extra stipulation that the error with respect to D should have a correct sign for the current
rounding direction." This is also a "should"-level requirement, while HTML's is a "must".

So there's not just one "strtod"; potentially each platform can have its own. Looking at `fast_float()`, they say "We provide exact rounding (including round to even).", which I think matches HTML's requirement.

[09:13:34.0775] <Jeffrey Yasskin>
 * Both (the specification of) strtod and HTML start with a computation of the exact mathematical value of the number, and then round to a nearby representation. strtod's rounding is: " If the subject sequence has the decimal form and at most DECIMAL\_DIG (defined in
\<float.h>) significant digits, the result should be correctly rounded. If the subject
sequence D has the decimal form and more than DECIMAL\_DIG significant digits,
consider the two bounding, adjacent decimal strings L and U, both having
DECIMAL\_DIG significant digits, such that the values of L, D, and U satisfy L ‚â§ D ‚â§ U.
The result should be one of the (equal or adjacent) values that would be obtained by
correctly rounding L and U according to the current rounding direction, with the extra stipulation that the error with respect to D should have a correct sign for the current
rounding direction." This is also a "should"-level requirement, while HTML's is a "must".

So there's not just one "strtod"; potentially each platform can have its own. Looking at `fast_float()`, they say "We provide exact rounding (including round to even).", which I think matches HTML's requirement.

[15:12:59.0187] <Jeffrey Yasskin>
FYI, https://whatwg.org/working-mode links to https://whatwg.org/Stages.md, which doesn't exist.

[15:13:24.0487] <Jeffrey Yasskin>
(I'll file an issue at some point, but distracted by the W3C Breakout Day right now.)


2024-03-13
[18:24:47.0287] <Domenic>
Seems like the sort of thing where if your concern was interop, step 1 would be an exhaustive test suite.

[18:29:26.0575] <sideshowbarker>
I guess my biggest concern is whether we can maybe prevent other implementors from spending time evaluating that algorithm, if it‚Äòs not actually important or useful for it to be actually be implemented as-is to the letter of the spec.

[18:29:45.0717] <sideshowbarker>
It‚Äôs not clear to me at least what the algorithm is actually based on

[18:31:26.0757] <sideshowbarker>
For example, was is written based on reading the double definition in the IEEE 754 spec and then attempting to put together an algorithm for parsing that? Or else was it written by looking at existing parsing code for double-parsing functions (`strtod` or whatever)?

[18:35:56.0894] <sideshowbarker>
I would personally be happy with us just adding a non-normative Note to the end or that algorithm, saying something like
> _Note: In practice, rather than handcrafting an implementation of the above algorithm, most existing implementations use double-parsing functions from libraries such as [double-conversion](https://github.com/google/double-conversion) and [fast_float](https://github.com/fastfloat/fast_float)._
‚Ä¶or whatever similar wording we might be able to get agreement on.

[18:36:13.0598] <sideshowbarker>
 * I would personally be happy with us just adding a non-normative Note to the end or that algorithm, saying something like

> _Note: In practice, rather than handcrafting an implementation of the above algorithm, most existing implementations use double-parsing functions from libraries such as [double-conversion](https://github.com/google/double-conversion) and [fast\_float](https://github.com/fastfloat/fast_float)._

‚Ä¶or whatever similar wording we might be able to get agreement on.

[18:46:00.0641] <sideshowbarker>
I think it‚Äôs also worth noting that the ES spec doesn‚Äôt rely on the HTML floating-point algorithm for double parsing, and I think the CSS spec doesn‚Äôt either.

And so also worth noting that because of that, implementations do double-parsing in places in their code other than just for HTML attribute values ‚Äî notably, in the JavaScript-handling sources, and in the CSS sources.

And so, in the engine sources, implementations have common/shared code for double-parsing that‚Äòs called into from the HTML-attribute parsing code, and the JavaScript parsing code, and the CSS parsing code.

Given all that, it seems very unlikely that any engine over the long run is going to have a specific implementation of the HTML floating-point algorithm that‚Äôs separate from their shared double-parsing code. (I realize that Ladybird does now, but I think that‚Äôs likely to change eventually ‚Äî for various reasons, maybe including performance.)

[18:53:39.0305] <sideshowbarker>
I‚Äôm personally happy with the existing level of WPT coverage that we have for this ‚Äî with https://github.com/web-platform-tests/wpt/pull/44355 now merged. What I‚Äôm less happy about is the effect it may have for causing implementors be unaware that existing engines don‚Äôt implement the algorithm as-is, and for causing implementors to potentially waste time.

[18:55:01.0488] <Domenic>
I mean, in general it's pretty rare to implement spec algorithms as-is, especially for low-level stuff like numbers and strings. https://infra.spec.whatwg.org/#algorithm-conformance and all that.

[18:58:04.0322] <sideshowbarker>
True, but in most cases what‚Äôs implemented in engines is an algorithm that‚Äôs handcrafted to be a workalike that‚Äôs functionally equivalent to the spec algorithm ‚Äî rather than instead being implemented by just calling some code in a third-party library that you don‚Äôt know actually fully conforms to the requirements in the spec as written.

[19:00:14.0553] <sideshowbarker>
Anyway, I don‚Äôt mean to beat this into the ground and I‚Äôm not bringing it up to be pedantic about it ‚Äî instead, I‚Äôm just wondering whether it‚Äôs a place where we might be able to save implementors some trouble by putting a little more information in the spec, even if just a non-normative note.

[19:00:38.0801] <sideshowbarker>
And if so, I‚Äôd be very happy to raise a PR for it.

[19:01:56.0861] <Domenic>
I guess I'd personally like to hear if the implementers of the relevant parts of the browser were confused by the spec, or not. I guess we have one testimonial from yourself, but more would be helpful before concluding its a problem.

[19:05:06.0588] <sideshowbarker>
Fair enough

[01:54:45.0012] <Ms2ger>
I assume all the implementations besides Servo and Ladybird long predate the spec

[01:55:14.0394] <sideshowbarker>
yeah I reckon so

[02:01:53.0335] <annevk>
I think what is first- and third-party code can shift over time and it's not really the job of the specification to go into the weeds about that. If you find a library or function call that happens to match the requirements in the specification and passes all the tests, and is better in some measurable way over what you had before, more power to you. From what Jeffrey wrote about ISO C that at least doesn't match the spirit of the HTML language as it allows for less precision. HTML in theory also allows for that due to the overarching "limits may apply", but also encourages implementers to push those limits. I'm not sure a note would really help with this as it would have to go into the weeds as I have done here to properly convey all the nuances.

[02:02:48.0058] <sideshowbarker>
Yeah, as far as a note, I can imaging that it would be challenging to get the wording right

[02:11:35.0643] <sideshowbarker>
Also by the way, I realize I misspoke a bit about something: While it‚Äôs true that the Blink and Gecko and WebKit use double-conversion or fast_float ‚Äî they don‚Äôt _just _ use those. Instead they have to do preprocessing to skip ASCII whitespace ‚Äî¬†not Unicode whitespace, and specifically not U+000B, and _maybe_ to skip/ignore any leading plus sign.

fast_float uses a `from_chars` implementation rather than `strtod` ‚Äî and `from_chars` on its own per-spec doesn‚Äôt skip/ignore leading whitespace. The docs say it also doesn‚Äôt skip/ignore a leading plus sign, but it seems to me that maybe the fast_float `from_chars` at least actually does.

And I‚Äôm not sure if the double parser in double-conversion skips leading plus signs and whitespace ‚Äî¬†but if it _does_ skip whitespace, it would do it for Unicode whitespace, not the ASCII whitespace subset.

So anyway, to conform to the HTML algorithm, engines using any third-party libraries would need to do preprocessing on the strings ‚Äî to skip/ignore the right kind of whitespace and (possibly) the plus sign.

[02:13:32.0649] <sideshowbarker>
(and with that I‚Äôll be quiet, and go back to trying to figure out how to correctly handle find-in-page for closed `details` that are nested‚Ä¶)

[06:18:16.0507] <Dominic Farolino>
How does one "copy" or "clone" an infra struct? There are several definitions for "clone" in infra, but none specifically for structs. Can we just say "copy" or "clone" manually?

[06:21:31.0582] <Ms2ger>
I'd ask infra for a definition

[06:23:43.0299] <annevk>
Hmm, maybe URL.parse() should be added: https://twitter.com/kilianvalkhof/status/1765312128188088454 (I disagree with the assertion there, but it seems reasonable to have a URL-or-null abstraction)

[08:08:38.0491] <Noam Rosenthal>
Dominic Farolino: usually you clone a struct manually. Often enough some special processing needs to be done on one or more of the items (e.g. if one of the items is a list, do you want to clone the list or pass it by reference?)

[08:11:21.0411] <annevk>
It seems reasonable to define a shallow clone for structs. We have that for lists and maps. Thus far nobody needed it for structs I guess. Should be a fairly straightforward PR.

[08:36:03.0710] <TabAtkins>
> <@annevk:matrix.org> Hmm, maybe URL.parse() should be added: https://twitter.com/kilianvalkhof/status/1765312128188088454 (I disagree with the assertion there, but it seems reasonable to have a URL-or-null abstraction)

Yes, having to use a try block every time you want to parse a URL is indeed very frustrating. If we had an expression-level way to catch an error and return a value, it wouldn't be as big of an issue, but in the absence of JS having that, we absolutely should have a non-throwing way to parse a URL (returning null on failure, definitely).

[08:41:11.0723] <annevk>
Reopened https://github.com/whatwg/url/issues/372 cc Adam Rice 

[08:57:48.0662] <Jeffrey Yasskin>
> <@sideshowbarker:matrix.org> I think it‚Äôs also worth noting that the ES spec doesn‚Äôt rely on the HTML floating-point algorithm for double parsing, and I think the CSS spec doesn‚Äôt either.
> 
> And so also worth noting that because of that, implementations do double-parsing in places in their code other than just for HTML attribute values ‚Äî notably, in the JavaScript-handling sources, and in the CSS sources.
> 
> And so, in the engine sources, implementations have common/shared code for double-parsing that‚Äòs called into from the HTML-attribute parsing code, and the JavaScript parsing code, and the CSS parsing code.
> 
> Given all that, it seems very unlikely that any engine over the long run is going to have a specific implementation of the HTML floating-point algorithm that‚Äôs separate from their shared double-parsing code. (I realize that Ladybird does now, but I think that‚Äôs likely to change eventually ‚Äî for various reasons, maybe including performance.)

FWIW, +1 to having a single double-parsing algorithm that all of ES, CSS, and HTML can use ... if that's web-compatible. See also https://github.com/whatwg/infra/issues/189.

[08:59:41.0869] <annevk>
I'm not sure we should share with ES until we know how the long term number types thing plays out. It came up before and the main reason not to do it was to preserve infinite precision, which seems like a worthwhile goal for a high-level language.

[09:00:01.0131] <annevk>
CSS & HTML I can see though.

[09:15:07.0318] <Jeffrey Yasskin>
I don't feel strongly about the details, but we could explicitly divide the algorithm into 2 pieces: First we parse the string into an infinite-precision real number, which pins down syntax like whitespace and leading-plus behavior. Then we define the Real->IEEE 754 conversion, which establishes than 0 ULPs of error are allowed, and the round-to-even behavior. If ES wants to preserve infinite-precision arithmetic for a while after the string is parsed, that's fine; they just only call the first algorithm.

[09:15:18.0051] <Jeffrey Yasskin>
 * I don't feel strongly about the details, but we could explicitly divide the algorithm into 2 pieces: First we parse the string into an infinite-precision real number, which pins down syntax like whitespace and leading-plus behavior. Then we define the Real->IEEE 754 conversion, which establishes that 0 ULPs of error are allowed, and the round-to-even behavior. If ES wants to preserve infinite-precision arithmetic for a while after the string is parsed, that's fine; they just only call the first algorithm.

[11:01:49.0225] <judge_sour_dough_bread>
Hi all. The HTML spec says, under [¬ß4.13.4](https://html.spec.whatwg.org/#custom-elements-api), for "Element definition" list of steps, specifically step 18:
> Let upgrade candidates be all elements that are shadow-including descendants of document, whose namespace is the HTML namespace and whose local name is localName, in shadow-including tree order. Additionally, if extends is non-null, only include elements whose is value is equal to name.
This suggests that e.g. `define(`foo-bar`, class FooBarElement extends HTMLElement { /* ... */ })` (autonomous custom element)  ` will _not_ "upgrade" elements like `<span is="foo-bar"></span>` (`span` is an example, any other known HTML element will do as well), correct? To explain how I have assumed this: the `name` for the element is `foo-bar`, after all (established at the outset of the aforementioned list of steps), while `localName` is same as `name` (step 5) since `extends` is null, and so only `foo-bar` element(s) in the document will be upgraded. Can someone tell me my reading of the spec is correct?

[11:02:50.0368] <judge_sour_dough_bread>
 * Hi all. The HTML spec says, under [¬ß4.13.4, "The `CustomElementRegistry` interface"](https://html.spec.whatwg.org/#custom-elements-api), for the "Element definition" list of steps, specifically step 18:

> Let upgrade candidates be all elements that are shadow-including descendants of document, whose namespace is the HTML namespace and whose local name is localName, in shadow-including tree order. Additionally, if extends is non-null, only include elements whose is value is equal to name.
This suggests that e.g. `define(`foo-bar`, class FooBarElement extends HTMLElement { /* ... */ })` (autonomous custom element)  `will _not_ "upgrade" elements like`\<span is="foo-bar">` (`span`is an example, any other known HTML element will do as well), correct? To explain how I have assumed this: the`name`for the element is`foo-bar`, after all (established at the outset of the aforementioned list of steps), while `localName`is same as`name`(step 5) since`extends`is null, and so only`foo-bar\` element(s) in the document will be upgraded. Can someone tell me my reading of the spec is correct?

[11:03:04.0320] <judge_sour_dough_bread>
 * Hi all. The HTML spec says, under [¬ß4.13.4, "The `CustomElementRegistry` interface"](https://html.spec.whatwg.org/#custom-elements-api), for the "Element definition" list of steps, specifically step 18:

> Let upgrade candidates be all elements that are shadow-including descendants of document, whose namespace is the HTML namespace and whose local name is localName, in shadow-including tree order. Additionally, if extends is non-null, only include elements whose is value is equal to name.

This suggests that e.g. `define(`foo-bar`, class FooBarElement extends HTMLElement { /* ... */ })` (autonomous custom element)  `will _not_ "upgrade" elements like`\<span is="foo-bar">` (`span`is an example, any other known HTML element will do as well), correct? To explain how I have assumed this: the`name`for the element is`foo-bar`, after all (established at the outset of the aforementioned list of steps), while `localName`is same as`name`(step 5) since`extends`is null, and so only`foo-bar\` element(s) in the document will be upgraded. Can someone tell me my reading of the spec is correct?

[11:03:29.0834] <judge_sour_dough_bread>
 * Hi all. The HTML spec says, under [¬ß4.13.4, "The `CustomElementRegistry` interface"](https://html.spec.whatwg.org/#custom-elements-api), for the "Element definition" list of steps, specifically step 18:

> Let upgrade candidates be all elements that are shadow-including descendants of document, whose namespace is the HTML namespace and whose local name is localName, in shadow-including tree order. Additionally, if extends is non-null, only include elements whose is value is equal to name.

This suggests that e.g. `define("foo-bar", class FooBarElement extends HTMLElement { /* ... */ })` (autonomous custom element) will _not_ "upgrade" elements like`\<span is="foo-bar">` (`span`is an example, any other known HTML element will do as well), correct? To explain how I have assumed this: the`name`for the element is`foo-bar`, after all (established at the outset of the aforementioned list of steps), while `localName`is same as`name`(step 5) since`extends`is null, and so only`foo-bar\` element(s) in the document will be upgraded. Can someone tell me my reading of the spec is correct?

[11:04:31.0073] <judge_sour_dough_bread>
 * Hi all. The HTML spec says, under [¬ß4.13.4, "The `CustomElementRegistry` interface"](https://html.spec.whatwg.org/#custom-elements-api), for the "Element definition" list of steps, specifically step 18:

> Let upgrade candidates be all elements that are shadow-including descendants of document, whose namespace is the HTML namespace and whose local name is localName, in shadow-including tree order. Additionally, if extends is non-null, only include elements whose is value is equal to name.

This suggests that e.g. `define("foo-bar", class FooBarElement extends HTMLElement { /* ... */ })` (autonomous custom element) will _not_ "upgrade" elements like`<span is="foo-bar"><!-- ... --></span>` (`span`is an example, any other known HTML element will do as well), correct? To explain how I have assumed this: the`name`for the element is`foo-bar`, after all (established at the outset of the aforementioned list of steps), while `localName` is same as`name` (step 5) since`extends` is null, and so only`<foo-bar><!-- ... --></foo-bar>` element(s) in the document will be upgraded. Can someone tell me my reading of the spec is correct?

[11:12:10.0410] <judge_sour_dough_bread>
 * Hi all. The HTML spec says, under [¬ß4.13.4, "The `CustomElementRegistry` interface"](https://html.spec.whatwg.org/#custom-elements-api), for the "Element definition" list of steps, specifically step 18:

> Let upgrade candidates be all elements that are shadow-including descendants of document, whose namespace is the HTML namespace and whose local name is localName, in shadow-including tree order. Additionally, if extends is non-null, only include elements whose is value is equal to name.

This suggests that e.g. `define("foo-bar", class FooBarElement extends HTMLElement { /* ... */ })` (autonomous custom element) will _not_ "upgrade" elements like`<span is="foo-bar"><!-- ... --></span>` (`span` can be replaced with any other known HTML element for the sake of the example), correct? To explain how I have assumed this: the`name`for the element is`foo-bar`, after all (established at the outset of the aforementioned list of steps), while `localName` is same as`name` (step 5) since`extends` is null, and so only`<foo-bar><!-- ... --></foo-bar>` element(s) in the document will be upgraded. Can someone tell me my reading of the spec is correct?

[13:30:15.0872] <Noam Rosenthal>
judge_sour_dough_bread: seems right, you need to have an `extends` option to make this into a customize built-in element.


2024-03-14
[03:14:31.0863] <judge_sour_dough_bread>
> <@noamr:matrix.org> judge_sour_dough_bread: seems right, you need to have an `extends` option to make this into a customize built-in element.

Thank you, Noam. To give some context here, I may have understood Web components a bit wrong -- I originally wanted some subclass of specifically `HTMLElement` -- and not a known HTML element like `span`, `fieldset`, `button` etc -- because I wanted a "mix-in" component, one that can work regardless what element is upgraded to its functionality. Which is why I was trying to use the `is` attribute, but turns out that in practice (correct me if I am wrong about this, please) one either uses `is` attribute on a known HTML element, to upgrade to a custom element that specifies `extends`, or one that uses the custom element name (e.g. `foo-bar`) for a component that does _not_ use `extends`. So, in effect, "mix-ins", contrary to perhaps their general principle, cannot be used without `extends`?

[07:17:35.0182] <Noam Rosenthal>
Yea I don‚Äôt think you can implement a mixin in this particular way, but there might be other forums with more ideas around this (this forum is for working on the standards themselves)

[07:58:39.0838] <annevk>
Luke Warlow: feel free to reverse dupe yourself in the future, especially if it's an area you're working on. I think you should be able to do that given you're in the triage team.

[07:59:36.0489] <Luke Warlow>
Okay good to note, forgot I had those permissions.

[09:49:30.0598] <zcorpan>
annevk: https://github.com/whatwg/html/issues/10077#issuecomment-1997383562

[11:22:24.0558] <Dominic Farolino>
Suppose you want a web API to be able to take as an argument, an instance of a JS class that has some methods, and you want the API to be able to call those methods on the input instance. Do you have to define the param as type `any` and then just `GetMethod(obj, 'method1')`, ....? and pull those methods off and store them separately as callback functions, for later invocation?

[11:23:59.0784] <Dominic Farolino>
And does that give you the right `this` value (i.e., the instance of the class w/ the methods) when you're invoking the callbacks later on? I'm pretty sure it doesn't

[11:27:22.0315] <annevk>
Is this about Observer? There's an issue discussing that I thought.

[11:27:40.0848] <Dominic Farolino>
This is not

[11:27:49.0502] <annevk>
Thanks, will hopefully have some details tomorrow.

[11:27:50.0131] <Dominic Farolino>
I found https://webidl.spec.whatwg.org/#dfn-callback-this-value though, which is what I'm looking for

[11:27:54.0447] <Dominic Farolino>
This is about shared storage worklets

[11:28:14.0230] <Dominic Farolino>
So it turns out https://html.spec.whatwg.org/C#fakeworkletglobalscope-process is basically what I was looking for-ish i think

[11:28:50.0784] <TabAtkins>
If it's an arbitrary JS class (not an IDL interface), then generally we'll treat it as a dictionary, I think? And pull the methods off when initially passed, stashing them for later calling.

[11:29:20.0364] <Dominic Farolino>
That, _plus_ storing the original instance for later use as the callback this value, I guess?

[11:29:20.0869] <annevk>
Worklets was the other thing I thought of that might have something like this, yeah.

[11:30:11.0715] <annevk>
The one wrinkle here is that this is what `interface callback` is, essentially, but we generally decided we didn't want that. But maybe we do, sometimes.

[11:33:10.0385] <Dominic Farolino>
Heh, yeah but for as long as that scary note above callback interfaces exists, getting away with normal callbacks feels less controversial

[11:55:06.0062] <annevk>
These are not normal callbacks though. You're using `object` here presumably in IDL. That's even more magical.

[15:09:29.0646] <snek>
is the parent document of an iframe supposed to lose focus when the iframe is focused? seeing disagreement among browsers

[16:55:21.0931] <Domenic>
> <@domfarolino:matrix.org> That, _plus_ storing the original instance for later use as the callback this value, I guess?

Example at https://streams.spec.whatwg.org/#rs-constructor , underlyingSource is taken as an object but also converted to a dictionary type to grab the methods

[16:57:00.0693] <Domenic>
https://github.com/whatwg/webidl/issues/701 is the canonical issue and we did discuss something very similar at https://github.com/WICG/observable/issues/71#issuecomment-1804956795


2024-03-15
[00:11:42.0734] <annevk>
snek: I think so, yes.

[00:36:44.0854] <annevk>
Details posted. Apparently code has been in place for about a decade...

[02:38:39.0853] <zcorpan>
A lot of red in https://wpt.fyi/results/html/semantics/embedded-content/media-elements/loading-the-media-resource?label=experimental&label=master&aligned

[02:41:00.0545] <zcorpan>
annevk: https://github.com/WebKit/WebKit/blob/a7b863a49945946c913e6e194ec047da844094a4/Source/WebCore/html/HTMLMediaElement.cpp#L5404 responds to inserting `source` elements, and https://github.com/WebKit/WebKit/blob/a7b863a49945946c913e6e194ec047da844094a4/Source/WebCore/html/HTMLMediaElement.cpp#L886 ("end tag seen") only invokes text track selection, so it looks to me like WebKit follows the spec's model to try `source` elements in order during parsing

[02:41:51.0150] <zcorpan>
but I may be missing something

