2024-02-01
[21:49:09.0444] <Domenic>
I would strongly support that; it seems like a good fit...

[03:24:00.0962] <hsivonen>
annevk, Domenic : Do you happen to know the history of why step 1 "Map under section 4 "Processing" in UTS 46 leaves disallowed characters in place and they are only checked in step 4 "Convert/Validate"? https://www.unicode.org/reports/tr46/#Processing

[03:24:20.0235] <hsivonen>
 * annevk, Domenic : Do you happen to know the history of why step 1 "Map" under section 4 "Processing" in UTS 46 leaves disallowed characters in place and they are only checked in step 4 "Convert/Validate"? https://www.unicode.org/reports/tr46/#Processing

[03:42:50.0585] <Adam Rice>
PR Preview is now saying `Error: 405 Method Not Allowed: Must use POST to process URL` at https://github.com/whatwg/websockets/pull/48

[03:42:55.0710] <Adam Rice>
I retried a few times.

[09:49:48.0191] <zcorpan>
keithamus: The wpt Interop  team has an issue with a new GitHub account seemingly beeing detected as a spam account (because we made a script to comment on a 100+ issues).  Is it easy to unblock the account?

[09:50:33.0969] <zcorpan>
`wpt-interop`

[09:57:46.0178] <keithamus>
Sure. Is that the name of the bot? I‚Äôll get it handled 

[10:05:01.0476] <zcorpan>
keithamus: Thanks! We've started posted manually, so maybe we get some duplicates, but we can remove dup comments. Should it work to run the script for all issues now?

[10:07:08.0190] <keithamus>
Okay zcorpan that user has been restored and marked as `hammy` which hopefully means it won‚Äôt get flagged for that kind of activity again üòâ

[10:07:39.0141] <zcorpan>
keithamus: TY!

[11:04:04.0039] <keithamus>
Yeah it shouldn‚Äôt get flagged for being overly active now 

[14:55:36.0466] <Tristan Ross>
Working on implementing a webidl parser in Zig. Looks like this is a good place to ask questions.

[15:45:32.0883] <TabAtkins>
> <@rosscomputerguy:matrix.org> Working on implementing a webidl parser in Zig. Looks like this is a good place to ask questions.

Yes, this is a reasonable spot for questions about the spec.


2024-02-02
[22:43:36.0613] <annevk>
mfreed: I think it would be nice if you or we together drafted a small blog post around the shadow tree changes

[00:07:48.0300] <sideshowbarker>
Regarding trailing (not leading) characters in floating-point number values: Does the parsing algorithm at https://html.spec.whatwg.org/multipage/common-microsyntaxes.html#rules-for-parsing-floating-point-number-values require implementations to ignore all trailing characters that are not ASCII digits?

[00:35:21.0240] <annevk>
sideshowbarker: yeah, it ends up ignoring essentially everything at a certain point. Whereas before that it is quite strict.

[00:36:00.0858] <sideshowbarker>
OK, thanks

[00:37:18.0064] <sideshowbarker>
That complicates dealing with U+000B‚Ä¶ Implementation-wise, it would be easier to just reject it everywhere

[00:46:33.0257] <annevk>
sideshowbarker: I left a comment on your implementation. You need to go deeper. :-)

[00:47:41.0550] <annevk>
The source of the problem is WebKit's (copied by Chromium) string to double operations. They do a bit too much.

[00:51:52.0182] <sideshowbarker>
> <@annevk:matrix.org> The source of the problem is WebKit's (copied by Chromium) string to double operations. They do a bit too much.

Yeah, I‚Äôm discovering that now‚Ä¶

[00:52:02.0089] <annevk>
sideshowbarker: It might be a bit much though so not handling U+000B for now would be reasonable too.

[00:52:25.0817] <annevk>
 * sideshowbarker: It might be a bit much though so not handling U+000B correctly for now would be reasonable too.

[00:52:29.0143] <sideshowbarker>
OK

[00:53:36.0470] <annevk>
Ideally string to double would just do the minimal thing. It would progress some character pointer and return failure or a number. And then after that the caller gets to decide whether to ignore trailing characters or not.

[00:54:04.0471] <annevk>
And the caller also gets to decide where the character pointer starts (i.e., whether to skip whitespace and what type of whitespace beforehand).

[00:57:20.0664] <sideshowbarker>
And had already thought about changing `parseDouble()` to disallow U+000B as leading whitespace, but figured the problem with hard-coding it that way would be that it could regress other existing code that does expect `parseDouble()` allow U+000B.

So yeah ‚Äî¬†ideally would need to be made configurable, as you said in your comment.


[01:02:04.0717] <annevk>
sideshowbarker: It looks like the other callers are in JSC. You could ask in the WebKit JSC channel maybe.

[01:02:20.0086] <sideshowbarker>
OK

[01:03:34.0771] <sideshowbarker>
For now I guess I may also go ahead and hard-code the `parseDouble()` code to disallow U+000B, and see what that breaks

[01:03:56.0255] <sideshowbarker>
(just locally, I mean)

[01:04:30.0266] <annevk>
Yeah seems reasonable to try. JavaScript should be concerned about more whitespace than just ASCII anyway, but maybe that's handled separately?

[01:04:57.0620] <sideshowbarker>
maybe so‚Ä¶ we‚Äôll see, anyway

[01:05:20.0657] <annevk>
CSS seems to have mostly its own conversion, which seems suboptimal.

[04:53:58.0200] <hsivonen>
annevk: Am I counting correctly that there are 16 ASCII characters that the URL Standard allows in a domain but STD3 does not? The list is surprising. Also, some characters on that list don't go to DNS resolution in Firefox but to the search engine if typed into the URL bar. How did you derive the forbidden domain code point list?

[04:57:25.0379] <annevk>
hsivonen: it's an attempt to be as reasonable as possible to non-DNS systems which Ryan Sleevi deemed important (and probably are in certain deployments, though unclear to what extent they have non-DNS names as that is hard to find out)

[04:57:48.0504] <annevk>
I don't know the exact numbers offhand though, definitely not at this point

[04:59:43.0790] <hsivonen>
annevk: I see. I'm wondering if it's a good idea for an IDNA library to have the UTS 46 flag of `UseSTD3ASCIIRules` where `false` means anything goes, or if an IDNA library should have an ASCIIRules parameter that take STD3 or WHATWG.

[05:00:10.0273] <annevk>
hsivonen: https://github.com/whatwg/url/issues/397

[05:02:11.0393] <annevk>
That's a good question and I'm not sure. I don't really know what email does for instance. It would be very nice if the library could just be "domain to ASCII" and "domain to Unicode" without any kind of configuration. But we might still be too much in a state of flux.

[05:02:51.0390] <hsivonen>
Today, I'm been wondering if I should ask UTS 46 to document the use cases for its tunables.

[05:03:30.0413] <hsivonen>
I'm rather unhappy about how the spec definition of the UTS 46 STD3 stuff is so much more complicated than what ICU4C does. I've spent way too much time designing data structures from the spec.

[05:04:51.0436] <hsivonen>
I'm also a bit unhappy about it taking me so long to realize that the next step in the URL Standard after the UTS 46 integration point provides a somewhat similar filter as ICU4C's STD3 filter. (But I didn't notice it by reading just the UTS 46 integration language in the URL Standard.)

[05:05:08.0119] <annevk>
I've attempted to influence UTS 46 quite a bit, but the process is still quite opaque to me and I don't always understand the decisions they make. Nor are they explained to me.

[05:06:37.0145] <annevk>
hsivonen: that's good feedback. We should probably move step 7 of the host parser to domain to ASCII.

[05:07:06.0807] <hsivonen>
I'll file a couple of URL Standard issues.

[06:34:18.0450] <emilio>
annevk: anything I need to do to move https://github.com/whatwg/html/pull/10067 forward?

[06:34:28.0796] <emilio>
It blocks some other fixes I want to do in that area

[07:12:45.0587] <annevk>
emilio: was that blocked on jarhar agreeing perhaps?

[07:13:44.0562] <annevk>
emilio: yeah I would like jarhar to agree so we don't need to go back and forth

[07:14:57.0719] <annevk>
But maybe two weeks is sufficient time. emilio could you wait until Monday morning? If not, happy to merge it now I suppose.

[07:31:37.0122] <emilio>
> <@annevk:matrix.org> But maybe two weeks is sufficient time. emilio could you wait until Monday morning? If not, happy to merge it now I suppose.

Sure, that's alright with me :)

[07:45:54.0332] <jarhar>
done, sorry that took so long

[07:46:17.0602] <jarhar>
also fyi i am adding more tests to the user-valid tests for checkboxes here: https://github.com/web-platform-tests/wpt/pull/44354


2024-02-05
[17:43:15.0398] <Kostya Petridi>
Hello,

I apologize in advance if this is the wrong place to ask a question. I am wondering why the comment exists in the specification in the section about dialog description (see attached). Because a dialog is a single element that serves as a perfect base for popups, menus, tooltips, and any other piece of content that should be displayed over anything else on the page. Avoiding the use of dialog elements may leads to using workarounds (e.g., adding content directly at the top of the body), which might break specific scenarios (e.g., walkthrough elements in the tree). Am I missing something? 
Thanks.

[17:44:38.0793] <Domenic>
One small example of the many problems that can occur from abusing dialog for a non-dialog is that a screen reader will announce your tooltip (or whatever) as a dialog to non-sighted users.

[03:28:29.0379] <hsivonen>
annevk: https://github.com/whatwg/url/issues/110#issuecomment-261694624 indicates that WebKit switched to non-transitional IDNA processing in 2016. However, just now, I wrote fu√üball.de in the location field and pressed enter with the network inspector open in Firefox, Chrome, and Safari on macOS 14.3, and Safari is the only one that claims that the first request goes to fussball.de whereas Firefox and Chrome show the first request going to fu√üball.de, which redirects. Has WebKit deliberately switched back to transitional IDNA, is the network inspector omitting something, or do I misunderstand something?

[03:50:07.0632] <hsivonen>
TIL: Characters that are combining marks but that have canonical combining class 0, and UTS 46 is stricter about this than W3C charmod norm.

[05:37:07.0849] <annevk>
hsivonen: I suspect the inspector is omitting something. Maybe try something else that redirects? Bug reports welcome.

[06:30:15.0108] <Sam Sneddon [:gsnedders]>
it's also plausible that Safari is doing some processing of the location field before it reaches WebKit

[06:48:01.0812] <annevk>
It's possible, but if you try https://example√ü.com/ it gives a near identical error message to other browsers, so that seems less likely.

[07:08:00.0685] <hsivonen>
me√üdienst.de works in Safari, so I guess the network pane in dev tools is what's weird.

[07:08:42.0869] <hsivonen>
Reading the old Bugzilla threads about transitional vs. non-transitional was interesting. I didn't recall that this stuff was so controversial.

[07:09:32.0580] <hsivonen>
Anyway, not that the three browser engines agree, should there be an effort to declare the transition over in UTS 46?

[07:10:16.0084] <annevk>
Overall I think it's dumb we did it, but then ICANN has been responsible for many TLD deaths as well so what's a couple of domain names at the hand of the IETF.

[07:11:21.0449] <annevk>
As part of my UTS46 feedback last year I did indeed ask them to remove the transitional mode. I'm not sure why they didn't. Might not hurt asking again, but perhaps we should have a more consolidated ask for changes as there are also test changes they need to make and such.

[12:52:11.0978] <Kostya Petridi>
> <@domenicdenicola:matrix.org> One small example of the many problems that can occur from abusing dialog for a non-dialog is that a screen reader will announce your tooltip (or whatever) as a dialog to non-sighted users.

Domenic: thank you for pointing that out


2024-02-06
[19:42:44.0964] <jojo404>
"I'll help anyone interested on how to earn 100k in just 24hours  from the crypto market. But you will have to pay me my commission! when you receive your profit! if interested click on the group link and send me a direct message 
https://t.me/+FGhsj-vpp7dmZDc0
by asking me HOW

[21:33:04.0976] <Domenic>
annevk: ping on https://github.com/whatwg/html/pull/10015 , it's ready to merge but ntim was hoping for a check from you it seems.

[00:07:09.0871] <hsivonen>
Currently, I'm thinking that the right API for IDNA is `pub fn process<W: Write + ?Sized>(&self, domain_name: &[u8], mode: Mode, strictness: Strictness, sink: &mut W) -> Result<(), ()>` where Mode is ToAscii or ToUnicode and Strictness is Whatwg or Std3. Am I missing something?

[00:10:55.0421] <hsivonen>
annevk: In UTS 46 section 4 Processing step 4 Convert/Validate substeps 1 & 2, it seems to me that there's a bug in step 1 saying "continue with the next label" but step 2 saying "Attempt to convert the rest of the label". Am I misunderstanding, or is this a spec bug where it first continues to the next label but still wants to do stuff with the non-next label?

[00:14:12.0828] <hsivonen>
Or maybe Strictness could be something like UserAgent and Validator.

[00:14:44.0419] <hsivonen>
Also depends on the outcome of https://github.com/whatwg/url/issues/820 and https://github.com/whatwg/url/issues/821 .

[00:32:01.0713] <hsivonen>
Seems annoying that if an RTL character shows up in a later label, the rules for the earlier labels change.

[00:33:20.0184] <hsivonen>
Complicates an ASCII fast path. :-(

[01:15:41.0002] <Noam Rosenthal>
HTML spec local build question: is there a way to make it fail on HTML parsing issues? I often get success on local build and then a failure on PR preview build (e.g. missing end-tags)

[08:06:15.0912] <annevk>
Is anyone other than Aryeh familiar with WPT dom/common.js? Ms2ger maybe? We need CDATASection coverage, but I've no idea how to go about it.

[08:15:27.0984] <Ms2ger>
Oh dear, that one

[08:21:25.0029] <Ms2ger>
annevk: I think you'll need to update all references to `Node.TEXT_NODE` to also include cdata sections, and then add a couple of cases to testRanges/testNodes and it should just work, maybe?

[08:25:29.0972] <annevk>
Ms2ger: I will give that a go. Making some changes to WebKit to verify. But debugging for actual correctness seems really hard so maybe I should also write some simple tests on the side...

[08:25:55.0710] <Ms2ger>
Sounds good

[08:27:18.0418] <annevk>
So yeah, I found unique test failures in WebKit. I guess that's proof that nobody cares about CDATASection.

[08:29:41.0116] <annevk>
Domenic: minor [SecureContext] mess: https://github.com/w3c/webref/issues/1142#issuecomment-1930188979. Thoughts?

[08:32:53.0216] <Noam Rosenthal>
annevk: can I ask for your guidance about https://github.com/whatwg/html/pull/9970#discussion_r1479199162 ? Trying to figure out if the new `<link rel=expect>` should use URL-parse or encoding-parse (I think the latter to be consistent with existing link/a, but you should be more informed about this than myself)

[08:36:09.0771] <annevk>
Noam Rosenthal: yeah, for (new) elements using encoding-parse is reasonable.

[08:36:45.0454] <annevk>
Although maybe if we had a completely new element we'd sidestep it? Not sure.

[08:41:53.0960] <Noam Rosenthal>
annevk: the guidance in the html spec suggests  that new stuff should use "parse", was I reading it wrong?

[08:45:00.0882] <Noam Rosenthal>
Ah it's for new APIS rather than elements 


2024-02-07
[17:01:30.0376] <Domenic>
> <@noamr:matrix.org> HTML spec local build question: is there a way to make it fail on HTML parsing issues? I often get success on local build and then a failure on PR preview build (e.g. missing end-tags)

This is a regression since the Rust build tools since they autocorrect bad tags. Jeremy Roman might have ideas. Ideally the Rust parser we're using would have a validating mode, but I'm not sure it does...

Filing a tracking issue on html-build would be helpful.

[17:02:50.0004] <Domenic>
> <@annevk:matrix.org> Domenic: minor [SecureContext] mess: https://github.com/w3c/webref/issues/1142#issuecomment-1930188979. Thoughts?

No particular thoughts from me...

[22:37:36.0404] <Noam Rosenthal>
> <@domenicdenicola:matrix.org> This is a regression since the Rust build tools since they autocorrect bad tags. Jeremy Roman might have ideas. Ideally the Rust parser we're using would have a validating mode, but I'm not sure it does...
> 
> Filing a tracking issue on html-build would be helpful.

OK will file a bug there, thanks!

[01:53:48.0297] <hsivonen>
annevk: Not sure what to think of the lab9.be link at the bottom on https://util.unicode.org/UnicodeJsps/idna.jsp . The page says that Firefox resolves the link, but Firefox no longer does (because Firefox calls into ICU4C on a per-label basis and has incorrect special-case code for CJK characters that normalize to period). That is, Firefox, Chrome, and Safari fail to implement the spec mutually consistently. This raises the question if we should change the specs or the browsers. I can see arguments both ways.

[01:54:17.0364] <hsivonen>
 * annevk: Not sure what to think of the lab9.be link at the bottom on https://util.unicode.org/UnicodeJsps/idna.jsp . The page says that Firefox resolves the link, but Firefox no longer does (because Firefox calls into ICU4C on a per-label basis and has incorrect special-case code for CJK characters that normalize to period). That is, Firefox, Chrome, and Safari mutually consistently fail to implement the spec. This raises the question if we should change the specs or the browsers. I can see arguments both ways.

[02:09:27.0613] <hsivonen>
I'm on track to writing code that would make the link resolve in Firefox again. Making it _not_ resolve takes its own kind of special effort.

[02:13:56.0134] <mathiasbynens>
looks like we had some data loss here https://blog.whatwg.org/implementation-progress-on-the-html5-ruby-element

[02:17:05.0242] <mathiasbynens>
the ‚Äú???‚Äù in the examples are real U+003F QUESTION MARK characters instead of the intended non-ASCII characters

[02:17:13.0620] <mathiasbynens>
https://web.archive.org/web/20120522110923/https://blog.whatwg.org/implementation-progress-on-the-html5-ruby-element is what it used to be

[02:36:41.0007] <annevk>
hsivonen: that should not resolve I think. Not sure what U+2490 gets mapped to though.

[02:38:12.0850] <hsivonen>
> <@annevk:matrix.org> hsivonen: that should not resolve I think. Not sure what U+2490 gets mapped to though.

Ooh. Indeed. It's disallowed. Nevermind then. Sorry.

[02:39:13.0570] <hsivonen>
Well, at least I do also find actual bugs: https://unicode-org.atlassian.net/browse/ICU-22658

[11:01:41.0561] <TabAtkins>
> <@tabatkins:matrix.org> All right, https://github.com/w3c/htmldiff-ui/pull/10 filed

And merged! HTMLDiff should hopefully be generating good diff colors now.

[11:09:25.0819] <akaster>
Does that fix help at all with <https://github.com/whatwg/html/issues/10072>? üôè

[11:25:33.0103] <TabAtkins>
> <@akaster:serenityos.org> Does that fix help at all with <https://github.com/whatwg/html/issues/10072>? üôè

No, but let me go fix that now.

[12:50:49.0873] <sefeng>
Domenic: I have another case for sequential focus which I am not sure which behaviour is correct. https://jsfiddle.net/qyuc0otf/ If you focus the first input and then press <TAB>, firefox moves the focus to the "second" input, Chrome and Safari moves to the <area> element

[13:05:38.0045] <sefeng>
I think we should do DOM orders here, so that's what Chrome and Safari do. 


2024-02-08
[10:24:00.0353] <annevk>
Pfff. <select> thread with Open UI is so weird.

[10:24:12.0221] <annevk>
 * Pfff. That \<select> thread with Open UI folks is so weird.

[13:54:14.0059] <smaug>
keithamus: I can't comment on lines which haven't been changed when reviewing a pr?

[13:54:36.0984] <smaug>
keithamus: I'm looking at the  open attribute removal

[13:56:56.0474] <smaug>
keithamus: don't the focusing steps possibly trigger events synchronously ? Maybe I'm missing something

[13:57:15.0073] <smaug>
jarhar: ^

[14:00:45.0322] <keithamus>
Which PR is this in question?

[14:03:35.0278] <jarhar>
oh yeah i thought about that too

[14:03:49.0046] <jarhar>
when closing the dialog we focus another element synchronously

[14:04:09.0398] <jarhar>
and it might be a bad idea to fire an event while removing an attribute

[14:04:15.0226] <jarhar>
not sure whats best

[14:04:32.0767] <smaug>
keithamus: https://github.com/whatwg/html/pull/10124

[14:04:33.0470] <jarhar>
we could skip that step for attribute removal if needed

[14:07:10.0529] <keithamus>
smaug: oh I see what you mean about github not letting you add a comment. We've got that feature in the backlog ü´†

[14:07:40.0229] <smaug>
good good üôÇ 

[14:11:51.0160] <smaug>
But about the behavior, I think it would be nice to have similar behavior as what calling close has. Are there other cases when removing an attribute triggers events this way? (not talking about mutation events)

[14:12:05.0275] <smaug>
Looks like DOM spec wouldn't like sync events

[14:22:02.0622] <keithamus>
`<details>` 

[14:22:23.0702] <keithamus>
 * `<details>`? Removing the attribute closes but I don't recall if it triggers events

[14:25:21.0316] <keithamus>
https://searchfox.org/mozilla-central/source/dom/html/HTMLDetailsElement.cpp#45-67 looks like it dispatches the toggle event if you remove the `open` attribute, but that's done in a task.

[14:25:40.0068] <smaug>
right, also per spec

[14:27:51.0312] <keithamus>
I'd love to chat more about this. I'm trying to understand the constraints and get a way for all groups to progress. It feels like something is getting lost in the comments.

[14:28:26.0586] <smaug>
(oh, details has some rather unusual mutation events flag usage in the spec)

[14:31:37.0060] <smaug>
hmm, doesn't popover removal have a bug


2024-02-09
[17:40:29.0179] <oliver>
I have some problems keeping the Websocket connection alive in Apache since they deprecated mod_proxy_wstunnel. Now it‚Äôs disconnecting after the ProxyTimeout or Timeout is reached.

If I understand the spec correctly the ping mechanism is the right way to keep the connection alive. Is it by means of the specification correct to disconnect the websocket if it was idle for only a short time like the timeout interval? It seems inefficient to me to send ping and pong below such an interval from many clients for keepalive purposes.

[17:43:52.0818] <oliver>
* I have some problems keeping the Websocket connection alive in Apache since they deprecated mod_proxy_wstunnel. Now it‚Äôs disconnecting after the ProxyTimeout or Timeout is reached.
If I understand the spec correctly the ping mechanism is the right way to keep the connection alive. Is it by means of the websocket specification correct to disconnect the websocket if it was idle for only a short time like the timeout interval? It seems inefficient to me to send ping and pong below such an interval from many clients for keepalive purposes.

[17:52:27.0790] <Domenic>
smaug: jarhar: I think the DOM spec is fine with sync events, but I agree this does seem counter to our goals of removing mutation events.

[17:54:21.0860] <Domenic>
annevk: keithamus: I agree that OpenUI thread is very weird. It got even weirder if you read their minutes on a related issue. https://github.com/openui/open-ui/issues/532#issuecomment-1934844026 . My current hypothesis is that OpenUI has decided to conflate the four separate things: parser behavior, styling, shadow DOM structure, and changed keyboard/a11y behavior, and so whenever annevk talks about one of those, they go "what about the other?", and confusion follows.

[17:54:55.0823] <smaug>
removeNamedItem starts to behave a bit oddly if removing attribute may have already executed js. (I'm excluding custom elements here)

[17:56:00.0666] <Domenic>
I guess odd is in the eye of the beholder; seems fine to me.

[17:57:36.0707] <smaug>
and CEReaction happens after attribute change steps, so it doesn't play nicely with that either

[18:06:21.0883] <sideshowbarker>
> <@smaug:mozilla.org> (oh, details has some rather unusual mutation events flag usage in the spec)

Yeah I don‚Äôt know the background on the decision to include that suppress-firing-of-mutation-events behavior in the requirements for details@name; but I can say that in the case of the WebKit at least, without suppressing mutation events in that way ‚Äî¬†even if it weren‚Äôt required by the spec ‚Äî the WebKit implementation would otherwise run into existing security asserts in the code that‚Äôd prevent firing mutation events in that case anyway.

And implementing `details` auto-expand (for find-in-page and fragment navigation) in WebKit will require that same suppress-firing-of-mutation-events behavior ‚Äî even though the spec doesn‚Äôt (yet) require it in that case.

Anyway, I wish we all could all just go ahead and disable mutations-events support in all engines in the very near future. I know Chrome at least is scheduled to do so later this year. I don‚Äôt know if other engines have it scheduled yet.

Otherwise, it seems like we‚Äôre letting the overhead of needing to deal with mutation events when implementing new features (and in the spec) just keep on being an ongoing PITA indefinitely.

[18:08:36.0510] <smaug>
It was agreed already 2011 or 2012 to remove mutation events and FF has warned about them being deprecated since 2012 üòâ 

[18:15:57.0098] <sideshowbarker>
Yeah, definitely not a case where developers haven‚Äôt got plenty of warning.

Maybe once (if) Chrome actually manages to drop support this year, then other engines will finally be able to go ahead with dropping support too.

I mean, once they‚Äôre not supported in Chrome any longer, you‚Äôd have to wonder what kind of existing apps/code with mutation events that developers would have running that weren‚Äôt already now broken in Chrome.

I guess at that point it would be apps that intentionally targeted only to Firefox or Safari users. Some extensions maybe, I dunno

[18:16:20.0319] <sideshowbarker>
 * Yeah, definitely not a case where developers haven‚Äôt got plenty of warning.

Maybe once (if) Chrome actually manages to drop support this year, then other engines will finally be able to go ahead with dropping support too.

I mean, once they‚Äôre not supported in Chrome any longer, you‚Äôd have to wonder what kind of existing apps/code with mutation events that developers would have running that weren‚Äôt already now broken in Chrome.

I guess at that point it would be apps intentionally targeted only to Firefox or Safari users. Some extensions maybe, I dunno

[18:17:25.0588] <sideshowbarker>
So anyway, fingers crossed on Chrome actually being able to successfully drop support for mutation-events this year

[23:36:31.0639] <annevk>
smaug: what will be weird for removeNamedItem that's not weird for removeAttribute?

[23:47:14.0762] <annevk>
Domenic: should https://html.spec.whatwg.org/multipage/nav-history-apis.html#dom-navigation-cangoforward be size - 1?

[23:47:29.0946] <annevk>
(Via https://github.com/WebKit/WebKit/pull/23578.)

[23:48:04.0256] <Domenic>
annevk: I don't understand the question

[23:48:25.0750] <Domenic>
Oh, size minus 1, not size negative 1

[23:48:35.0673] <annevk>
Domenic: since. the index is 0-based, how can it ever match size?

[23:48:42.0971] <annevk>
 * Domenic: since the index is 0-based, how can it ever match size?

[23:49:05.0210] <Domenic>
Yes, that seems clearly like a bug... let me double-check Chromium to confirm there's not something galaxy-brained going on

[23:49:23.0936] <Domenic>
Yes indeed, Chromium has it correct

[23:49:30.0482] <Domenic>
I'll fix

[23:51:33.0937] <Domenic>
https://github.com/whatwg/html/pull/10130

[00:27:20.0665] <annevk>
Domenic: keithamus: https://github.com/whatwg/html/issues/9799#issuecomment-1935512376

[00:27:40.0321] <annevk>
keithamus: happy to chat further if you think that'd be useful. I have time today.

[00:47:35.0504] <keithamus>
annevk Domenic name the time and I‚Äôll do my best. I‚Äôd love to figure out the path forward for both. 

[00:48:08.0596] <keithamus>
I‚Äôm free in about 15 mins 

[01:06:16.0177] <Domenic>
It's 6pm Friday for me :)

[01:06:32.0884] <Domenic>
I don't think I'm that necessary though

[02:24:26.0286] <smaug>
annevk: removeAttribute doesn't return the removed attribute, removeNamedItem does

[02:27:52.0714] <annevk>
smaug: is the weirdness that you get an attribute back that might still be attached?

[02:29:05.0644] <smaug>
the weirdness is that when you get the attribute back, scrips may have already run and added another attribute there

[02:29:14.0390] <smaug>
or basically anything may have happened

[02:29:42.0821] <smaug>
well, that anything may have happened is of course an issue with removeAttribute too

[02:30:19.0495] <smaug>
But  the issue is more obvious with removeNamedItem

[02:32:26.0816] <annevk>
I see, I guess that's fair. But this does not rise to the level of mutation event issues, I think.

[02:32:44.0340] <smaug>
right, because it is after attribute removal

[02:32:52.0314] <annevk>
Note that Trusted Types also allows for this.

[02:33:04.0036] <annevk>
Hmm, I think Trusted Types is before removal?

[02:33:29.0241] <annevk>
smaug: review https://github.com/whatwg/dom/pull/1247 please?

[02:38:21.0936] <smaug>
Though, DOMAttrModified isn't the particularly bad mutation event. The bad one is DOMNodeRemoved

[02:38:31.0185] <smaug>
But looking at that TT issue

[02:38:38.0295] <smaug>
 * But looking at that TT PR

[10:19:39.0155] <annevk>
https://portal.gitnation.org/contents/yous-the-platform talk about adding the submitter argument to the `FormData` constructor


2024-02-10
[00:27:17.0440] <Franco Rougier>
Hi


2024-02-12
[02:48:44.0751] <Ms2ger>
annevk: hey, re: shadowrealms: do I understand correctly that queuing microtasks is fine, and it's just "real" tasks that are an issue

[02:48:46.0061] <Ms2ger>
?

[08:07:18.0264] <smaug>
Ms2ger: what is the context? (I'm just curious because of microtasks)

[08:11:52.0197] <Ms2ger>
smaug: https://github.com/tc39/proposal-shadowrealm/issues/398 - we got feedback that exposing timers would be useful in shadow realms, but those need more of an event loop than worklets offer, so I'm reviewing the list of APIs to make sure we don't have other similar issues. It seems like they do support microtasks, though

[08:13:00.0449] <smaug>
Ms2ger: hmm, is shadowrealm now closer to a worklet?

[08:13:30.0211] <smaug>
or do you mean that using shadowrealms in worklets wouldn't work?

[08:13:32.0390] <Ms2ger>
The idea is that worklets will be able to use a shadow realm as well

[08:13:39.0747] <Ms2ger>
Yeah

[08:14:29.0092] <smaug>
What would be even the use case for shadow realms in worklets?

[08:17:30.0258] <Ms2ger>
TC39 tends to assume that what it adds to JS is available in all JS scopes - I don't know if anyone has shared use cases for that specific combination, though

[08:35:57.0335] <smaug>
perhaps not all the features should be exposed in all the shadowrealms?

[08:59:37.0422] <ljharb>
in particular, any feature that's not exposed everywhere empirically gets vanishingly little adoption


2024-02-13
[22:24:21.0107] <Kaiido>
This [stackoverflow question](https://stackoverflow.com/questions/77969202) made me look into how [localStorage](https://html.spec.whatwg.org/multipage/webstorage.html#dom-localstorage) is defined and there is a point that seems weird. As I read it, each Document has its `local storage holder` set only when the `localStorage` getter is called, and the *broadcast* operation fires event only on globals that have a matching Storage holder.  So if a Document does set a *storage* event listener without calling that getter it wouldn't receive events? All browsers seem to fire it anyway https://jsfiddle.net/yspr304z/ So why define it only in the getter? Did I miss something or should I open an issue?

[23:33:07.0892] <Domenic>
> <@kaiido:matrix.org> This [stackoverflow question](https://stackoverflow.com/questions/77969202) made me look into how [localStorage](https://html.spec.whatwg.org/multipage/webstorage.html#dom-localstorage) is defined and there is a point that seems weird. As I read it, each Document has its `local storage holder` set only when the `localStorage` getter is called, and the *broadcast* operation fires event only on globals that have a matching Storage holder.  So if a Document does set a *storage* event listener without calling that getter it wouldn't receive events? All browsers seem to fire it anyway https://jsfiddle.net/yspr304z/ So why define it only in the getter? Did I miss something or should I open an issue?

Looks like a bug introduced with the storage bottles work, indeed. A bug would be helpful.

[06:01:36.0761] <Dominic Farolino>
Can we treat "not present undefined" differently than "present but explicitly undefined", for members of a Web IDL dictionary? I think we can because in the former, the member would simply not [=map/exist=], while the latter would explicitly trigger Web IDL conversion steps from `undefined` -> the specified type. Is that right?

[06:22:59.0573] <Ms2ger>
No, explicit undefined isn't converted; see 4.1.3 https://webidl.spec.whatwg.org/#js-dictionary


2024-02-14
[05:46:53.0203] <zcorpan>
annevk: Do you know why this particular `Accept` value is in the spec for images? https://fetch.spec.whatwg.org/#ref-for-concept-request-destination%E2%91%A0%E2%91%A2

[05:59:24.0104] <zcorpan>
annevk: I found https://github.com/whatwg/fetch/issues/43#issuecomment-97909717 and https://github.com/whatwg/fetch/commit/d095fdcf284cd36e9ddee526ad6faa6fda4ecc00

[06:05:40.0278] <zcorpan>
(context: https://bugzilla.mozilla.org/show_bug.cgi?id=1711622 )


2024-02-15
[01:44:55.0858] <smaug>
hmm, dom spec has some animation when clicking on an algorithm (to get the popup where it is referred from) Maybe it has been there for quite some time, but it is a bit annoying

[02:19:10.0285] <Noam Rosenthal>
smaug: hsivonen any thoughts on https://github.com/whatwg/html/pull/9970#discussion_r1489167432?

There was a question whether allowing the new `<link rel=expect>` to also consider `<a name>` and not just IDs would have a parser performance implications...

(My sense of logic says it would be fine but I'm reading the room's topic).

[03:54:34.0553] <hsivonen>
> <@noamr:matrix.org> smaug: hsivonen any thoughts on https://github.com/whatwg/html/pull/9970#discussion_r1489167432?
> 
> There was a question whether allowing the new `<link rel=expect>` to also consider `<a name>` and not just IDs would have a parser performance implications...
> 
> (My sense of logic says it would be fine but I'm reading the room's topic).

I can't say for perf for real right now.

(In any case, we should file the `id` vs. `name` thing on some list of mistakes that can be referred to when someone suggests giving some pre-existing thing a second better-bikeshedded name. This one is from 1998 (or earlier?) and still keeps popping up like this.)

[03:56:09.0354] <hsivonen>
I do expect taking `name` into account to be more complex and to have some gotcha. Not sure if I can claim a perf effect, though.

[03:56:39.0731] <smaug>
it feels very surprising to support name

[03:56:54.0305] <smaug>
it isn't then idref but something else

[03:57:01.0975] <smaug>
what is the need?

[03:57:07.0853] <Noam Rosenthal>
Just `<a name>` like when scrolling

[03:57:30.0439] <Noam Rosenthal>
there is no need except from being consistent with other links with `href` that take this into consideration

[03:59:20.0613] <Noam Rosenthal>
I'm also fine with starting with ID only and then see later if we need to follow up. I don't find the consistency argument strong here, `<link rel=expect>` is a new thing anyway and you don't necessarily need to be consistent with some old way we used to create scroll-to points in the document

[04:00:26.0237] <smaug>
yeah, I don't think this is really about consistency

[04:00:43.0206] <smaug>
<a name> and render blocking are quite different concepts 

[04:01:13.0502] <smaug>
so, I'd rather prefer simplicity here

[04:05:45.0711] <Noam Rosenthal>
zcorpan: thoughts on ^^^ ?

[04:13:09.0170] <smaug>
Noam Rosenthal: oh, wait, I change my mind. The syntax is really href

[04:15:24.0314] <Noam Rosenthal>
smaug: yes, the syntax is href.

[04:15:47.0128] <smaug>
so it is resolved as an url 

[04:15:56.0997] <smaug>
I assume

[04:16:29.0672] <Noam Rosenthal>
yes. you can also put a whole URL in there and as long as it resolves to a same-document fragment in the end (given `base` etc) it would try to match

[04:16:58.0902] <Noam Rosenthal>
it uses the same matching algorithm for the normal scroll-to (try first without percent encoding, then with)

[04:17:35.0771] <Noam Rosenthal>
OTOH it doesn't respect "top" etc because that's nonsensical

[04:17:35.0979] <smaug>
other thing is that rel=expect ... blocking=render feels a bit verbose. I need to read some discussion why we ended up with rel=expect

[04:17:54.0818] <Noam Rosenthal>
there was a loooong discussion about it

[04:18:37.0321] <Noam Rosenthal>
you mean as opposed to not having rel at all?

[04:19:11.0017] <Noam Rosenthal>
(I personally don't mind that if you want to render-block on things you have to be a bit verbose. This is an advanced feature in a way)

[04:20:41.0035] <smaug>
...looked, and ok, seems fine. verbose but fine

[06:19:57.0465] <zcorpan>
Noam Rosenthal: smaug: We do have an opportunity to move away from rel/href for same-document references. I know we had a long discussion already. But `<link expect=someid blocking=render>` is less verbose and could have a real idref like `<label for>`

[06:22:34.0075] <Noam Rosenthal>
it feels weird to have a `link` without a `rel`.

[06:23:13.0957] <zcorpan>
Noam Rosenthal: same for `<meta charset=utf-8>`, but we did that anyway

[06:24:54.0967] <Noam Rosenthal>
 It does feel that adding all these URL-ish things to this feature doesn't add value, but at this point I don't think those options are materially different.

[06:26:55.0426] <Noam Rosenthal>
... as in, their differences relate to options that people are not going to use in practice

[06:29:17.0752] <smaug>
<link> is already weird in many ways, since what people usually think as link is <a href>

[06:31:39.0219] <zcorpan>
Noam Rosenthal: I think the `base` handling is a disadvantage with `href` - people will just use a hash, and if they put a `base` element in then the render blocking thing stops working (while `label for` continues to work). I don't know how common `base` is, but it seems avoidable.

[06:32:30.0323] <Noam Rosenthal>
Can you do this? `<link expect=id blocking=render rel=stylesheet href="style.css">`

[06:32:53.0911] <smaug>
(link used to be more like a normal link before https://github.com/whatwg/html/pull/6269 )

[06:36:22.0546] <Noam Rosenthal>
zcorpan: I agree that the `base` thing is error-prone

[06:41:48.0549] <zcorpan>
> <@noamr:matrix.org> Can you do this? `<link expect=id blocking=render rel=stylesheet href="style.css">`

Sure, but we can make it a document conformance error

[06:42:35.0528] <Noam Rosenthal>
OK. I wonder what Domenic thinks about these alternatives (in Tokyo business hours :))

[06:50:12.0663] <zcorpan>
Did handling of fragment-only links with a base url change at some point? I recall them being same-document references even if there was a base url, but that has changed?

[06:54:47.0259] <Noam Rosenthal>
zcorpan: it changed during the spec review;

[06:55:11.0503] <zcorpan>
Noam Rosenthal: I mean for links in general, e.g. `a href`

[06:55:32.0269] <Noam Rosenthal>
oh I don't know then

[06:57:51.0159] <zcorpan>
demo https://software.hixie.ch/utilities/js/live-dom-viewer/saved/12380 - gecko/chromium/webkit apply the base url


2024-02-16
[19:18:35.0774] <Domenic>
> <@smaug:mozilla.org> hmm, dom spec has some animation when clicking on an algorithm (to get the popup where it is referred from) Maybe it has been there for quite some time, but it is a bit annoying

I tried to convince the Bikeshed maintainers to remove it, but failed. Maybe you can try again. https://github.com/speced/bikeshed/issues/2772

[19:19:17.0224] <Domenic>
Root cause is https://matrixlogs.bakkot.com/WHATWG/2024-01-26#L2-L3

[19:21:04.0169] <Domenic>
> <@zcorpan:mozilla.org> Did handling of fragment-only links with a base url change at some point? I recall them being same-document references even if there was a base url, but that has changed?

You may be thinking of CSS url()? IIRC those fail to respect <base>. But href="" has always respected <base>.

[22:49:14.0790] <sideshowbarker>
Has anybody ever run into a problem with bikeshed generating output with yesterday‚Äôs date rather than today‚Äôs date?

I‚Äôm running bikeshed locally, and it‚Äôs putting 15 February 2024 into the output it‚Äôs generating‚Ä¶

[22:50:31.0990] <sideshowbarker>
When I was doing the exact same thing yesterday, it was putting 15 February 2024 as expected. But that was yesterday

[22:53:12.0242] <sideshowbarker>
I find nowhere in my build environment where the date would getting persisted somehow

[00:17:43.0519] <Domenic>
Maybe it's picking UTC dates?

[06:19:10.0018] <Noam Rosenthal>
zcorpan: how about `<link rel=expect idref=foo blocking=render>`? It's a tad more verbose, but then we can use IDRefs for future "internal resource links", they don't have to be "expect", and it feels a bit more consistent with links.

[06:21:05.0479] <Noam Rosenthal>
(rel was never the problem here, it was reusing `href`)

[07:47:29.0877] <annevk>
Ms2ger: not entirely sure tbh. Apparently worklets is more complicated than I remembered.

[07:48:19.0227] <annevk>
zcorpan: don't quite remember, it might need some rethinking 

[07:50:17.0982] <Ms2ger>
> <@annevk:matrix.org> Ms2ger: not entirely sure tbh. Apparently worklets is more complicated than I remembered.

Yeah, I saw something pass by. I reverted the times, since those at least seem pretty clearly to be a problem. Happy to adjust around microtasks as that clears up

[07:50:38.0225] <Ms2ger>
Please let me know if there's anything I can do to make review easier

[11:19:22.0291] <annevk>
jfernandez: do you know if ed25519 has been brought to WebAppSec yet?

[13:26:59.0435] <jfernandez>
Not yet, as far as I known 

[13:27:57.0246] <jfernandez>
From one side, I wanted to wait until blink and WebKit ship it by default, ideally both ed25519 and x25519 

[13:29:13.0046] <jfernandez>
On the other hand, the spec editor prefers to implement also the Curve488 algorithms and propose both curves altogether 

[13:30:07.0610] <jfernandez>
I don‚Äôt agree with that, thought; I think we can bring Curve25519 first 

[13:40:19.0805] <annevk>
jfernandez: I think bringing it to WebAppSec before shipping would be good. Having it in a proper standards setting will help ensure we're all on the same page. I'm at least somewhat hesitant to approve WebKit shipping WICG-only things.

[13:40:46.0102] <annevk>
jfernandez: FWIW, I agree with you in terms of scope.

[13:50:00.0117] <jfernandez>
> <@annevk:matrix.org> jfernandez: I think bringing it to WebAppSec before shipping would be good. Having it in a proper standards setting will help ensure we're all on the same page. I'm at least somewhat hesitant to approve WebKit shipping WICG-only things.

Ed25519 is already shipped in WebKit, btw 

[13:50:53.0837] <jfernandez>
But yeah, it‚Äôs indeed better to propose it in the WebAppSec as soon as possible 

[13:52:13.0134] <jfernandez>
I‚Äôll take care of it 

[15:19:05.0955] <aja>
FYI https://groups.google.com/a/mozilla.org/g/dev-platform/c/xlLoQdgJy-I


2024-02-19
[21:05:34.0620] <sideshowbarker>
> <@domenicdenicola:matrix.org> Maybe it's picking UTC dates?

Yeah I had thought about that ‚Äî but at the time of day when I had been trying it on the 16th locally and Bikeshed was using the wrong date, it was actually already the 16th in UTC time too

Anyway, I resorted to just putting `Date: now` in the `.bs` source, and that made Bikeshed stop putting the wrong, previous-day date

[21:07:57.0586] <sideshowbarker>
> <@domenicdenicola:matrix.org> Maybe it's picking UTC dates?

 * Yeah I had thought about that ‚Äî but at the time of day when I had been trying it on the 16th locally and Bikeshed was using the 15th as the date, it was actually already the 16th in UTC time too

Anyway, I resorted to just putting `Date: now` in the `.bs` source, and that made Bikeshed stop putting the wrong, previous-day date

[23:01:08.0479] <sideshowbarker>
TabAtkins: For `bikeshed echidna`, are you aware of any (previous) cases where the W3C service has been unable to extract the generated tar file?

In particular, for jobs running user GitHub Actions?

I have a reproducible case where locally (in my macOS environment) when I use `bikeshed echidna ‚Ä¶ --u ‚Ä¶ --p ‚Ä¶` to generate and send the tar file to the W3C service, it succeeds as expected.

And when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions with one particular Bikeshed spec source file, publishing it with the W3C service also succeeds as expected.

But when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions in exactly the same way with another particular Bikeshed spec source file, publishing it with the W3C service also fails unexpectedly.

And troubleshooting it with help from Denis, he says it‚Äôs failing in that case because the W3C service is unable to extract the tar file successfully.

FWIW, Denis says the service uses https://github.com/mafintosh/tar-stream to parse/extract tar files ‚Äî so they may be some bug in that.

Anyway, I worked around it by switching the GitHub Actions build for the spec(s) to use the system `tar` command, rather than using `bikeshed echidna`.

And FWIW https://github.com/WebAssembly/spec/pull/1730 is where this fun has been happening ‚Äî and the spec that the failure was happening for with `bikeshed echidna` submission is the WebAssembly JavaScript API spec, the Bikeshed source for which is at https://github.com/WebAssembly/spec/blob/main/document/js-api/index.bs

[23:01:57.0529] <sideshowbarker>
 * TabAtkins: For `bikeshed echidna`, are you aware of any (previous) cases where the W3C service has been unable to extract the generated tar file?

In particular, for jobs running user GitHub Actions?

I have a reproducible case where locally (in my macOS environment) when I use `bikeshed echidna ‚Ä¶ --u ‚Ä¶ --p ‚Ä¶` to generate and send the tar file to the W3C service, it succeeds as expected.

And when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions with one particular Bikeshed spec source file, publishing it with the W3C service also succeeds as expected.

But when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions in exactly the same way with another particular Bikeshed spec source file, publishing it with the W3C service also fails unexpectedly.

And troubleshooting it with help from Denis, he says it‚Äôs failing in that case because the W3C service is unable to extract the tar file successfully.

FWIW, Denis says the service uses https://github.com/mafintosh/tar-stream to parse/extract tar files ‚Äî so there may be some bug in that.

Anyway, I worked around it by switching the GitHub Actions build for the spec(s) to use the system `tar` command, rather than using `bikeshed echidna`.

And FWIW https://github.com/WebAssembly/spec/pull/1730 is where this fun has been happening ‚Äî and the spec that the failure was happening for with `bikeshed echidna` submission is the WebAssembly JavaScript API spec, the Bikeshed source for which is at https://github.com/WebAssembly/spec/blob/main/document/js-api/index.bs

[23:02:22.0140] <sideshowbarker>
 * TabAtkins: For `bikeshed echidna`, are you aware of any (previous) cases where the W3C service has been unable to extract the generated tar file?

In particular, for jobs running user GitHub Actions?

I have a reproducible case where locally (in my macOS environment) when I use `bikeshed echidna ‚Ä¶ --u ‚Ä¶ --p ‚Ä¶` to generate and send the tar file to the W3C service, it succeeds as expected.

And when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions with one particular Bikeshed spec source file, publishing it with the W3C service also succeeds as expected.

But when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions in exactly the same way with another particular Bikeshed spec source file, publishing it with the W3C service also fails unexpectedly.

And troubleshooting it with help from Denis, he says it‚Äôs failing in that case because the W3C service is unable to extract the tar file successfully.

FWIW, Denis says the service uses https://github.com/mafintosh/tar-stream to parse/extract tar files ‚Äî so there may be some bug in that library.

Anyway, I worked around it by switching the GitHub Actions build for the spec(s) to use the system `tar` command, rather than using `bikeshed echidna`.

And FWIW https://github.com/WebAssembly/spec/pull/1730 is where this fun has been happening ‚Äî and the spec that the failure was happening for with `bikeshed echidna` submission is the WebAssembly JavaScript API spec, the Bikeshed source for which is at https://github.com/WebAssembly/spec/blob/main/document/js-api/index.bs

[23:11:59.0851] <sideshowbarker>
 * TabAtkins: For `bikeshed echidna`, are you aware of any (previous) cases where the W3C service has been unable to extract the generated tar file?

In particular, for jobs running user GitHub Actions?

I have a reproducible case where:

- locally (in my macOS environment) when I use `bikeshed echidna ‚Ä¶ --u ‚Ä¶ --p ‚Ä¶` to generate and send the tar file to the W3C service, it succeeds as expected.

- and when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions with one particular Bikeshed spec source file, publishing it with the W3C service also succeeds as expected.

- but when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions in exactly the same way with another particular Bikeshed spec source file, publishing it with the W3C service also fails unexpectedly.

And troubleshooting it with help from Denis, he says it‚Äôs failing in that case because the W3C service is unable to extract the tar file successfully.

FWIW, Denis says the service uses https://github.com/mafintosh/tar-stream to parse/extract tar files ‚Äî so there may be some bug in that library.

Anyway, I worked around it by switching the GitHub Actions build for the spec(s) to use the system `tar` command, rather than using `bikeshed echidna`.

And FWIW https://github.com/WebAssembly/spec/pull/1730 is where this fun has been happening ‚Äî and the spec that the failure was happening for with `bikeshed echidna` submission is the WebAssembly JavaScript API spec, the Bikeshed source for which is at https://github.com/WebAssembly/spec/blob/main/document/js-api/index.bs

[23:13:40.0821] <sideshowbarker>
 * TabAtkins: For `bikeshed echidna`, are you aware of any (previous) cases where the W3C service has been unable to extract the generated tar file?

In particular, for jobs running user GitHub Actions?

I have a reproducible case where:

- locally (in my macOS environment) when I use `bikeshed echidna ‚Ä¶ --u ‚Ä¶ --p ‚Ä¶` to generate and send the tar file to the W3C service, it succeeds as expected.
- and when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions with one particular Bikeshed spec source file, publishing it with the W3C service also succeeds as expected.
- but when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions in exactly the same way with another particular Bikeshed spec source file, publishing it with the W3C service also fails unexpectedly.

And troubleshooting it with help from Denis, he says it‚Äôs failing in that case because the W3C service is unable to extract the tar file successfully.

FWIW, Denis says the service uses https://github.com/mafintosh/tar-stream to parse/extract tar files ‚Äî so there may be some bug in that library.

Anyway, I worked around it by switching the GitHub Actions build for the spec(s) to use the system `tar` command, rather than using `bikeshed echidna`.

And FWIW https://github.com/WebAssembly/spec/pull/1730 is where this fun has been happening ‚Äî and the spec that the failure was happening for with `bikeshed echidna` submission is the [WebAssembly JavaScript API spec](https://www.w3.org/TR/wasm-js-api-2/), the Bikeshed source for which is at https://github.com/WebAssembly/spec/blob/main/document/js-api/index.bs

[00:07:13.0715] <sideshowbarker>
 * TabAtkins: For `bikeshed echidna`, are you aware of any (previous) cases where the W3C service has been unable to extract the generated tar file?

In particular, for jobs running user GitHub Actions?

I have a reproducible case where:

- locally (in my macOS environment) when I use `bikeshed echidna ‚Ä¶ --u ‚Ä¶ --p ‚Ä¶` to generate and send the tar file to the W3C service, it succeeds as expected. ‚úÖ
- and when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions with one particular Bikeshed spec source file, publishing it with the W3C service also succeeds as expected. ‚úÖ
- but when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions in exactly the same way with another particular Bikeshed spec source file, publishing it with the W3C service also fails unexpectedly. ‚ùå

And troubleshooting it with help from Denis, he says it‚Äôs failing in that case because the W3C service is unable to extract the tar file successfully.

FWIW, Denis says the service uses https://github.com/mafintosh/tar-stream to parse/extract tar files ‚Äî so there may be some bug in that library.

Anyway, I worked around it by switching the GitHub Actions build for the spec(s) to use the system `tar` command, rather than using `bikeshed echidna`.

And FWIW https://github.com/WebAssembly/spec/pull/1730 is where this fun has been happening ‚Äî and the spec that the failure was happening for with `bikeshed echidna` submission is the [WebAssembly JavaScript API spec](https://www.w3.org/TR/wasm-js-api-2/), the Bikeshed source for which is at https://github.com/WebAssembly/spec/blob/main/document/js-api/index.bs

[00:08:09.0100] <sideshowbarker>
 * TabAtkins: For `bikeshed echidna`, are you aware of any (previous) cases where the W3C service has been unable to extract the generated tar file?

In particular, for jobs running user GitHub Actions?

I have a reproducible case where:

- locally (in my macOS environment) when I use `bikeshed echidna ‚Ä¶ --u ‚Ä¶ --p ‚Ä¶` to generate and send the tar file to the W3C service, it succeeds as expected. ‚úÖ
- and when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions with one particular Bikeshed spec source file, publishing it with the W3C service also succeeds as expected. ‚úÖ
- but when I use `bikeshed echidna ‚Ä¶ --just-tar` under GitHub Actions in exactly the same way with another particular Bikeshed spec source file instead, publishing it with the W3C service fails unexpectedly. ‚ùå

And troubleshooting it with help from Denis, he says it‚Äôs failing in that case because the W3C service is unable to extract the tar file successfully.

FWIW, Denis says the service uses https://github.com/mafintosh/tar-stream to parse/extract tar files ‚Äî so there may be some bug in that library.

Anyway, I worked around it by switching the GitHub Actions build for the spec(s) to use the system `tar` command, rather than using `bikeshed echidna`.

And FWIW https://github.com/WebAssembly/spec/pull/1730 is where this fun has been happening ‚Äî and the spec that the failure was happening for with `bikeshed echidna` submission is the [WebAssembly JavaScript API spec](https://www.w3.org/TR/wasm-js-api-2/), the Bikeshed source for which is at https://github.com/WebAssembly/spec/blob/main/document/js-api/index.bs

[05:05:48.0745] <TabAtkins>
Weird, no, haven't heard of that before. But with a reproducible case I'm sure we can fix it. On vacation this week tho. I'll be back on Monday.


2024-02-20
[16:59:06.0916] <sideshowbarker>
hsivonen: https://github.com/validator/htmlparser/pull/91

[01:10:00.0171] <zcorpan>
> <@noamr:matrix.org> zcorpan: how about `<link rel=expect idref=foo blocking=render>`? It's a tad more verbose, but then we can use IDRefs for future "internal resource links", they don't have to be "expect", and it feels a bit more consistent with links.

That seems OK

