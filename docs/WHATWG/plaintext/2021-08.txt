2021-08-01

2021-08-02
[02:58:24.0400] <jgraham>
Can someone point out to me what the errors are which are causing https://github.com/whatwg/html/pull/6921/checks?check_run_id=3205414516 to fail?

[03:23:57.0007] <sideshowbarker>
jgraham: https://github.com/whatwg/html/pull/6921/checks?check_run_id=3205414516#step:3:91
```
unloaded</span>, , then invoke <span>WebDriver BiDi navigation failed</span> with
```
The `, ,` there, I guess? (And possibly some other things after — I stopped looking when I found that `, ,`…)

[03:39:07.0053] <jgraham>
sideshowbarker: Apparently not :( Would be nice if this would print out which lint rules are actually failing in each case

[03:39:36.0296] <jgraham>
(for clarity: I fixed the `, ,` and still get the errors)

[05:10:06.0715] <sideshowbarker>
jgraham: I’ll check out the branch now, and try to see if I can debug it locally

[05:37:24.0859] <sideshowbarker>
jgraham: the one that’s failing is this:
>   perl -ne '$/ = "\n\n"; print "$_" if (/chosing|approprate|occured|elemenst|\bteh\b|\blabelled\b|\blabelling\b|\bhte\b|taht|linx\b|speciication|attribue|kestern|horiontal|\battribute\s+attribute\b|\bthe\s+the\b|\bthe\s+there\b|\bfor\s+for\b|\bor\s+or\b|\bany\s+any\b|\bbe\s+be\b|\bwith\s+with\b|\bis\s+is\b/si)' "$1" | perl -lpe 'print "\nPossible typos:" if $. == 1'


[05:37:36.0464] <sideshowbarker>
will look further

[05:38:00.0586] <sideshowbarker>
(And by the way I did not write this code.)

[05:39:03.0683] <jgraham>
Would be nice if it printed the actual re match along with the paragraph

[05:40:23.0548] <sideshowbarker>
indeed yeah it would be nice

[05:40:28.0031] <sideshowbarker>
this is nuts

[05:40:47.0048] <sideshowbarker>
anyway, I spotted a possible cause

[05:41:01.0196] <sideshowbarker>
“with with”

[05:41:12.0173] <sideshowbarker>
in lines 2-3 of the patch

[05:41:25.0969] <sideshowbarker>
will try fixing that now and re-testing

[05:44:26.0441] <sideshowbarker>
OK yeah, fixed three instances of that, and have one remaining other yet-unknown cause. Checking further…

[05:44:47.0075] <sideshowbarker>
ah, same — “with with”

[05:45:21.0212] <sideshowbarker>
yup, all fixed

[05:45:30.0645] <sideshowbarker>
will push a commit to your branch

[05:46:15.0332] <sideshowbarker>
…and done

[05:47:12.0241] <sideshowbarker>
sorry about that linter — we need to fix that

[06:03:07.0781] <jgraham>
sideshowbarker: Thanks!

[06:12:58.0185] <sideshowbarker>
cheers


2021-08-03
[06:21:32.0095] <annevk>
sideshowbarker: Domenic: if you could look at https://github.com/whatwg/dom/pull/1004 at least up until line 2100 that'd be terrific

[06:27:57.0256] <sideshowbarker>
annevk: will look now

[07:53:25.0299] <annevk>
Thanks sideshowbarker. To be clear though, I was thinking of aligning more prose with this new model if it looks good. There's actually quite a lot of text is impacted.

[07:54:00.0639] <sideshowbarker>
annevk: so you want suggestions on what else needs to be changed?

[07:54:25.0726] <annevk>
sideshowbarker: no, just if this direction looks good as a thing to expand upon; I can find the rest :-)

[07:54:43.0918] <sideshowbarker>
OK, I think in general it’s definitely an improvement

[07:55:25.0257] <sideshowbarker>
I am as usual more interested in the use case of web developers reading the spec than I am for implementors

[07:56:25.0269] <sideshowbarker>
as far as implementors, I get the impression that the existing spec works well overall for anybody implementing/writing code from it

[07:56:33.0776] <sideshowbarker>
 * as far as implementors, I get the impression that the existing spec works well overall for anybody implementing/writing code from it

[07:56:55.0931] <sideshowbarker>
but I think it’s a lot harder for developers to learn from

[07:57:07.0004] <annevk>
Apparently jsdom ran into issues with "is a Text node" not clearly including CDATASection nodes

[07:57:14.0710] <sideshowbarker>
aha

[07:57:43.0010] <sideshowbarker>
OK, yeah, I wondered who would actually be implementing these parts at this point

[07:58:39.0298] <annevk>
You don't really want to say Text or CDATASection however as otherwise you also need to say Element or HTMLAnchorElement or ... It gets tricky quickly

[07:59:09.0452] <sideshowbarker>
yeah, I can see that

[07:59:14.0889] <annevk>
Anyway, I hope that depending on CharacterData in a number of cases will make that more clear, as well as more clearly explaining what X node is.

[08:00:26.0929] <sideshowbarker>
I have recently been looking at some of the lowe-level DOM-related content at MDN, and to speak generously… it has a lot of room for improvement

[08:00:55.0943] <sideshowbarker>
there is actually nowhere any good “Introduction to the DOM” for web developers

[08:01:15.0239] <Domenic>
> <@annevk:mozilla.org> You don't really want to say Text or CDATASection however as otherwise you also need to say Element or HTMLAnchorElement or ... It gets tricky quickly

The difference is that when working in "DOM" code as opposed to "HTML" code, it's pretty natural to use .nodeType a lot.

[08:01:58.0359] <annevk>
Domenic: yeah that's fair, but there's nothing that corresponds to nodeType

[08:02:17.0083] <Domenic>
Yeah it's just very easy to think that "is a Text node" means .nodeType === TEXT_NODE

[08:02:32.0291] <Domenic>
I just opened the PR but if you use "implements" that will help.

[11:37:35.0061] <favonia>
Hi, I was checking the standard library of the Go programming language and found that the STD3 rules are disabled by default in the current WHATWG URL standard. I was a bit surprised because many Unicode characters in their KC normal forms could introduce forbidden host code points `@`, `#`, `/`, ... that are dangerous or at least misleading. The STD3 check protects us from those dangerous characters. I understand many existing hosts have the underscore `_` in their names that is forbidden by the STD3, but by disabling the entire STD3 check, we become vulnerable to many other attacks based on Unicode normalization. I believe this must have been carefully discussed somewhere within WHATWG. If not, I wonder how I should comment on the current URL standard and propose new changes. I am familiar with GitHub operations but I never interacted with WHATWG before, and would appreciate your guidance in making a proposal.

TL;DR: I wish to add a warning about the danger of disabling the STD3 check and, if an application chooses to disable the STD3 check (possibly to allow the underscore), it should verify that forbidden host code points would never arise from normalization and mapping.

[13:12:16.0771] <Domenic>
favonia: I don't think I understand the issue. Because those are forbidden host code points parsing will fail if they appear. It doesn't matter for the spec whether the parsing fails due to Unicode STD3 checking or because of the explicit step 7 in https://url.spec.whatwg.org/#concept-host-parser

[13:12:42.0938] <Domenic>
 * favonia: I don't think I understand the issue. Because those are forbidden host code points parsing will fail if they appear. It doesn't matter for the spec whether the parsing fails due to Unicode STD3 checking in step 5 or because of the explicit step 7 in https://url.spec.whatwg.org/#concept-host-parser

[14:06:19.0998] <favonia>
> <@domenicdenicola:matrix.org> favonia: I don't think I understand the issue. Because those are forbidden host code points parsing will fail if they appear. It doesn't matter for the spec whether the parsing fails due to Unicode STD3 checking in step 5 or because of the explicit step 7 in https://url.spec.whatwg.org/#concept-host-parser

As far as I understand, Step 7 does not prevent such attacks. The attack is that the _same_ URL (record) has multiple Unicode normal forms that would be parsed differently. Here is an example: 
```
https://google.com\uFF03@evil.com
```
A parser would give the following results:
- username: `google.com\uFF03`
- host: `evil.com`

But with its NFKC:
```
https://google.com#@evil.com
```
a parser would give these results instead:
- host: `google.com`
- fragment: `@evil.com`

So, the string and one of its normal forms are both valid URL records, but with different structures. The discrepancies can be exploited in many IDNA-aware applications to fool users or even bypass security checking. This attack is known as HostSplit.

[14:07:25.0388] <favonia>
> <@domenicdenicola:matrix.org> favonia: I don't think I understand the issue. Because those are forbidden host code points parsing will fail if they appear. It doesn't matter for the spec whether the parsing fails due to Unicode STD3 checking in step 5 or because of the explicit step 7 in https://url.spec.whatwg.org/#concept-host-parser

 * As far as I understand, Step 7 does not prevent such attacks. One attack is that the _same_ URL (record) has multiple Unicode normal forms that would be parsed differently. Here is an example:
```
https://google.com\uFF03@evil.com
```

A parser would give the following results:
- username: `google.com\uFF03`
- host: `evil.com`

But with its NFKC:
```
https://google.com#@evil.com
```

a parser would give these results instead:
- host: `google.com`
- fragment: `@evil.com`

So, the string and one of its normal forms are both valid URL records, but with different structures. The discrepancies can be exploited in many IDNA-aware applications to fool users or even bypass security checking. This attack is known as HostSplit.

[14:08:36.0298] <favonia>
 * As far as I understand, Step 7 does not prevent such attacks. One attack is that the _same_ URL (record) has multiple Unicode normal forms that would be parsed differently. Here is an example:
```
https://google.com\uFF03@evil.com
```

A parser would give the following results:
- username: `google.com\uFF03`
- host: `evil.com`

But with its NFKC (where `\uFF03` is normalized to `#`):
```
https://google.com#@evil.com
```

a parser would give these results instead:
- host: `google.com`
- fragment: `@evil.com`

So, the string and one of its normal forms are both valid URL records, but with different structures. The discrepancies can be exploited in many IDNA-aware applications to fool users or even bypass security checking. This attack is known as HostSplit.

[14:13:46.0165] <Domenic>
That is not how those URLs are parsed

[14:13:51.0903] <Domenic>
See https://jsdom.github.io/whatwg-url/#url=aHR0cHM6Ly9nb29nbGUuY29tI0BldmlsLmNvbQ==&base=YWJvdXQ6Ymxhbms=

[14:14:17.0860] <Domenic>
and https://jsdom.github.io/whatwg-url/#url=aHR0cHM6Ly9nb29nbGUuY29t77yDQGV2aWwuY29t&base=YWJvdXQ6Ymxhbms=

[14:16:28.0893] <Domenic>
I guess your larger point remains though

[14:16:41.0273] <Domenic>
Which is yes, different input strings can product different hosts

[14:16:52.0819] <Domenic>
Opening an issue to discuss that seems fine if you want?

[14:17:39.0317] <favonia>
Oops, sorry for my mistakes. It's hard to construct such contrived examples on the fly. 😛 Maybe `https://localhost＃@evil.com` and `https://localhost#@evil.com` would work.

[14:47:47.0104] <favonia>
After some thinking I realized this is probably more serious than I thought---the STD3 rules in UTS#46 could prevent some attacks but seem powerless to handle `https://localhost＃@evil.com` v.s. `https://localhost#@evil.com` where the problematic character is never part of the host/domain name. 😱

[14:50:18.0803] <favonia>
I can start a GitHub issue, though I will not be able to meaningfully participate in the discussions probably after two weeks. (I'm teaching in a university and the semester is starting...) Also, I am not an expert on Unicode/URL, merely a concerned user after reading these documents. There might be many strange corner cases that I am not aware of. Therefore, perhaps someone else should take the lead? I can still take the initiative.

[14:58:51.0874] <favonia>
PS: consistently applying STD3 rules can probably detect something like `https://cool.asi℀.evil.com` where `℀` could be normalized to `a/c`.

[15:01:01.0933] <Domenic>
https://cool.asi℀.evil.com is just an invalid URL https://jsdom.github.io/whatwg-url/#url=aHR0cHM6Ly9jb29sLmFzaeKEgC5ldmlsLmNvbQ==&base=YWJvdXQ6Ymxhbms=


2021-08-04
[17:12:48.0437] <sideshowbarker>
https://stackoverflow.com/questions/68641231/does-javascripts-abortable-fetch-close-the-http-connection

[17:29:16.0097] <favonia>
> <@domenicdenicola:matrix.org> https://cool.asi℀.evil.com is just an invalid URL https://jsdom.github.io/whatwg-url/#url=aHR0cHM6Ly9jb29sLmFzaeKEgC5ldmlsLmNvbQ==&base=YWJvdXQ6Ymxhbms=

Thank you. Now I see that the Step 7 you mentioned earlier implements a weaker version of the STD3 check that stopped my attack. However, I found another issue showing that whatwg-url probably violated (at least the spirit of) UTS#46. UTS#46 says:

> ...
> U+2260 ( ≠ ) NOT EQUAL TO
> U+226E ( ≮ ) NOT LESS-THAN
> U+226F ( ≯ ) NOT GREATER-THAN 
>
> ... If an implementation uses `UseSTD3ASCIIRules=false` but disallows any of these three ASCII characters, then it must also disallow the corresponding precomposed character for its negation. 

The URL standard forbids `<` and `>`, so I feel `≮` and `≯` should be banned as well. I am happy to open a GitHub issue on this (smaller issue).

https://jsdom.github.io/whatwg-url/#url=d3M6Ly88&base=YWJvdXQ6Ymxhbms=
https://jsdom.github.io/whatwg-url/#url=d3M6Ly/iia4=&base=YWJvdXQ6Ymxhbms=

[17:36:55.0374] <Domenic>
Yes, I think this is a case where conforming to the rules doesn't really buy anything. Encoding ≮ to punycode seems fine.

[17:37:47.0073] <Domenic>
It might be clearer if you think of the URL Standard as a standalone document that gives the full processing model. The fact that it calls into some specific Unicode algorithms with some parameters is interesting, but is just an implementation detail and isn't meant to indicate any greater alignment with the philosophies of those documents.

[17:42:25.0204] <favonia>
alright I will skip the reporting. it's perhaps an interesting technical point, though

[17:46:22.0835] <favonia>
Sorry I accidentally pressed Enter to create an issue when doing some complex editing on GitHub. Please give me some time to fix that :-/

[18:04:24.0614] <favonia>
Domenic: Is https://jsdom.github.io/whatwg-url some website I can/should cite in my reporting? The tool is very convenient and I wonder if it's "permanent" in any sense.

[18:39:11.0805] <Domenic>
favonia: yes, feel free to use that site.

[19:29:00.0506] <favonia>
> <@domenicdenicola:matrix.org> favonia: yes, feel free to use that site.

Done! https://github.com/whatwg/url/issues/626

[07:25:00.0831] <favonia>
> <@domenicdenicola:matrix.org> Yes, I think this is a case where conforming to the rules doesn't really buy anything. Encoding ≮ to punycode seems fine.

After checking the Unicode tables more carefully, I must disagree with this judgment and admit UTS#46 has done the right thing. My latest reporting was mainly about NFKC and NFKD, but if we agree that the standard should prevent problematic characters, then ≮, ≯ or even ≠ could generate <, > or = under NFD.

[07:25:50.0989] <favonia>
> <@domenicdenicola:matrix.org> Yes, I think this is a case where conforming to the rules doesn't really buy anything. Encoding ≮ to punycode seems fine.

 * After checking the Unicode tables more carefully, I must disagree with this judgment and admit UTS#46 has done the right thing. My latest reporting was mainly about NFKC and NFKD, but if we agree that the standard should prevent problematic characters on that basis, then ≮, ≯ or even ≠ could also generate <, > or = under NFD and should be banned as well.

[07:34:59.0516] <annevk>
That reading is only correct under the assumption that NFD(URL string) is a valid operation, which it's not; as long as you do URL parser(URL string) I don't think you have demonstrated an issue

[07:35:42.0023] <annevk>
I could see banning more code points out of caution (though we cannot ban all, e.g., `_` is important), but I wouldn't classify these as a problem with the URL parser

[07:39:53.0433] <favonia>
well... I did not imply that the current URL parser itself is wrong. I was only proposing to restrict valid URLs as you suggested. it would be kind of you to cite exact phrases which gave you such an impression so that I can revise my proposal.

[07:42:17.0763] <favonia>
Another thing is, according to your statements "You cannot apply Unicode normalization to all inputs" on GitHub, you seemed assume no normalization should be applied to URL strings. that's against the standard and W3C recommendations. NFC _must_ be applied to URL strings as well. There is a related page made by W3C Internationalization Activity: https://www.w3.org/International/questions/qa-html-css-normalization

[07:43:59.0055] <favonia>
 * Another thing is, according to your statement "You cannot apply Unicode normalization to all inputs" on GitHub, you seemed assume no normalization should be applied to URL strings. That's against the W3C recommendations. NFC _must_ be applied to URL strings as well. There is a related page made by W3C Internationalization Activity: https://www.w3.org/International/questions/qa-html-css-normalization

[07:44:08.0933] <favonia>
 * Another thing is, according to your statement "You cannot apply Unicode normalization to all inputs" on GitHub, you seemed assume no normalization should be applied to URL strings. That's against the W3C recommendations. NFC should be applied to URL strings as well. There is a related page made by W3C Internationalization Activity: https://www.w3.org/International/questions/qa-html-css-normalization

[07:45:22.0929] <favonia>
 * Another thing is, according to your statement "You cannot apply Unicode normalization to all inputs" on GitHub, you seemed assume no normalization should be applied to URL strings. That's against (at least the spirit of) the W3C recommendations. NFC should be applied to URL strings as well. There is a related page made by W3C Internationalization Activity: https://www.w3.org/International/questions/qa-html-css-normalization

[07:47:14.0263] <favonia>
 * Also, you seemed assume no normalization should be applied to URL strings. That's against (at least the spirit of) the W3C recommendations. NFC should be applied to URL strings as well. There is a related page made by W3C Internationalization Activity: https://www.w3.org/International/questions/qa-html-css-normalization

[07:51:17.0049] <annevk>
favonia: if you apply normalization at that level though, there is nothing the URL parser can do about it, because you cannot distinguish it from a URL that contains ASCII `#`

[07:52:58.0271] <favonia>
I want to repeat that I never implied that the URL parsing is at fault. Could you possibly cite the phrases that gave you such an impression? It seems we miscommunicated and I want to clear up the misunderstanding.

[07:53:08.0197] <annevk>
favonia: it might be worth raising with www-international@w3.org as it's a somewhat interesting case; you cannot take a URL from somewhere, validate its scheme and host, then put the input string in HTML that gets normalized; you'd have to put the serialization in which might not be something folks realize

[07:54:10.0555] <annevk>
favonia: you start out with talking about URL records, and URL records are the result of parsing

[07:54:32.0077] <favonia>
yes, but the parser is not the problem. at least not in my opinion.

[07:55:09.0269] <annevk>
"A proper fix would probably be similar to the sanitization of host names." Isn't that a parser change?

[07:55:52.0737] <favonia>
> <@annevk:mozilla.org> I could see banning more code points out of caution (though we cannot ban all, e.g., `_` is important), but I wouldn't classify these as a problem with the URL parser

no, this is what I meant. thank you for citing exact phrases so that I can prevent other people from misunderstanding the proposal

[07:57:45.0024] <annevk>
To be clear, that would be a change to the URL parser aimed at helping scenarios where people parse a URL string to validate it and then somehow output NFX(URL string) elsewhere, which is a somewhat problematic practice for various reasons

[07:58:37.0261] <annevk>
E.g., the changes to the URL's path or query are not something we could prevent in that way

[07:58:56.0767] <annevk>
(I gotta go for a bit)

[08:02:51.0777] <favonia>
> <@annevk:mozilla.org> To be clear, that would be a change to the URL parser aimed at helping scenarios where people parse a URL string to validate it and then somehow output NFX(URL string) elsewhere, which is a somewhat problematic practice for various reasons

technically yes, but I think there's a difference between only enlarging the set of forbidden/disrecommended characters and changing the structure of the parser

[08:06:54.0561] <annevk>
A difference in what sense?

[08:30:49.0237] <favonia>
Could you possibly elaborate more so that I can better answer it? I am happy to simply admit it's a change to the parser.

[08:32:53.0933] <favonia>
I don't feel how I personally classify different levels of changes matter here. If WHATWG thinks it's a major change, then it's a major change. If WHATWG thinks it's a minor change, then it's a minor change. I am happy to eliminate different usages in terminology. 

[08:33:13.0528] <favonia>
 * I don't feel how I personally classify different levels of changes matter here. If WHATWG thinks it's a major change, then it's a major change. If WHATWG thinks it's a minor change, then it's a minor change. I am happy to eliminate different usages in terminology in case it helps communication.

[08:33:33.0866] <favonia>
 * I don't feel how I personally classify different levels of changes matters here. If WHATWG thinks it's a major change, then it's a major change. If WHATWG thinks it's a minor change, then it's a minor change. I am happy to eliminate different usages in terminology in case it helps communication.

[08:38:46.0203] <annevk>
I just noticed that `＃` is already rejected when it's part of a host, but it's not rejected when used as a username or password. So STD3 Rules wouldn't matter there either way.

[08:39:11.0455] <annevk>
As in, `https://test＃test/` results in failure.

[08:39:41.0848] <favonia>
that's correct. proper checking has been done for host names in the current standard.

[08:40:23.0582] <annevk>
So yeah, I don't think this is something that can be changed. Those components are expected to allow arbitrary scalar values.

[08:41:43.0441] <annevk>
It might be worth calling out somewhere though and I also think raising this with www-international could be worthwhile.

[08:42:07.0456] <favonia>
as a disclaimer I only read these documents like three days ago. as a naive suggestion how about demanding percentage-encoding? 

[08:42:14.0217] <favonia>
 * as a disclaimer I only read these documents like three days ago. as a naive suggestion how about demanding percent-encoding? 

[08:42:24.0130] <favonia>
 * as a disclaimer I only started reading these documents like three days ago. as a naive suggestion how about demanding percent-encoding? 

[08:42:30.0433] <favonia>
 * as a disclaimer I only started reading these documents like 2-3 days ago. as a naive suggestion how about demanding percent-encoding? 

[08:47:50.0835] <annevk>
favonia: it would be a breaking change, URL strings have allowed U+FF03 (＃) for well over a decade

[08:48:22.0050] <annevk>
It's easier to ban certain things in hosts because they don't resolve anyway, but we cannot do that for paths and such

[08:54:05.0685] <favonia>
got it. well, I feel no one is a warning against any normalization forms other than NFC. following your comment, I guess banning ≮, ≯ in host names would be fine, then? it has almost zero practical impacts while saving us from some terrible situations due to mishandling of host names.

[08:54:29.0562] <favonia>
 * got it. well, I feel no one is a warning against any normalization forms other than NFC, then? I can actually be satisfied with just that. following your comment, I guess banning ≮, ≯ in host names would be fine, then? it has almost zero practical impacts while saving us from some terrible situations due to mishandling of host names.

[08:55:00.0241] <favonia>
 * got it. well, I feel no one is a warning against any normalization forms other than NFC, then? I can actually be satisfied with just that. following your comment, I guess banning ≮, ≯ in host names would be fine? it has almost zero practical impacts while saving us from some terrible situations due to mishandling of host names.

[08:55:54.0869] <favonia>
 * got it. well, I feel no one is aganist a warning about normalization forms other than NFC, then? I can actually be satisfied with just that. following your comment, I guess banning ≮, ≯ in host names would be fine? it has almost zero practical impacts while saving us from some terrible situations due to mishandling of host names.

[08:57:27.0462] <annevk>
Well, e.g., ≮ becomes xn--gdh, and it's not clear we can make that inaccessible. And generally we forbid things after ToASCII succeeds, not before. So for that one I'm not sure. It would also depend on how we resolve various other longstanding IDNA issues.

[08:58:42.0243] <annevk>
If you apply NFD or some such to a domain name and then pass it to a host parser you are already likely to end up on the wrong website so it's not clear this would prevent all of these attacks so it might be better if sites address the root cause.

[09:00:13.0837] <annevk>
Heck, if you apply NFD to HTML in general you would open yourself up to all kinds of attacks.

[09:00:38.0270] <annevk>
There's a reason you want NFC unless you do some kind of specialized text processing.

[09:01:33.0677] <annevk>
You might enjoy http://www.diveintomark.link/2004/unicode-normalization-form-c

[09:02:53.0776] <favonia>
Hah, it's funny and to the point. :laugh

[09:03:03.0746] <favonia>
 * Hah, it's funny and to the point. 😆

[09:03:38.0073] <favonia>
to be fair KD would be even worse

[09:11:36.0849] <favonia>
> <@annevk:mozilla.org> If you apply NFD or some such to a domain name and then pass it to a host parser you are already likely to end up on the wrong website so it's not clear this would prevent all of these attacks so it might be better if sites address the root cause.

No you will be fine even after NFD unless the application has serious bugs. See <https://unicode.org/reports/tr46/#ProcessingStepNormalize>. You need to compute NFC which would undo the "damage". At least Firefox got this correct.

[09:20:38.0808] <favonia>
`whatwg-url` gives the correct result as well (which is not really surprising because the `tr46` package used by `whatwg-url` correctly implements UTS46) https://jsdom.github.io/whatwg-url/#url=aHR0cHM6Ly88zLg=&base=YWJvdXQ6Ymxhbms=

[09:24:04.0499] <favonia>
anyways, personally I am much less motivated to promote the banning of ≮ and ≯ in host names because it seems significantly harder to construct concrete attacks.

[09:24:18.0614] <favonia>
 * anyways, personally I am much less motivated to promote the banning of ≮ and ≯ in host names because it seems significantly harder to construct concrete attacks. it's just a possibility.

