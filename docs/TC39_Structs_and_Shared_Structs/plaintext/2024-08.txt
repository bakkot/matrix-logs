2024-08-28
[10:08:41.0996] <Mathieu Hofman>
shu: could you update the TC39 calendar invite for the meeting? Looks like it never got updated when we switched to biweekly

[10:12:28.0979] <shu>
Mathieu Hofman: ah i only switched my personal one? my bad, let me fix it now


2024-08-29
[11:55:28.0663] <kriskowal>
I seem to have bludgeoned the Join button enough times for Matrix to acknowledge my presence.

[11:57:06.0457] <nicolo-ribaudo>
Welcome

[11:58:29.0501] <rbuckton>
kriskowal: I tried to DM you the link I mentioned, but there are two matrix identities for you in the delegates chat and I may have sent them to the wrong one. Here's what I sent, in any case:

For reference, this Gist contains a brief analysis of an earlier proposed handshaking mechanism: https://gist.github.com/rbuckton/08d020fc80da308ad3a1991384d4ff62 
Alternatively, this other gist details possible mechanisms to grant/deny correlation as well as to support bundlers when correlating by source location: https://gist.github.com/rbuckton/b00ca9660fb888486da07b22e38dd1e9

[11:59:53.0523] <kriskowal>
> <@rbuckton:matrix.org> kriskowal: I tried to DM you the link I mentioned, but there are two matrix identities for you in the delegates chat and I may have sent them to the wrong one. Here's what I sent, in any case:
> 
> For reference, this Gist contains a brief analysis of an earlier proposed handshaking mechanism: https://gist.github.com/rbuckton/08d020fc80da308ad3a1991384d4ff62 
> Alternatively, this other gist details possible mechanisms to grant/deny correlation as well as to support bundlers when correlating by source location: https://gist.github.com/rbuckton/b00ca9660fb888486da07b22e38dd1e9

Yeah, Matrix isn’t good at chat. One cannot simply start up a new Matrix instance with friends and migrate their identity, much less convince Matrix the old one is gone, especially when matrix.org has forgotten its side of the credentials for it.

[12:04:53.0579] <kriskowal>
By a glance, it looks like this design direction hasn’t been considered or was dismissed out-of-hand:
```
struct Foo {}
addEventListener('message', event => {
  const foo = new Foo(event.data.foo);
});
```
Wherein, `Foo` is an opaque struct definition closing over the vm-specific vagaries of padding, alignment, embedding, dereferencing, &c, `event.data.foo` is an opaque handle on shared memory without behavior, and `new Foo(event.data.foo)` unites the data and behavior.

[12:05:50.0783] <kriskowal>
And, of course `Foo.prototype` captures the behavior side.

[12:09:11.0957] <shu>
what would this union do

[12:09:33.0669] <shu>
one of the primary goal here is to actually share the objects, not just share the payload

[12:10:10.0432] <shu>
this is because application state, by volume, is a lot of pointers. recreating your object graph from payloads per thread means you are not scaling with the number of threads

[12:10:22.0050] <shu>
so any solution that requires creating wrapper objects per-thread is a nonstarter

[12:10:25.0905] <kriskowal>
i’m assuming you mean sharing the backing memory, since the objects are necessarily in different realms

[12:10:50.0009] <shu>
yes, payload and backing memory are interchangeable for what i said

[12:11:06.0354] <shu>
a related question is "why not create object overlays on top of SABs"

[12:11:11.0362] <nicolo-ribaudo>
> <@kriskowal:aelf.land> i’m assuming you mean sharing the backing memory, since the objects are necessarily in different realms

If objects don't capture any realm-specific state, you can actually share the objects 

[12:11:55.0117] <kriskowal>
oh, right, we’re talking about a new primitive.

[12:12:32.0722] <nicolo-ribaudo>
This would be different from SharedArrayBuffer, where there is a per-thread wrapper pointing to the same memory

[12:13:14.0543] <shu>
> <@kriskowal:aelf.land> oh, right, we’re talking about a new primitive.

well, they're objects

[12:13:29.0562] <shu>
but yes, internally you can think of them as new primitives

[12:13:34.0464] <shu>
they're objects with special behavior

[12:13:45.0831] <kriskowal>
alright, so the crux of this is that the _value_ capturing the union of the shared memory and behavior must also be a primitive.

[12:14:11.0842] <shu>
sorry, having trouble parsing that sentence

[12:14:21.0525] <kriskowal>
i now better understand how we arrive at the prototype walk algorithm

[12:15:00.0147] <shu>
there's another alternative that was dismissed, which is actually thread-safe functions

[12:15:04.0960] <kriskowal>
there’s no per-worker object that points to the local prototype and shared data

[12:15:08.0604] <shu>
that is just too much a can of worms, and nobody wants a new callable type

[12:15:16.0204] <shu>
> <@kriskowal:aelf.land> there’s no per-worker object that points to the local prototype and shared data

yeah

[12:15:38.0368] <kriskowal>
this seems cursed

[12:15:54.0723] <shu>
heh, in what way?

[12:16:39.0527] <kriskowal>
i can see why this design direction forces today’s debate about where to put the global state

[12:16:51.0946] <shu>
ah, yeah

[12:17:46.0350] <iain>
For the record, I think it would be good to explore the thread-safe functions option at least a little bit. 

[12:18:02.0220] <shu>
i agree, as long as in parallel

[12:18:24.0084] <shu>
but identity discontinuity makes it _really_ difficult

[12:18:24.0604] <kriskowal>
the Moddable folks would be good to involve in a conversation about thread-safe functions.

[12:19:31.0704] <kriskowal>
XS is a bit unique in its design constraints, but does have thread-safe functions and can sense when a subgraph can be safely captured in ROM.

[12:19:45.0410] <iain>
There are many parts of this proposal that make big changes; I'm not convinced that new callables would be worse than some of the other proposed changes

[12:19:53.0941] <iain>
What do you mean by identity discontinuity?

[12:20:10.0026] <shu>
> <@iain:mozilla.org> There are many parts of this proposal that make big changes; I'm not convinced that new callables would be worse than some of the other proposed changes

i am

[12:20:33.0315] <shu>
i'm gonna need something more specific than "this is already large, therefore it has room for other large changes"

[12:20:40.0140] <kriskowal>
Identity discontinuity is `const source = '{}', eval(source) !== eval(source)`.

[12:21:16.0799] <kriskowal>
Which is not an interesting example, but `const source = 'class Foo { #p }'` is more interesting.

[12:21:45.0190] <shu>
> <@iain:mozilla.org> What do you mean by identity discontinuity?

specifically, i'm talking about how each global has its own set of Math, Object, Function, etc, that have distinct identity

[12:22:19.0987] <shu>
JS functions are closures very deep down, not just the JS user code closed-over stuff

[12:22:32.0249] <shu>
so we'd have to answer the question of what does that mean for thread-safe functions

[12:22:35.0632] <shu>
do they become more dynamically scoped?

[12:24:07.0288] <iain>
Without having thought it through much, I would want to say that they can't capture anything other than global variables, and global variables are always looked up in the local global.

[12:24:57.0200] <shu>
okay, so dynamically scoped to the caller global

[12:25:29.0676] <iain>
Yes. If there were a clean way to distinguish between `shared function foo() { return Math; }` and `var x; shared function foo() { return x; }`, I would also like to prohibit the latter.

[12:26:59.0634] <shu>
is it basically this thing i wrote up a while ago

[12:27:00.0158] <shu>
https://github.com/tc39/proposal-structs/blob/main/CODE-SHARING-IDEAS.md

[12:27:36.0042] <iain>
So that modulo monkey-patching, all the "dynamically scoped" stuff you're closing over is basically the same between realms

[12:27:54.0960] <iain>
That looks like a better thought out version of my vague notion, yes

[12:29:07.0184] <shu>
my conclusion is that i think it's a lot of work and a lot of complexity for the language for not as much gain as you might think

[12:29:29.0440] <shu>
like, people are gonna want to close over state in a thread-local way during computation

[12:29:32.0070] <shu>
and i think that's fine

[12:30:23.0964] <kriskowal>
It it imagined that every get/set of an individual property on a shared struct is implicitly an atomic on that individual field?

[12:30:28.0247] <shu>
and i believe more and more that we actually get more mileage out of letting people use the functions we have today on shared data, but make that ergonomic

[12:30:56.0669] <iain>
My hope is that doing something like this would let us significantly simplify the prototype problem

[12:31:18.0874] <shu>
> <@kriskowal:aelf.land> It it imagined that every get/set of an individual property on a shared struct is implicitly an atomic on that individual field?

yes, Unordered by default. Atomics.load/store and friends are extended to be able to operate on struct fields should you want sequentially consistent atomic access

[12:31:48.0421] <shu>
the guarantee is the same as bare reads/writes on SABs via TypedArrays: if you have races, you can observe any of the written values, but they shall never tear

[12:32:02.0773] <shu>
i.e. you can't observe half of one write composed with half of another write

[12:33:01.0239] <kriskowal>
I gather from the requirements, that it’s imagined that incrementally replacing a `class` with a `shared struct` is a delicate-but-possible performance improving refactor that doesn’t require changes from the consuming code

[12:34:04.0200] <kriskowal>
I’m much more familiar with these shenanigans in other languages. I see that CAS is `Atomics.compareExchange`. Alright.

[12:34:05.0793] <shu>
that's not a hard requirement for me, but is certainly a goal. i believe that's harder requirement for Ron perhaps

[12:34:41.0580] <shu>
i said in the beginning of the call, before you joined, that i can live in a world where we don't solve the correlation problem because on net there's still enough value here for the power apps

[12:35:04.0391] <shu>
but if we can solve the correlation problem, we unlock things like incremental adoption that helps a larger amount of apps

[12:35:09.0352] <kriskowal>
So, you’d personally be satisfied with the data-only subset?

[12:35:22.0683] <shu>
i wouldn't equate "satisfied" with "can live with"

[12:35:27.0677] <kriskowal>
Or rather, on behalf of the economic interests your represent.

[12:35:43.0008] <shu>
by "can live with" as, if it was the only thing holding the rest of the proposal up, i'd drop it

[12:35:59.0140] <shu>
and iterate on it after the initial proposal

[12:37:28.0929] <shu>
> <@kriskowal:aelf.land> Or rather, on behalf of the economic interests your represent.

speaking only for myself, yes. i still think we'd be doing a disservice for many of the reasons we've gone into with Mark in the past. the most salient of which, i think, is that without ergonomically correlated methods, we're inviting people to use free functions, and it becomes _harder_ to encapsulate

[12:37:46.0898] <shu>
which ron and i think will result in higher likelihood of thread unsafe code being written

[12:38:20.0446] <shu>
> <@kriskowal:aelf.land> Or rather, on behalf of the economic interests your represent.

 * speaking only for myself, yes. i still think we'd be doing a disservice to the language for many of the reasons we've gone into with Mark in the past. the most salient of which, i think, is that without ergonomically correlated methods, we're inviting people to use free functions, and it becomes _harder_ to encapsulate

[12:42:34.0587] <kriskowal>
So, the cursed fork has tines:
1. manual union of data and behavior (untenable because it obviates shared memory and reduces to a shared array buffer proxy membrane we can already do)
2. per-realm registry of prototypes (which requires some mitigation so such prototypes can be safely shared between compartments, maybe pure functions, freezing isn’t enough, but pure could be shared by threads)
3. dynamic scope and a per-module/evaluator hook to virtualize get-prototype-of (toward addressing compartment isolation—i think it unlikely that it does)
4. deniable global registry of token->prototype mappings (i can’t speak for Mathieu Hofman’s proposal, which might preserve sub-realm sandboxing, but i’m not convinced)

[12:43:41.0908] <shu>
what's difference between 3 and 4?

[12:44:21.0504] <kriskowal>
An outcome to avoid is order-dependence of evaluations of the same source, or a composition hazard where a system explodes if you evaluate a struct definition twice.

[12:46:27.0324] <kriskowal>
> <@shuyuguo:matrix.org> what's difference between 3 and 4?

3. Hooking get-prototype-of looks like `new Module(source, getStructPrototype(source, identifier) {maybeReturnPrototype()})`
4. Looks like `new Evaluators({ globalThis: { structRegistry: new StructRegistry() }})` and `struct Foo with structRegistry.something() {}`

[12:46:50.0859] <kriskowal>
> <@shuyuguo:matrix.org> what's difference between 3 and 4?

 * 3. Hooking get-prototype-of looks like `new Module(source, {getStructPrototype(source, identifier) {maybeReturnPrototype()}})`
4. Looks like `new Evaluators({ globalThis: { structRegistry: new StructRegistry() }})` and `struct Foo with structRegistry.something() {}`

[12:47:55.0203] <kriskowal>
In the prototype hook, the “identifier” would necessarily come from the text of the module source.

[12:48:20.0918] <shu>
given that neither of those things exist i don't really know the proposals well enough to understand

[12:48:31.0230] <shu>
 * given that neither of those things exist today i don't really know the proposals well enough to understand

[12:49:50.0827] <shu>
i just wanna do something naive and simple man

[12:49:56.0613] <kriskowal>
I think we’re unlikely to converge on either 3 or 4.

[12:51:06.0700] <shu>
can we pass a nonce to Realm (Worker?) construction that determines which registry they'll use?

[12:51:09.0048] <kriskowal>
> <@shuyuguo:matrix.org> i just wanna do something naive and simple man

shared memory concurrency

[12:51:19.0295] <kriskowal>
> <@shuyuguo:matrix.org> i just wanna do something naive and simple man

 * shared memory parallelism

[12:51:26.0508] <shu>
like script nonces, these are supposed to be generated afresh per load

[12:51:35.0936] <shu>
but you'd express constraints like, these workers are conceptually in the same package and should share the nonce

[12:51:40.0474] <shu>
and these other workers aren't

[12:52:01.0745] <shu>
and those with the same nonce have the same implicit, ambiently available registry

[12:52:11.0090] <shu>
so by default you don't get any correlation at all

[12:52:40.0676] <shu>
> <@kriskowal:aelf.land> shared memory parallelism

you telling me stores and loads are complicated? :)

[12:52:56.0394] <iain>
Yes

[12:53:15.0541] <kriskowal>
i think it goes without saying that shared structs have very narrow field of applicability. not even “all notions of worker” and certainly “not every postMessage”

[12:55:32.0177] <kriskowal>
clarifying question: is `new Worker()` consistently an OS thread or sometimes an OS process across all browsers? Do we currently have a place to stand to say “this worker must be in another process to mitigate process pipeline sidechannels”?

[12:55:36.0805] <shu>
are you inviting me to defend the motivation or...?

[12:55:37.0773] <kriskowal>
 * clarifying question: is `new Worker()` consistently an OS thread or sometimes an OS process across all browsers? Do we currently have a place to stand to say “this worker must be in another process to mitigate pipeline sidechannels”?

[12:56:20.0119] <kriskowal>
No, just clarification, I’m wondering whether this proposal implies other web changes like distinguished Worker constructor signatures.

[12:57:07.0980] <kriskowal>
Did all browsers follow V8’s lead with isolates?

[12:58:49.0406] <kriskowal>
I like that pure functions obviate the correlation and identity discontinuity problems.

[12:58:53.0026] <shu>
so while the HTML spec doesn't define threads vs processes, it follows 262's lead in "agent" and "agent cluster", with the understanding that an agent is a thread, and an agent cluster constitutes an abstract process boundary

[12:59:03.0728] <kriskowal>
And that’s a design direction you can follow from the just-data subset.

[12:59:18.0904] <shu>
i'd rather just not have it for the initial proposal then

[13:00:30.0611] <shu>
> <@kriskowal:aelf.land> No, just clarification, I’m wondering whether this proposal implies other web changes like distinguished Worker constructor signatures.

it doesn't

[13:00:41.0448] <iain>
Doing shared memory GC between threads is already scary enough; I don't think anybody would be especially interested in implementing cross-process GC between different-process worker threads.

[13:01:02.0294] <shu>
there is already the notion of "agent cluster" being the set of agents that can access shared memory, which is currently SABs

[13:01:17.0341] <kriskowal>
So, I gather it’s the case that Worker is always agent and there isn’t a mechanism for a process boundary.

[13:01:19.0400] <shu>
 * there is already the notion of "agent cluster" being the set of agents that can access the same shared memory, which is currently SABs

[13:01:30.0459] <shu>
there is the notion of an agent cluster, but it is not reified

[13:01:33.0495] <kriskowal>
 * So, I gather it’s the case that Worker is always agent [edit: agent cluster] and there isn’t a mechanism for a process boundary.

[13:01:43.0599] <shu>
no, a Worker is an agent

[13:01:51.0135] <shu>
a set of workers + the main page constitutes an agent cluster

[13:01:57.0303] <kriskowal>
 * So, I gather it’s the case that Worker is always agent and there isn’t a mechanism for a process boundary.

[13:01:58.0556] <shu>
because they are in the same cluster, they can pass SABs to each other

[13:02:20.0942] <kriskowal>
alright, so there isn’t a web API for a process boundary.

[13:02:26.0968] <shu>
correct

[13:02:37.0994] <kriskowal>
thanks, that helps my grokery

[13:02:49.0840] <shu>
the decision Chrome took was, roughly, to put each tab into its own individual process

[13:04:05.0801] <shu>
the more important process boundary is between "content" or "renderer" processes that run JS and display web content, and the "browser" process that is much more higly privileged

[13:04:26.0318] <shu>
but as far as user content goes on the web, they all run in renderer processes

[13:09:08.0362] <shu>
> <@kriskowal:aelf.land> alright, so there isn’t a web API for a process boundary.

there is no API access, but you can basically request process boundaries via https://web.dev/articles/why-coop-coep

[13:09:17.0484] <kriskowal>
there’s a very old cartoon about a company that relocates to the north pole so they can hire penguins for cheap labor. my mental model for plugin systems on the web was until this moment that you get to choose whether to endow your plugins with either timers or confine them in a worker so you get a process boundary.

[13:09:38.0198] <shu>
i think you're still misunderstanding. Workers are not a process boundary

[13:09:41.0915] <shu>
Workers are threads

[13:09:50.0738] <kriskowal>
no, i’m following you.

[13:10:09.0128] <shu>
was responding to "confine them in a worker so you get a process boundary"

[13:10:19.0361] <kriskowal>
thank you for correcting my mental landscape :-)

[13:10:39.0612] <shu>
so, since the web security model is built on same-origin

[13:10:41.0391] <kriskowal>
yeah, i’m the MBA who thought there are penguins at the north pole in this metaphor.

[13:11:25.0810] <shu>
there are these headers that let the page say "i want different origins to be isolated (read: process boundary)"

[13:11:38.0310] <kriskowal>
oh, alright, i see i was not wrong, just `new Worker` isn’t sufficient. You need a separate origin and maybe COOP COEP, which I ought to learn more about before I make a web platform.

[13:11:43.0314] <shu>
and if you serve your page with these headers, _then_ we enable shared memory

[13:12:08.0908] <kriskowal>
kk, same page.

[13:12:56.0744] <shu>
this proposal of course follows that policy, not that we have a choice :)

[13:13:07.0282] <kriskowal>
this is coherent.

[13:14:02.0553] <kriskowal>
I assume postMessage that crosses a process boundary would be in a position to throw if you attempted to share a struct.

[13:14:16.0459] <shu>
exactly right, same as for SABs

[13:14:42.0494] <rbuckton>
> <@kriskowal:aelf.land> By a glance, it looks like this design direction hasn’t been considered or was dismissed out-of-hand:
> ```
> struct Foo {}
> addEventListener('message', event => {
>   const foo = new Foo(event.data.foo);
> });
> ```
> Wherein, `Foo` is an opaque struct definition closing over the vm-specific vagaries of padding, alignment, embedding, dereferencing, &c, `event.data.foo` is an opaque handle on shared memory without behavior, and `new Foo(event.data.foo)` unites the data and behavior.

This is similar to what I do for `@esfx/struct-type`, which is more like the old "typed objects" proposal and uses objects backed by `SharedArrayBuffer`. In the end, this doesn't work unless the objects are typed as you must know the type of everything in the object graph. `new Foo(event.data.foo)` just isn't sufficient on its own.

[13:15:29.0101] <kriskowal>
Right, I assumed `new Foo` would entrain its transitive reachable struct definitions.

[13:15:57.0892] <kriskowal>
In any case, it’s moot because you have a stated position that you don’t want per-agent wrapper objects.

[13:16:21.0119] <kriskowal>
And my proposal was specifically to enable >1 wrapper object per agent.

[13:16:34.0359] <kriskowal>
Such that different compartments might have different prototypes for the same struct.

[13:17:26.0551] <kriskowal>
With that off the table, I can see the appeal of not having to solve sub-realm isolation.

[13:18:07.0096] <snek>
this is what I suggested before but it was dismissed because shared structs may be nested, so it's hard to wrap each layer

[13:18:12.0584] <shu>
let me expand on the stated position: the goal is that the order of the number of wrapper objects should either not grow with the number of threads, or grow very slowly with the number of threads

[13:18:44.0971] <shu>
per-realm prototypes of course already violates "not grow with the number of threads", but it seems okay because O(number of struct types) should be << O(number of struct instances)

[13:18:57.0008] <shu>
sub-realm prototypes is probably also fine, so long as that inequality roughly holds

[13:19:26.0202] <kriskowal>
> <@shuyuguo:matrix.org> sub-realm prototypes is probably also fine, so long as that inequality roughly holds

That’s likely.

[13:19:35.0607] <rbuckton>
> <@kriskowal:aelf.land> I gather from the requirements, that it’s imagined that incrementally replacing a `class` with a `shared struct` is a delicate-but-possible performance improving refactor that doesn’t require changes from the consuming code

delicate-but-possible sounds like an apt description. For something like TypeScript, our AST nodes are *essentially* immutable (though only enforced via design-time checking, not at runtime), so it is very feasible that we could convert our AST nodes to be shared structs, so long as we can attach behavior. That would allow us to efficiently parallelize parse and emit without the need to duplicate the entire AST in memory for each thread, while still enabling our customers to use our language service API to produce and consume these nodes.

[13:20:26.0470] <shu>
cause you buy into the pain of shared memory for two reasons, right: one is CPU time, one is to actually share memory and save memory than duplicating per-thread. so our solution can't preclude the second reason

[13:20:43.0818] <rbuckton>
In the long term, it would be better to have the nodes be *actually* immutable, but that would require either shared private fields or some operation to atomically freeze a shared struct instance.

[13:21:10.0367] <shu>
yeah, if we think of structs as "declarative sealing", we should also have "declarative freezing"

[13:21:15.0678] <shu>
though i don't want to bite off that now

[13:22:21.0426] <kriskowal>
I really like the design direction where you start with data and work your way out to thread-safe shared behavior too.

[13:22:37.0848] <kriskowal>
It would be limiting, but also enabling.

[13:22:52.0916] <kriskowal>
You wouldn’t even need to replicate the prototypes.

[13:23:02.0070] <shu>
in a different life, without this being demand-driven, i would love to agree

[13:23:45.0509] <shu>
demand-driven meaning we started from actual partners wanting more performance and expressivity out of the web platform

[13:25:32.0589] <shu>
> <@kriskowal:aelf.land> I really like the design direction where you start with data and work your way out to thread-safe shared behavior too.

i want to reiterate we _started that way_

[13:25:38.0246] <shu>
we all wanted to go that way, for the same reasons

[13:25:55.0550] <shu>
but we're here now because of experience

[13:26:17.0371] <rbuckton>
One direction I'd suggested for shared functions was to entertain the notion of a single frozen shared realm that all shared things live in, but then shared structs cannot close over or use anything in the current realm, only other shared things, but that's a lot to bite off and wasn't well received.

[13:26:18.0752] <kriskowal>
Yeah, please pardon me for replaying a great deal of history to catch up. It was my hope not to get drawn in :-)

[13:28:22.0062] <shu>
bbl, will catch up after labor day

[13:28:31.0773] <kriskowal>
Down the pure behavior road is also the possibility of JIT to shader.

[13:28:51.0476] <rbuckton>
Data-only shared structs would be fine for green field projects, but for something like TypeScript we'd essentially need to create a wrapper/proxy layer over a shared AST that we would have to rehydrate in every thread, which eats up all of the memory/performance gains you would hope to gain.

[13:29:19.0044] <iain>
Without making the claim that this is actually taking place: in the abstract, I think it would be unfortunate if we locked in a suboptimal design for shared behaviour out of an urge to have something that we can ship sooner. Specifically: if we think we could eventually work out a design for thread-safe shared behaviour, and it would be more performant than the current thread-local prototype approach, then it would be better not to lock ourselves into a local maximum.

[13:29:21.0308] <kriskowal>
But I digress, it seems that the remaining options both involve more elaborate mitigations for sub-realm confinement and I’ll have to be here to evaluate those options.

[13:29:59.0542] <kriskowal>
 * But I digress, it seems that the remaining options both involve more elaborate mitigations for sub-realm confinement and I’ll have to be here to help evaluate those options.

