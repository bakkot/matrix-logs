2023-09-06
[13:43:26.0749] <rbuckton>
shu: Are the origin trial shared structs not allowed to have fields that are stringified integers?

[14:25:56.0386] <shu>
rbuckton: it should, that looks like a bug

[14:26:01.0355] <shu>
i'll investigate soon, thanks for raising it

[15:32:40.0914] <rbuckton>
The more I tinker with this, trying to shoehorn it into the compiler, the more I want some mechanism to attach behavior.
I also had to implement a custom `Map`-like mechanism using shared structs to share some keyed data efficiently. 

[15:33:20.0290] <rbuckton>
I have made some progress on parallel parsing, however. 

[15:44:56.0565] <shu>
i am working on the behavior thing

[15:45:10.0955] <shu>
more specifically, the thread-local storage thing

[15:45:46.0842] <shu>
our current GC scheme makes inter-heap cycles uncollectable, and i'm trying to fix that, which is taking a bit due to GC being finnicky


2023-09-08
[16:48:21.0705] <rbuckton>
shu: are you aware of any issues debugging workers when - - harmony-structs or the Shared string table flag are enabled? I'm running issues debugging in VS Code and wanted to check if there were any known issues before I file an issue with VS Code. 

[16:50:12.0414] <rbuckton>
I'm not sure if it's Code, the chrome debug protocol, NodeJS, or V8 causing the issue, but the first breakpoint I hit after starting a worker and passing it a shared struct results in the debugger locking up. 

[16:57:14.0828] <rbuckton>
I finally reached a point where I can successfully parse a large project (xstate) using parallel parsing and the results aren't very promising yet. On a single thread, parse takes about 1.2s on my machine, and about 3.5s when running in parallel. However this is still very early and I'm having to copy the entire AST of each file from the struct representation into a normal JS object so it can be used by our existing checker and emitter. The limitations of structs mean we can't just use them as-is without a significant rewrite. 


2023-09-09
[17:06:01.0751] <shu>
rbuckton: re: VSCode debugging, i don't know but i wouldn't be surprised if devtools just doesn't work because nobody has looked at it. printf debugging is what we do unfortunately, devtools investment is unlikely to materialize without something like getting to stage 3 first

[17:06:17.0834] <shu>
yeah, copying into normal objects sounds like it would kill performance indeed

[17:06:31.0900] <shu>
what are the limitations? attaching behavior and that ownProperty bug?

[17:06:52.0555] <shu>
(please file issues for the limitations getting in your way in addition to the attaching behaviors thing)

[17:27:38.0514] <rbuckton>
> <@shuyuguo:matrix.org> what are the limitations? attaching behavior and that ownProperty bug?

If I limit this to just the command line compiler, the biggest issue is that I can't emulate our internal `NodeArray` with a `SharedArray`. A `NodeArray` is just an `Array` with a few extra properties attached, but that causes several issues:
- Can't define extra fields on `SharedArray`
- Alternatively, can't define numeric indexed properties on a regular struct.
- SharedArray is not iterable and you can't make a regular struct iterable, so I have to rewrite every `for..of` and array method call to work around. 

[17:27:53.0931] <rbuckton>
* In reply to @shuyuguo:matrix.org
what are the limitations? attaching behavior and that ownProperty bug?


If I limit this to just the command line compiler, the biggest issue is that I can't emulate our internal NodeArray with a SharedArray. A NodeArray is just an Array with a few extra properties attached, but that causes several issues:

Can't define extra fields on SharedArray

Alternatively, can't define numeric indexed properties on a regular struct.

SharedArray is not iterable and you can't make a regular struct iterable, so I have to rewrite every for..of and array method call to work around.


[17:28:20.0192] <rbuckton>
* In reply to shu
what are the limitations? attaching behavior and that ownProperty bug?


In reply to @shuyuguo:matrix.org
what are the limitations? attaching behavior and that ownProperty bug?

If I limit this to just the command line compiler, the biggest issue is that I can't emulate our internal NodeArray with a SharedArray. A NodeArray is just an Array with a few extra properties attached, but that causes several issues:
- Can't define extra fields on SharedArray

- Alternatively, can't define numeric indexed properties on a regular struct.

- SharedArray is not iterable and you can't make a regular struct iterable, so I have to rewrite every for..of and array method call to work around.


[17:28:32.0877] <rbuckton>
* In reply to shu
what are the limitations? attaching behavior and that ownProperty bug?


In reply to shu
what are the limitations? attaching behavior and that ownProperty bug?

In reply to @shuyuguo:matrix.org
what are the limitations? attaching behavior and that ownProperty bug?
If I limit this to just the command line compiler, the biggest issue is that I can't emulate our internal NodeArray with a SharedArray. A NodeArray is just an Array with a few extra properties attached, but that causes several issues:

Can't define extra fields on SharedArray

Alternatively, can't define numeric indexed properties on a regular struct.

SharedArray is not iterable and you can't make a regular struct iterable, so I have to rewrite every for..of and array method call to work around.


[17:30:00.0937] <rbuckton>
We also use data structures like `Map` that we can't emulate due to the inability to attach behavior, so there's a lot of copying in and out of data structures we can use. 

[17:33:14.0207] <rbuckton>
If I wanted to extend these structs to the language service, we're in the realm of needing behavior and the ability to freeze or lock down specific properties. Our AST is mostly treated as immutable, but if we were to vend struct based nodes from our API they would become unsafe to use if a consumer could make changes to properties outside of a lock. 

[17:37:52.0976] <rbuckton>
For now I've worked around a few other issues. I add a `__tag__` field to structs I create when type identity is important, as well as a field containing a pseudo- identity hash so I can use some structs as keys in a shared hashmap implementation I wrote (in place of Map where needed). 

[17:40:39.0203] <rbuckton>
I'm using classes and decorators to fake syntax to better work with the type system, like in the example above. The decorators just collect field names and create a SharedStructType attached to the class, behavior is just defined as static methods. 

[17:43:41.0680] <rbuckton>
I'm also experimenting with a `Mutex` wrapper that let's me write code like this:

```ts
{
  using lck = new UniqueLock(mutex);
  ...
}
```

Though the mutex wrapper is slower than `Atomics.Mutex`.

[18:11:10.0329] <rbuckton>
> <@rbuckton:matrix.org> In reply to shu
> what are the limitations? attaching behavior and that ownProperty bug?
> 
> 
> In reply to shu
> what are the limitations? attaching behavior and that ownProperty bug?
> 
> In reply to @shuyuguo:matrix.org
> what are the limitations? attaching behavior and that ownProperty bug?
> If I limit this to just the command line compiler, the biggest issue is that I can't emulate our internal NodeArray with a SharedArray. A NodeArray is just an Array with a few extra properties attached, but that causes several issues:
> 
> Can't define extra fields on SharedArray
> 
> Alternatively, can't define numeric indexed properties on a regular struct.
> 
> SharedArray is not iterable and you can't make a regular struct iterable, so I have to rewrite every for..of and array method call to work around.

This ended up horribly formatted due to trying to edit the message on my phone :/

[18:11:26.0750] <rbuckton>
> <@shuyuguo:matrix.org> what are the limitations? attaching behavior and that ownProperty bug?

 * If I limit this to just the command line compiler, the biggest issue is that I can't emulate our internal NodeArray with a SharedArray. A NodeArray is just an Array with a few extra properties attached, but that causes several issues:

- Can't define extra fields on SharedArray

- Alternatively, can't define numeric indexed properties on a regular struct.

- SharedArray is not iterable and you can't make a regular struct iterable, so I have to rewrite every for..of and array method call to work around.


2023-09-11
[13:54:53.0035] <shu>
rbuckton: we should figure out how to get builds of node with tip-of-tree V8. your indexed property woes seems to have been long fixed, but the V8 version that your version of node uses hasn't picked it up

[13:55:16.0170] <shu>
```
~/v8/v8 $ out/x64.debug/d8 --harmony-struct ./test-shared-struct-elements-own-prop.js 
V8 is running with experimental features enabled. Stability and security will suffer.
0,1
{"writable":true,"enumerable":true,"configurable":false}

~/v8/v8 $ cat ./test-shared-struct-elements-own-prop.js 
var t = new SharedStructType(["0", "1"]);
var s = new t();
print(Object.keys(s));
print(JSON.stringify(Object.getOwnPropertyDescriptor(s, "0")));
```

[16:32:36.0304] <rbuckton>
I'll have to take some time next week to spin up a NodeJS build environment


2023-09-12
[09:13:28.0069] <Mathieu Hofman>
I've used https://nodejs.org/download/v8-canary/ successfully before

[09:14:35.0250] <Mathieu Hofman>
Built from https://github.com/nodejs/node-v8

[13:29:19.0844] <rbuckton>
> <@mhofman:matrix.org> Built from https://github.com/nodejs/node-v8

Thanks! This works perfectly

[13:32:42.0538] <rbuckton>
`instanceof` for Mutex/Condition/SharedArray is great. I see that it works for instances of instances of `SharedStructType` as well, though there's still no fast way to see if a value is *any* shared struct (i.e., without access to its specific constructor)

[13:33:47.0149] <shu>
rbuckton: there is, i also added `SharedStructType.isSharedStruct` iirc

[13:35:52.0909] <rbuckton>
Ah, great

[13:41:14.0625] <rbuckton>
Hmm. I was hoping I could use `SharedStructType` to emulate `SharedArray` when I also need extra fields, but its significantly slower so that's a no-go.

[13:44:18.0721] <shu>
yes -- that's a possible optimization that's not implemented due to complexity/effort

[13:44:37.0995] <shu>
if you use indexed fields in SharedStructTypes, those are _always_ backed by "dictionary elements", i.e. a hash table

[13:44:41.0700] <shu>
SharedArrays are contiguous arrays

[13:45:09.0605] <shu>
we can optimize SharedStructTypes to use fast elements when those indexes are all packed, or something

[13:45:22.0754] <shu>
i could put it on the queue if it's a blocker

[13:47:08.0594] <Ashley Claymore>
> <@rbuckton:matrix.org> Hmm. I was hoping I could use `SharedStructType` to emulate `SharedArray` when I also need extra fields, but its significantly slower so that's a no-go.

Could the N extra fields be hidden at the start of the sharedarray? Their names map to fixed indexes 0,1,2 etc, and all array looping logic knows to start index at N? Or too big a refactor?

[13:48:54.0852] <rbuckton>
Thats just as much of a refactor as what I was doing, which was stashing a SharedArray in an `items` field in another struct. The biggest issue with that approach is that every function that expected a `NodeArray` with indexable elements has to check if it's instead a `SharedNodeArray` to use its `items` field.

[13:49:22.0691] <shu>
rbuckton: what's the full list of field names you'd like to be fast?

[13:49:29.0585] <shu>
might not be too bad, i'll see if i have time next week

[13:55:33.0222] <rbuckton>
I'm not sure how to answer that. What's "slow" is that I'm trying to emulate a `SharedArray` with fields named `"length"`, `"0"`, `"1"`, etc. as well as attach a few extra fields that we normally stash on a `NodeArray`, which looks something like this:

```ts
interface NodeArray<T extends Node> extends Array<T> {
  pos: number;
  end: number;
  hasTrailingComma: boolean;
  transformFlags: TransformFlags; // number
}
```
If you're asking about other fields, the most frequently hit fields on our AST are `pos`, `end`, `kind`, `id`, `transformFlags`, and `parent`:

```ts
interface Node {
  pos: number;
  end: number;
  kind: SyntaxKind; // number
  transformFlags: TransformFlags; // number
  id: number | undefined;
  parent: Node | undefined;
}
```

[13:59:06.0786] <shu>
ah i see

[13:59:29.0420] <shu>
is the length of these nodes known AOT per Node?

[13:59:42.0062] <shu>
(and are contiguous?)

[14:07:39.0068] <rbuckton>
Can you clarify what you mean by contiguous?

[14:09:41.0068] <rbuckton>
I've essentially mirrored our AST structure into shared struct definitions, so I could tell you exactly how many fields are attached to a given node, though I'd need a bit if you want something like the average field count.

[14:13:42.0627] <shu>
by contiguous i mean if a node type's length is N, then the node always has indexed properties 0 to N-1, inclusive, with no holes

[14:13:52.0378] <shu>
hole in the usual JS sense

[14:14:26.0808] <shu>
and no, not looking for an average field count

[14:14:42.0845] <shu>
by AOT i mean is the length fixed per node _type_ instead of per node _instance_

[14:14:52.0565] <shu>
since all shared arrays are fixed length

[14:14:59.0053] <rbuckton>
A `Node`? No. A `NodeArray`, yes. There are no holes in `NodeArray`s, though they could be filled with different kinds of `Node` subtypes.

[14:15:45.0316] <shu>
oh, my bad, i think i misread

[14:15:54.0561] <shu>
you're not saying you want Nodes to have some elements in addition to some properties

[14:16:17.0820] <shu>
you're saying you're trying to convert NodeArrays, which are arrays + some string-named properties that you listed above

[14:16:50.0246] <shu>
that points to another direction, which is...

[14:17:44.0991] <shu>
perhaps the dev trial should unify the notions of SharedStructType and SharedArray and just let SharedStructTypes specify "i want N indexed properties"

[14:17:54.0769] <shu>
but even then a SharedArray constructor is probably helpful

[14:18:06.0952] <shu>
in any case i hear the feedback now and i'll push it on the queue

[14:21:18.0770] <rbuckton>
Yes. I have two choices for a shared struct implementation of a `NodeArray`:

1. I use a Shared Struct with a small set of string-named fields (like `pos`/`end`), as well a `length` and a number of indexed fields with no holes. This would emulate `NodeArray` except for functionality from array prototype as I can just use `length` and indices instead. This provides enough overlap between `NodeArray` and `SharedNodeArray` that I don't need to special case every single function that works with `NodeArray`.

2. I use a Shared Struct with the same set of string-named fields as well as an `items` field that holds a `SharedArray`. In this case, I need to add branching cases in every function that works with `NodeArray`.

[14:23:03.0624] <shu>
i try to allow (1) to be more easily expressed and be faster

[14:23:10.0251] <rbuckton>
Another option would be the ability to add extra fields to a `SharedArray`, such that integer indexed properties go through the current fast path for `SharedArray` and other string properties go the slow path.

[14:23:10.0888] <shu>
 * i'll try to allow (1) to be more easily expressed and be faster

[14:23:40.0379] <rbuckton>
Though I assume that could be handled by unification as you suggested above.

[14:23:57.0693] <shu>
something like `SharedStructType(fields, { alsoGiveMeElementsUpTo: N })` or whatever

[14:25:32.0934] <rbuckton>
Yeah, or the `SharedStructType` constructor could just test `fields` for interger-indexed field names that start from `0` and go to `N` with no holes, and optimize those (unless you need to optimize `length` as well.

[14:25:42.0727] <rbuckton>
 * Yeah, or the `SharedStructType` constructor could just test `fields` for interger-indexed field names that start from `0` and go to `N` with no holes, and optimize those (unless you need to optimize `length` as well).

[14:26:23.0812] <rbuckton>
For the purposes of the trial, I don't necessarily need convenience, I just need capability. I can work around inconveniences if the capabilities are there.

[14:48:24.0575] <rbuckton>
Quick update on the parallel parsing front, after tinkering with how I batch source files to send to background threads, I went from parse time being 6x slower than single threaded, to only 1.5x slower.

[14:49:02.0433] <shu>
ah interesting, would love to dig in at some point, should be faster after all :)

[14:56:17.0112] <rbuckton>
TypeScript normally does a depth-first parse of source files: for each root file, we parse the file, collect its imports and `/// <reference>` directives, and then parse those files. The order in which we parse files affects signature overload resolution when we merge types for global scope and module augmentations. Depth first isn't very efficient for parallelization though, so I'm having to rewrite it to be breadth-first instead, which will (of course) affect overload resolution. I was trying a batching approach to minimize that affect, but it wasn't successful. In the end I'm probably just going to "fix it in post" and reorder the file list based on what we *would* have generated prior to batching.

[15:04:52.0147] <Ashley Claymore>
Curious, Is some of the remaining slowdown coming from under utilization, threads waiting for work to do, or are they fully saturated but there is additional overhead with the sharing? (Very excited by all this, we've also been looking at running TS in parallel and the parsing was showing as a bottleneck due to cache misses. A cross thread cache could be a big win)

[15:06:23.0701] <rbuckton>
I don't have enough information on that to say, yet. I think some of the inefficiencies are due to workarounds and needing to convert the struct representation to a normal `Node` representation.

[15:07:30.0820] <rbuckton>
I'm currently working on abstracting away the differences between a `Node` and a `SharedNode` so that I can just use shared structs end to end in the command line compiler, which would at least do away with the conversion step.

[15:09:14.0175] <rbuckton>
Once that works, I can look into whether its feasible to bind in parallel and possibly even emit in parallel. Unfortunately our emitter often queries information from the checker, which we probably won't be able to parallelize currently.

[15:10:19.0206] <rbuckton>
And I'm not sure how efficient synchronizing on the checker and calling into it from other threads will be.

[15:14:28.0427] <rbuckton>
> <@shuyuguo:matrix.org> if you use indexed fields in SharedStructTypes, those are _always_ backed by "dictionary elements", i.e. a hash table

Are you saying all property access against a shared struct (not a shared array) in the origin trial uses hash table lookup/slow mode?

[15:15:49.0413] <shu>
> <@rbuckton:matrix.org> Are you saying all property access against a shared struct (not a shared array) in the origin trial uses hash table lookup/slow mode?

No, just the integer-indexed properties on shared structs

[15:15:53.0364] <shu>
string-named properties are fast

[15:15:56.0920] <rbuckton>
Ah, ok

[15:16:06.0642] <shu>
it's a pecularity of how elements (indexed properties) are stored on JSObjects


2023-09-17
[10:06:04.0059] <rbuckton>
I'm still tinkering with my parallel parse prototype, and I'm planning to try it on a few large scale projects. I'm not currently seeing the perf-gains I would hope, but its too early to say if its an issue with the shared structs functionality, the size of the projects I've been using for testing, or something about how I've had to hack around parts of the compiler to get something functional.
I wrote a rudimentary work-stealing thread pooling mechanism, but I'm finding that adding more threads slows down parse rather than speeding it up for the monorepo I've been using as a test case. CPU profiling shows a lot of the threads aren't processing work efficiently, and are either spinning around trying to steal work or are waiting to be notified of work. Spinning isn't very efficient because there's no spin-wait mechanism nor the ability to write an efficient one (I can sort-of approximate one using `Condition.wait` with a short timeout to emulate `sleep`, but I can't efficiently yield). I also can't write efficient lock-free algorithms with shared structs alone, since I can't do CAS, so the fastest "lock-free"-ish updates I can perform are inside of a `Mutex.tryLock` unless I want to fall back to also sending a `SharedArrayBuffer` to the worker just so I can use `Atomics.compareExchange`.

Here's a rough approximation of the thread pool I'm using right now, if anyone has suggestions or feedback: https://gist.github.com/rbuckton/3648f878595ed4e2ff3d52a15baaf6b9

[10:08:56.0043] <rbuckton>
Ah, wait. I just noticed I can do compareExchange with `SharedArray`. That's good.

[10:09:58.0980] <rbuckton>
 * Ah, wait. I just noticed I can do `compareExchange` with `SharedArray` and shared structs. That's wonderful!

[11:03:44.0827] <rbuckton>
I've updated my gist slightly to perform atomic updates on the task counter, probably a few more updates later.

[16:05:52.0086] <shu>
>  I also can't write efficient lock-free algorithms with shared structs alone, since I can't do CAS, so the fastest "lock-free"-ish updates I can perform are inside of a Mutex.tryLock unless I want to fall back to also sending a SharedArrayBuffer to the worker just so I can use Atomics.compareExchange.

why can't you CAS shared structs?

[16:05:58.0600] <shu>
`Atomics.compareExchange` works with shared struct fields!

[16:06:08.0058] <shu>
oh, i should've kept reading, you noticed it


2023-09-18
[03:49:48.0663] <Ashley Claymore>
> <@rbuckton:matrix.org> I'm still tinkering with my parallel parse prototype, and I'm planning to try it on a few large scale projects. I'm not currently seeing the perf-gains I would hope, but its too early to say if its an issue with the shared structs functionality, the size of the projects I've been using for testing, or something about how I've had to hack around parts of the compiler to get something functional.
> I wrote a rudimentary work-stealing thread pooling mechanism, but I'm finding that adding more threads slows down parse rather than speeding it up for the monorepo I've been using as a test case. CPU profiling shows a lot of the threads aren't processing work efficiently, and are either spinning around trying to steal work or are waiting to be notified of work. Spinning isn't very efficient because there's no spin-wait mechanism nor the ability to write an efficient one (I can sort-of approximate one using `Condition.wait` with a short timeout to emulate `sleep`, but I can't efficiently yield). I also can't write efficient lock-free algorithms with shared structs alone, since I can't do CAS, so the fastest "lock-free"-ish updates I can perform are inside of a `Mutex.tryLock` unless I want to fall back to also sending a `SharedArrayBuffer` to the worker just so I can use `Atomics.compareExchange`.
> 
> Here's a rough approximation of the thread pool I'm using right now, if anyone has suggestions or feedback: https://gist.github.com/rbuckton/3648f878595ed4e2ff3d52a15baaf6b9

Looks good to me. Have you experimented with batch sizes? Each task being N files, rather than 1:1 task file ratio?

[03:50:56.0958] <Ashley Claymore>
Also wondering how much the tasks are known up front (one main glob) vs discovered as imports are found. I.e how well the queue can stay pumped?

[03:56:26.0704] <rbuckton>
Tasks are 1:1 per file. With work stealing, batching would be less efficient since you could have threads sitting idle. 

[03:58:48.0425] <rbuckton>
How much is known upfront depends on the tsconfig `files`, `include`, and `exclude` options, though I'm using a striping approach to try to collect all imports/references for each pass around the file list. 

[03:59:59.0871] <rbuckton>
I need to experiment with a few more projects of different sizes though, it's still fairly early yet. 

[04:02:33.0531] <rbuckton>
The current approach is still very waterfall like in the main thread. I would need to do a lot more work to have the child threads scan for imports/references so they don't have to constantly wait for the main thread to hand out more work. 

[04:04:06.0959] <rbuckton>
Unfortunately, program.ts is very callback heavy and dependent on caches that would *also* need to be shared. 

[04:05:02.0798] <rbuckton>
There's a lot of idle time waiting for main right now

[04:08:04.0489] <rbuckton>
I currently have a synchronized, shareable `Map`-like data structure I can use for that, but I may want to see if I can build a lock-free, concurrent Map first so there's less blocking involved

[05:26:52.0862] <Ashley Claymore>
> <@rbuckton:matrix.org> Tasks are 1:1 per file. With work stealing, batching would be less efficient since you could have threads sitting idle.

true tho that assumes the queuing system is zero-cost (no padding around tasks). So might work out that some batching, while theoretically less efficient at packing, leads to better results.
Just an idea :) 

[05:28:16.0925] <Ashley Claymore>
In an ideal world parsing the largest files first would also be ideal for work stealing, though finding the largest files may be more costly than that saves too

[06:09:07.0471] <Jack Works>
is there slides of update?

[06:09:41.0521] <Jack Works>
I'm excited about the progress you've made and want to know more details! I can't wait!

[07:43:35.0324] <shu>
Jack Works: there are in fact no slides yet :(

[07:43:39.0239] <shu>
got so much to do this week

[07:44:18.0193] <shu>
rbuckton: i wonder if also web workers sucking somehow is getting in the way of your performance? this is node though so who knows, might be unrelated to web workers even if its worker implementation were less than ideal

[09:03:27.0413] <rbuckton>
> <@aclaymore:matrix.org> true tho that assumes the queuing system is zero-cost (no padding around tasks). So might work out that some batching, while theoretically less efficient at packing, leads to better results.
> Just an idea :)

You are possibly correct, though that is a level of fine tuning I'm not anywhere near investigating yet.

[09:04:49.0981] <rbuckton>
> <@shuyuguo:matrix.org> rbuckton: i wonder if also web workers sucking somehow is getting in the way of your performance? this is node though so who knows, might be unrelated to web workers even if its worker implementation were less than ideal

Are you imagining there is overhead to reading/writing from shared structs or using mutex/condition caused by the worker? Or are you talking about overhead due as a result of setup, postMessage, etc.?

[10:08:35.0457] <rbuckton>
I've updated the thread pool example to use a lock free Chase-Lev deque, though it still uses a Mutex/Condition to put the thread to sleep when there's no work to do.

[10:26:00.0758] <rbuckton>
It's still somewhat inefficient if a thread ends up sleeping and a task is added to a queue for a different thread that is still active.

[12:16:05.0145] <Mathieu Hofman>
Reading all this, I am still curious to understand how Shared Struct help compared to a synchronization mechanism (to implement a thread pool) coupled with an efficient message passing. How much actual shared mutable state is necessary?

[12:51:48.0726] <rbuckton>
What would you consider to be "efficient message passing"? 

[12:53:13.0519] <rbuckton>
The lion's share of what TypeScript would send back and forth for parallel parse is essentially immutable, but a lot of the smaller data structures I need just to do coordination require shared mutable state.

[12:55:07.0476] <rbuckton>
If I wanted to write my own `malloc`/`free` over a growable `SharedArrayBuffer` as a heap, I could mostly do the same things as what we can do with Shared Structs, albeit *far* slower due to the need for wrappers and indirection, plus I would have to handle string encoding/decoding on my own and could never shrink the size heap. Shared structs are far more efficient in this regard.

[12:58:30.0453] <rbuckton>
And when I say "could mostly do the same things", I mean "have done something very similar" with https://esfx.js.org/esfx/api/struct-type.html, with the downside that it requires fixed sized types for fields and everything is laid out flat within a `SharedArrayBuffer`.

[12:59:05.0587] <rbuckton>
(and it doesn't support arbitrary string values)

[13:29:17.0123] <shu>
> <@rbuckton:matrix.org> Are you imagining there is overhead to reading/writing from shared structs or using mutex/condition caused by the worker? Or are you talking about overhead due as a result of setup, postMessage, etc.?

i was thinking the latter, and scheduling

[13:30:42.0491] <shu>
> <@mhofman:matrix.org> Reading all this, I am still curious to understand how Shared Struct help compared to a synchronization mechanism (to implement a thread pool) coupled with an efficient message passing. How much actual shared mutable state is necessary?

my thinking has always been single-writer XOR multiple-reader kind of data sharing will get you pretty far

[13:30:52.0224] <Mathieu Hofman>
I guess I'm wondering how these small data structures for synchronization are used, how much they need to do, and if there's any way to abstract them into higher level concepts. The immutable data could be passed as messages, and does not need to be based on shared struct from what I gather. I am basically still worried we're designing a blunt tool that will be abused when alternatives would be more aligned with the JS ecosystem.

[13:31:08.0391] <shu>
but if your application wants mutable shared state there is no alternative

[13:32:16.0992] <shu>
i continue to strongly disagree with this handwringing about abuse

[13:43:59.0607] <shu>
but i think we remain agreed that shared mutable state is a bad thing to entice people into reaching for from the get go

[14:00:37.0075] <rbuckton>
> <@shuyuguo:matrix.org> i was thinking the latter, and scheduling

For TypeScript, I'm not using postMessage at all except for the built-in one NodeJS does to pass the initial value of `workerData`, so that wouldn't be the cause. 

[14:04:47.0007] <rbuckton>
> <@mhofman:matrix.org> I guess I'm wondering how these small data structures for synchronization are used, how much they need to do, and if there's any way to abstract them into higher level concepts. The immutable data could be passed as messages, and does not need to be based on shared struct from what I gather. I am basically still worried we're designing a blunt tool that will be abused when alternatives would be more aligned with the JS ecosystem.

The problem is that concurrency and coordination often requires far more complex coordination primitives than we are likely to ship in the standard library. With the implementation in the origin trial, I can easily build these more complex coordination capabilities out of the primitives we have through the use of mutable shared state. If we are limited to only a few built-in mutable and shareable data structures and everything else is immutable, then it is possible this proposal won't meet the needs of the applications that need this capability the most.

[14:05:56.0119] <rbuckton>
That's not saying we shouldn't *also* have immutable data structures, or at least the ability to freeze all or part of a shared struct, as I'd like those too.

[14:06:20.0693] <shu>
rbuckton: yeah that all tracks exactly with my intuition

[14:06:51.0107] <rbuckton>
Even though I would consider most of the TypeScript AST to be immutable, that's not exactly true. It's immutable to our consumers, but we need to be able to attach additional shared data ourselves.

[14:08:05.0886] <rbuckton>
for example, I may build a `SourceFile` and its AST in parallel parse, but this file hasn't been bound and had its symbols and exports recorded yet. Once parse is complete, we hand the entire program off to the binder which could also do its work in parallel.

[14:08:56.0380] <shu>
in the back of my mind i'm still thinking about the viability of dynamic "ownership" tracking, for lack of a better word. by "ownership" i mean single writer XOR multiple readers

[14:09:38.0717] <rbuckton>
And while our emitter uses tree transformations that produce a new AST for changed subtrees, we still reuse unchanged subtrees as much as possible, and need to attach additional information about how those original nodes should be handled during emit as well. 

[14:10:47.0816] <rbuckton>
Weak Maps and thread-local state don't help there as I may want to parallelize emit and transformation for subtrees as well, which means handing parts of the tree off to other threads.

[14:12:38.0988] <rbuckton>
> <@shuyuguo:matrix.org> in the back of my mind i'm still thinking about the viability of dynamic "ownership" tracking, for lack of a better word. by "ownership" i mean single writer XOR multiple readers

On a per-instance level, or something less fine grained? In my TypeScript experiment I wrote a `SharedMutex` that supports single writer (exclusive) locks and multiple reader (shared) locks on top of the ones you provide on `Atomic`.

[14:12:49.0162] <rbuckton>
> <@shuyuguo:matrix.org> in the back of my mind i'm still thinking about the viability of dynamic "ownership" tracking, for lack of a better word. by "ownership" i mean single writer XOR multiple readers

 * On a per-instance level, or something less fine grained? In my TypeScript experiment I wrote a `SharedMutex` that supports single writer (exclusive) locks and multiple reader (shared) locks on top of the ones you provide on `Atomics`.

[14:14:25.0811] <shu>
rbuckton: on a per-instance level

[14:14:57.0728] <rbuckton>
That sounds potentially expensive?

[14:14:59.0948] <shu>
not to provide ordering, or blocking until reading is available, but to e.g. throw, or provide query APIs for whether it's currently safe to read

[14:15:04.0084] <shu>
indeed, that's why i've punted on it

[14:15:44.0707] <shu>
there is a 2-bit lock-free scheme, but that still means an additional load and branch on every access, and then an additional CAS on state changes

[14:16:16.0413] <shu>
2 bits are needed to transition the state between "unused", "being read", and "being written to"

[14:16:32.0088] <rbuckton>
My intuition is that if you're writing JS code that really needs multiple threads of execution, then you want things to be as lean as possible with explicit opt-ins to anything slower or more complex.

[14:16:50.0607] <shu>
that is my intuition as well for shared structs

[14:17:20.0918] <shu>
to be clear i'm thinking of these in the context of additions after the building blocks are there, to encourage a happy path that is a little less performant but a little more safe

[14:17:38.0263] <shu>
but this is probably still too fine-grained to make the safety tradeoff worth it

[14:18:42.0690] <rbuckton>
Was this related to the idea of snapshotting an object for mutation, and then applying the update atomically?

[14:19:53.0860] <rbuckton>
the RCU approach?

[14:20:05.0942] <shu>
yep, in that vicinity for sure

[14:22:59.0161] <rbuckton>
A few years ago there was discussion about the "monocle-mustache" operator, and I wondered if it could be used for this, i.e.:

```
let copy = obj.{ x, y };
copy.x++;
copy.y--;
obj.{ x, y } = copy;
```


[14:23:49.0283] <shu>
oh interesting

[14:23:59.0634] <shu>
and you're thinking of things between the { } as comprising a transaction?

[14:24:59.0815] <rbuckton>
i.e., normal JS objects could use it as a pick-operator for read, and like `Object.assign` for write, but shared structs could return a mutable snapshot that provides an atomic read of the requested values, and could perform an atomic write at the bottom.

[14:25:40.0211] <shu>
cool idea though a little magical feeling

[14:25:48.0820] <shu>
rbuckton: oh btw i wanted to poll your opinion before i made slides for the next meeting...

[14:26:15.0350] <rbuckton>
`.{` isn't new to most of the committee though, it's been discussed on and off for almost 9 years now, iirc.

[14:26:25.0355] <rbuckton>
just never formally presented.

[14:26:27.0044] <shu>
since the current prototyping effort is to do agent-local/realm-local (i'd like to discuss the granularity during the meeting) fields, how do you think that should look in syntax?

[14:26:39.0485] <shu>
we have precedent in auto accessors as having modifiers to fields

[14:26:53.0508] <shu>
i was thinking like `agentlocal fieldName;` or something

[14:28:08.0330] <rbuckton>
https://github.com/rtm/js-pick-notation for the pick notation, and I think there was some discussion in https://github.com/rbuckton/proposal-shorthand-improvements as well

[14:30:37.0915] <rbuckton>
> <@shuyuguo:matrix.org> i was thinking like `agentlocal fieldName;` or something

It's not terrible, I suppose? In other contexts/languages I might call it `threadlocal`, but another option might be `nonshared`? Especially if the struct syntax is something like `struct Foo {}` and `shared struct Bar {}`, declaring something as `nonshared` seems semantically consistent without needing to bring in terms like "agent"

[14:31:15.0063] <shu>
yes, i don't love the name agent

[14:31:51.0633] <shu>
i kinda like `nonshared`, though i wonder if it glosses over the per-thread/per-realm view aspect of the semantics

[14:32:29.0767] <shu>
actually, the bigger possibility for confusion is that the modifier applies values, not the field itself

[14:32:34.0040] <shu>
kind of like the `const` confusion

[14:32:47.0665] <rbuckton>
We don't say "agent" in any of the Atomics APIs, despite those APIs having to do with memory ordering to support atomic writes across agents, so I don't think its that bad to avoid the terminology.

[14:32:58.0454] <shu>
OTOH we already have that confusion, and the use of `nonshared` is consistent with how `const` modifies the binding

[14:33:19.0621] <shu>
or maybe just `local`

[14:33:23.0357] <shu>
though that's pretty vague

[14:33:50.0655] <rbuckton>
```
shared struct Data {
  x;
  y;
  nonshared foo;

  // would methods need this keyword too, or automatically be considered nonshared?
  method() { }

  nonshared method2() {}
}
```

[14:34:19.0244] <rbuckton>
`local` feels vague and has a different context in some other languages

[14:34:46.0564] <rbuckton>
i.e., in some languages, `local` refers to how you access shadowed variable bindings

[14:35:25.0993] <shu>
method declarations are currently just disallowed

[14:35:47.0996] <shu>
i don't know what it means to have that in a shared struct, without bringing in ideas we've talked about in the past like packaging it up as a module block that gets re-evaluated

[14:36:31.0991] <rbuckton>
> <@shuyuguo:matrix.org> method declarations are currently just disallowed

Yes, but I'm imagining syntax based on what I hope we can get in the end, including an easy Developer experience for the prototype handshake for attaching behavior, as in the Gist I shared several weeks ago.

[14:37:13.0326] <rbuckton>
I'm referring to this: ```
shared struct Point

[14:37:33.0049] <rbuckton>
 * I'm referring to this: https://gist.github.com/rbuckton/08d020fc80da308ad3a1991384d4ff62

[14:37:50.0505] <shu>
> <@rbuckton:matrix.org> Yes, but I'm imagining syntax based on what I hope we can get in the end, including an easy Developer experience for the prototype handshake for attaching behavior, as in the Gist I shared several weeks ago.

then in that future i favor requiring `nonshared method() {}` and making `method() {}` a parse error, to make the semantics explicit

[14:38:21.0135] <shu>
also, just in case by divine inspiration we manage to actually share functions in the future, somehow

[14:39:58.0911] <rbuckton>
essentially, the syntax covers multiple things:
- Declaring the fields that are shared (with a convenient place to hang type annotations off of)
- Declaring the fields that are not shared (specific to the current thread/agent/whatnot)
- Declaring the construction logic that is not shared (specific to the current thread/etc.)
- Declaring the instance methods that are not shared (specific to the current thread/etc.)
- Declaring the static methods on the non-shared constructor.

[14:40:47.0695] <shu>
i plan to reference that doc in the update sildes

[14:40:52.0969] <shu>
 * i plan to reference that doc in the update slides

[14:41:14.0084] <rbuckton>
so, would you be suggesting it be this:

```
shared struct Foo {
  x;
  y;
  
  nonshared constructor(x, y) {
    this.x = x;
    this.y = y;
  }

  nonshared toString() {
    return `${this.x},${this.y}`;
  }
}
```


[14:41:39.0758] <shu>
yes

[14:41:54.0626] <rbuckton>
It seems somewhat redundant, IMO, unless you expect we would ever have the concept of a "shared constructor" or a "shared method"

[14:41:59.0383] <shu>
(but to be clear i plan to leave out any mention of inline method declarations at all)

[14:42:11.0858] <shu>
in this update stage

[14:43:47.0067] <rbuckton>
btw, in the origin trial this has been pretty convenient in both JS and TS:

```js
class Foo extends SharedStructType(["x", "y"]) {
  constructor(x, y) {
    super();
    this.x = x;
    this.y = y;
  }
}

[14:44:07.0383] <shu>
> <@rbuckton:matrix.org> It seems somewhat redundant, IMO, unless you expect we would ever have the concept of a "shared constructor" or a "shared method"

i don't at this time, but things could change? but that's not the main reason for my preference. the main reason is i want the syntax to be explicitly reflect the semantics

[14:44:30.0203] <shu>
my personal design sense is i hate implicit stuff

[14:44:30.0368] <rbuckton>
 * btw, in the origin trial this has been pretty convenient in both JS and TS:

```ts
// js
class Foo extends SharedStructType(["x", "y"]) {
  constructor(x, y) {
    super();
    this.x = x;
    this.y = y;
  }
}

// ts
class Foo extends SharedStructType(["x", "y"]) {
  declare x: number;
  declare y: number;
  constructor(x: number, y: number) {
    super();
    this.x = x;
    this.y = y;
  }
}
```

[14:46:17.0762] <rbuckton>
As someone who has had chronic wrist pain due to a pretty severe break around 20 years ago, my opinion is the less redundancy and repetition when typing, the better.

[14:46:48.0285] <rbuckton>
though I agree with explicitness when necessary.

[14:48:46.0847] <shu>
> <@rbuckton:matrix.org> As someone who has had chronic wrist pain due to a pretty severe break around 20 years ago, my opinion is the less redundancy and repetition when typing, the better.

that's good feedback

[14:48:59.0796] <rbuckton>
If you think we will ever come to a place were we can actually share code across threads or allow threads to coexeist with main thread application memory like they do in many other languages, then I would agree that we need the keyword to avoid painting ourselves into a corner.

[14:50:01.0574] <rbuckton>
I always advocate for "less ceremony is better" when it comes to syntax, though not so much that I agree with using keywords like `pub`, `fn`, `def`.

[14:51:51.0044] <rbuckton>
`const`-aside

[14:58:51.0982] <Mathieu Hofman>
One question with the syntax as proposed above is how do you attach nonshared properties / methods to a struct definition you received from another thread 

[15:09:55.0680] <rbuckton>
That's explained in the gist I linked above.

[15:13:37.0016] <rbuckton>
The gist proposes a simple handshaking mechanism through the use of a string-keyed map. At the most fundamental level, you declare "this name is associated with this exemplar" on one thread, and "this name is associated with this prototype" on the other thread. 

Since you want to be able to produce new struct instances on both sides, you could declare these things bidirectionally, i.e. "this name is associated with this exemplar and prototype" on one thread, and "this name is associated with this exemplar and prototype" on another thread:

```js
// main.js
const worker = new Worker(file, {
  preload: "preload.js",
  structs: {
    Foo: { exemplar: FOO_EXEMPLAR, prototype: FOO_PROTOTYPE }
  }
});

// preload.js
prepareWorker({
  structs: {
    Foo: { exemplar: FOO_EXEMPLAR, prototype: FOO_PROTOTYPE }
  }
});
```

[15:15:28.0694] <rbuckton>
The preload script could run at the startup of the worker thread. It would establish the relationship on the worker's side, but wouldn't be allowed to send or receive messages on the worker. That would allow you to establish the relationship all at once and avoids a mutable registry.

[15:16:50.0247] <rbuckton>
This can then be expanded to introduce something like a built-in symbol-named method that the handshaking process could look at first, before looking for `{ exemplar, prototype }`, and a `shared struct` declaration would implement that as a static method, returning a suitable exemplar and prototype for the handshake without needing to run the constructor

[15:17:36.0385] <Mathieu Hofman>
only allowing init time registration somewhat concerns me, and I have to think more about this per connection registry.

[15:18:12.0004] <rbuckton>
Thus the handshake can be simplified with `shared struct` declarations like this:

```js
// foo.js
export shared struct Foo { 
  ...
}

// main.js
import { Foo } from "foo.js";
const worker = new Worker("worker.js", {
  preload: "preload.js",
  structs: { Foo }
});

// preload.js
import { Foo } from "foo.js";
prepareWorker({ structs: { Foo } });

```

[15:18:43.0950] <rbuckton>
The reason I proposed init-time registration was due to concerns you raised about data exfiltration with a mutable registry.

[15:19:44.0413] <Mathieu Hofman>
also this mechanism means there is technically 2 different point definitions, but since they share a prototype the type discontinuity is not observable?

[15:20:19.0460] <rbuckton>
This approach also avoids giving shared structs an identity based on path, and instead is a user-defined identity declared when the `Worker` is created. Its no different then just passing an array of workers without the need to ensure you properly marry up element order on both sides, and `Foo` is easier to remember and debug than an integer value.

[15:21:01.0613] <Mathieu Hofman>
yes non-init time registration does raise the problem of "land-rush", ability to extract information through the registry

[15:21:07.0809] <rbuckton>
> <@mhofman:matrix.org> also this mechanism means there is technically 2 different point definitions, but since they share a prototype the type discontinuity is not observable?

I thought that was the rationale we were moving towards anyways? To attach behavior to a shared struct in two threads, you must have two different definitions of the behavior, one in each thread.

[15:21:19.0530] <Mathieu Hofman>
I just wish we didn't have to make the trade-off somehow

[15:22:22.0655] <Mathieu Hofman>
> <@rbuckton:matrix.org> I thought that was the rationale we were moving towards anyways? To attach behavior to a shared struct in two threads, you must have two different definitions of the behavior, one in each thread.

yes just wanted to make sure that's actually what's happening, and that it should be fine

[15:22:49.0078] <rbuckton>
I think the preload mechanism is at the very least a palatable way to address it, and its the same approach used by runtimes like electron to provide privileged access when creating sandboxed environments

[15:23:03.0326] <Mathieu Hofman>
a possible 1-to-many relationship from behavior to type definition

[15:23:45.0911] <rbuckton>
This approach presupposes that you know ahead of time all of the possible types you wish to flow through all threads that can talk to each other in your application.

[15:25:17.0622] <rbuckton>
And by "know ahead of time", you can still support types added by libraries if they export a registry of their types in the form of a regular JS object, i.e.:

```js
import { structs as fooStructs } from "foo-package";

new Worker("worker.js", { ..., structs: { ...fooStructs, Bar, Baz } });
```

[15:30:56.0901] <rbuckton>
The main issue I see with this approach is when you have 3+ threads, where two or more child threads need to communicate without having established a handshake between themselves:

1. main thread M has struct `Foo` with type identity 0
2. child thread A has a struct `Foo` with type identity 1
3. child thread B has a struct `Foo` with type identity 2
4. M performs handshake with A establishing that `Foo-0` on A uses A's `Foo` prototype, and `Foo-1` on M uses M's `Foo` prototype.
5. M performs handshake with B establishing that `Foo-0` on B uses B's `Foo` prototype, and `Foo-2` on M uses M's `Foo` prototype.
6. M creates a `MessagePort` and hands `port1` to thread A, and `port2` to thread B
7. A creates a `Foo-1` and sends it to B over the message port.
8. What does a `Foo-1` look like in B? 

[15:31:21.0293] <Mathieu Hofman>
right, just wondering if we could still end up with something like
```
import { Point } from "./point.js";
import { attachBehavior, parentPort } from "worker_threads";
parentPort.on("message", data => {
    if (data.type === 'registerPoint') {
        attachBehavior(data.examplar, Point.prototype);
    }
});

```

[15:31:54.0612] <rbuckton>
the goal with the API design in the doc is to abstract away as much of that scaffolding as possible.

[15:33:08.0332] <rbuckton>
i.e., assume that the presence of a `structs: {}` property in the worker constructor will transmit a `'registerPoint'` message for you, and that a `prepareWorker({ structs: {} })` will automatically handle the `on("message")` event for you.

[15:33:20.0519] <rbuckton>
There's no reason to have users write all of that out themselves.

[15:34:25.0157] <rbuckton>
I also don't always want to have to depend on postMessage when I intend for most of the processing in the child thread to happen synchronously through the use of `Mutex` and other synchronization primitives.

[15:35:59.0541] <rbuckton>
One possibility is that an Agent keeps track of the type identity mappings for all of the types on all of the workers, and shares those identities with other agents.

[15:37:03.0405] <rbuckton>
So if A sends a `Foo-1` to B, B's Agent can first check if it has an explicit mapping of `Foo-1` to something else, then walk back to the Agent that spawned the thread for such a mapping, and so on.

[15:37:34.0734] <rbuckton>
Thus B's Agent would walk back to M to see that a `Foo-1` is associated with a `Foo-0`, and thus we can associate it with a `Foo-2` in B.

[15:38:55.0908] <rbuckton>
Whatever we would do would need to work without `postMessage` after the initial setup, because I can run into the same scenario when just sharing a shared struct between two worker threads

[15:39:12.0014] <rbuckton>
in which case I can't wait for an asynchronous `postMessage` to establish the relationship for me.

[15:39:34.0803] <Mathieu Hofman>
I agree we can provide sugar like you propose, but I believe having an explicit `attachBehavior` or similar allows to solve the late registration case without fully opening the can of worms of a mutable sting keyed registry

[15:40:32.0601] <Mathieu Hofman>
 * I agree we can provide sugar like you propose, but I believe having an explicit `attachBehavior` or similar allows to solve the late registration case without fully opening the can of worms of a mutable string keyed registry

[15:41:08.0546] <rbuckton>
i.e.,:
1. M hands a shared struct with `{ mutex, condition, value }` to both A and B.
1. B locks `mutex` and waits on `condition` (unlocking the mutex)
1. A locks `mutex`, writes a `Foo-1` to `value`, and and wakes B via `condition`
1. B reads `value` and gets a `Foo-1`

[15:41:58.0326] <rbuckton>
`attachBehavior` is pretty much what `prepareWorker` does, though `prepareWorker` doesn't have to do things one at a time.

[15:42:24.0832] <rbuckton>
And `attachBehavior` doesn't solve the late registration case I just posted.

[15:43:04.0875] <rbuckton>
Unless you are suggesting that `on("message")` gets called synchronously the moment `B` reads from `value`

[15:44:40.0339] <rbuckton>
To support the synchronous case I proposed above, you really have to establish the relationships *before* any work is done.

[15:45:49.0750] <rbuckton>
Maybe that means registration isn't just `struct: { ... }`. Maybe that means you have to create an instance of a `StructRegistry` object you pass to each worker you create, so that you explicitly establish the relationship between all of the workers.

[15:46:09.0826] <Mathieu Hofman>
I'm saying that in you example, between step 6 and 7, A could send a message to B with an examplar, and B could send a message to A with its examplar, and both could attach their behavior

[15:46:17.0287] <Mathieu Hofman>
 * I'm saying that in your example, between step 6 and 7, A could send a message to B with an examplar, and B could send a message to A with its examplar, and both could attach their behavior

[15:46:34.0634] <rbuckton>
Something like: 
```js
const structs = new StructsRegistry({ Foo, Bar });
const worker1 = new Worker("worker.js", { structs });
const worker2 = new Worker("worker.js", { structs });
```


[15:47:10.0121] <rbuckton>
That's the asynchronous case using `MessagePort`. I'm saying that doesn't work with the synchronous case using `mutex`/`condition`

[15:47:22.0724] <rbuckton>
> <@rbuckton:matrix.org> i.e.,:
> 1. M hands a shared struct with `{ mutex, condition, value }` to both A and B.
> 1. B locks `mutex` and waits on `condition` (unlocking the mutex)
> 1. A locks `mutex`, writes a `Foo-1` to `value`, and and wakes B via `condition`
> 1. B reads `value` and gets a `Foo-1`

this is the synchronous case

[15:47:24.0921] <Mathieu Hofman>
but yes it would be nice to abstract that away to avoid this manual protocol

[15:48:08.0169] <Mathieu Hofman>
oh I see, yeah I don't know how you solve that one

[15:49:27.0413] <rbuckton>
I currently see two mechanisms: either the agents communicate with each other to find a suitable mapping just using the provided `structs: {}` maps, or you explicitly hand a registry off to each worker that essentially records the per-agent mappings for each struct type in the registry.

[15:49:32.0351] <Mathieu Hofman>
you'd have to pass the behavior definition along, possibly as a module instance that can be synchronously evaluated when creating the realm, not just the local constructor / prototype

[15:49:53.0304] <rbuckton>
> <@mhofman:matrix.org> you'd have to pass the behavior definition along, possibly as a module instance that can be synchronously evaluated when creating the realm, not just the local constructor / prototype

Why? The point of this is that you _don't_ pass the behavior definition along.

[15:50:03.0395] <rbuckton>
Each thread maintains its own copy of the behavior

[15:50:35.0599] <rbuckton>
This is desirable since you can have a build tool perform static analysis and tree shaking to reduce overall code size that you have to load into a thread.

[15:51:27.0114] <rbuckton>
I'm not opposed to sharing behavior, but that does mean a lot of additional complexity with respect to module resolution, and makes things harder when it comes to checking reference identities.

[15:52:09.0066] <rbuckton>
Plus I may have per-thread setup I perform in the constructor of a shared struct that is side-effecting that can't be reached via a shared definition.

[15:53:14.0146] <Mathieu Hofman>
ok so the struct registry would itself be a shared thing. each string keyed entry would basically have a list of examplars, and the local prototype behavior to use

[15:53:33.0708] <rbuckton>
IMO, passing along shared behavior in a module record is a completely different direction than passing exemplars to attach behavior. They have different issues and solve the problem in different ways.

[15:54:12.0301] <Mathieu Hofman>
during prepare you basically add your examplar to the list, and other threads somehow lookup the examplar to find the right behavior to use

[15:54:40.0439] <Mathieu Hofman>
 * during prepare you basically add your examplar to the list, and other threads somehow lookup the examplar / type to find the right behavior to use

[15:55:09.0624] <rbuckton>
> <@mhofman:matrix.org> ok so the struct registry would itself be a shared thing. each string keyed entry would basically have a list of examplars, and the local prototype behavior to use

Maybe somewhat? `StructRegistry` is more like a built-in. It says "here's what M things a `Foo` is". In A, I use `prepareWorker` to say "Here's what A thinks a `Foo` is", and the same in B. Both B and A's agents will have access to the registry provided by M, and thus when B and A communicate, they can refer to the same registry.

[15:56:08.0974] <rbuckton>
The registry isn't "mutable" per-se as each Agent only cares about what was provided as a key in that agent, but the registry itself knows what each key maps to in each Agent.

[15:56:22.0028] <Mathieu Hofman>
yeah I'm still wondering if it can be explained in terms of `attachBehavior`

[15:57:20.0997] <Mathieu Hofman>
I think the registry is mutable in the sense that each thread needs to register its type definition to an existing entry

[15:57:52.0452] <rbuckton>
I could possibly model this in terms of `attachBehavior` and abstract it away, assuming some other information is available. I can't emulate the thread-localness I'm describing in quite the same way, but could emulate it with a lock-free data structure

[15:58:07.0103] <rbuckton>
Yes, but each thread can't change the entries of other threads.

[15:58:20.0063] <rbuckton>
They can only line up with same-named keys.

[15:58:44.0418] <Mathieu Hofman>
right

[15:58:52.0020] <rbuckton>
And we could throw runtime errors if your exemplars don't have a matching field layout.

[15:59:35.0057] <rbuckton>
And you can't arbitrarily add new keys to a registry in a given thread, only during initial setup.

[15:59:43.0392] <rbuckton>
I need to break for dinner.

[16:41:54.0423] <shu>
oops i had meetings and now there's a lot of backlog


2023-09-19
[17:25:26.0717] <rbuckton>
> <@rbuckton:matrix.org> I could possibly model this in terms of `attachBehavior` and abstract it away, assuming some other information is available. I can't emulate the thread-localness I'm describing in quite the same way, but could emulate it with a lock-free data structure

I threw together a bunch of pseudocode for this to get an idea of what's needed. You couldn't support the synchronous case without some kind of synchronous notification occurring when an Agent encounters a shared struct with a previously unseen type identity, but that callback would be something like:

```js
    setFindMissingPrototypeCallback((exemplar, agentId) => {
        const agentRegistry = agentId === 0 ? registry.root : ConcurrentList.find(registry.children, registry => registry.agentId === agentId);
        if (!agentRegistry) {
            return false;
        }

        const exemplarTypeIdentity = getTypeIdentity(exemplar);
        const agentEntry = Array.prototype.find.call(agentRegistry.entries, entry => getTypeIdentity(entry.exemplar) === exemplarTypeIdentity);
        if (!agentEntry) {
            return false;
        }

        const thisAgentEntry = Array.prototype.find.call(perAgentRegistry.entries, entry => entry.key === agentEntry.key);
        if (!thisAgentEntry || !thisAgentEntry.prototype) {
            return false;
        }

        attachBehavior(exemplar, thisAgentEntry.prototype);
        return true;
    });

```

And something similar would be wired up on the main thread when constructing the `Worker`

[17:27:44.0587] <rbuckton>
Without the synchronous case, you could achieve this via `postMessage` if the worker/port checked each shared struct being sent out to see if it had already seen its type identity, and then posting a handshake message before posting the actual message.

[17:28:14.0506] <Mathieu Hofman>
right there has to be something that triggers when another agent register an examplar

[17:28:52.0477] <rbuckton>
But this is much simpler if we do all this work on the user's behalf.

[17:29:01.0137] <Mathieu Hofman>
for the async case you don't really need to check every shared struct being sent, I'll send some code later

[17:29:54.0843] <rbuckton>
An async-only case doesn't really exist though, since any thread could set data on a shared struct visible by any other thread.

[17:31:40.0706] <rbuckton>
And this `setFindMissingPrototypeCallback` only needs to be invoked lazily when performing `[[GetPrototype]]`

[17:32:43.0043] <rbuckton>
You could theoretically shim *all* of this with the current shared structs trial if you want to use `Proxy` and patch a bunch of globals and imports.

[17:32:52.0414] <rbuckton>
but it would be abysmally slow.

[17:46:02.0982] <rbuckton>
> <@rbuckton:matrix.org> And this `setFindMissingPrototypeCallback` only needs to be invoked lazily when performing `[[GetPrototype]]`

And this lazy operation doesn't necessarily require blocking. By the time thread A and B can communicate, they would both have already filled out their side of the shared registry.

[18:06:14.0004] <Mathieu Hofman>
I'm really not good at multi-threaded coded, but I was thinking of something along the lines of:
```
shared struct StructRegistryEntry {
    name;
    examplar;
    next;
}

shared struct StructRegistry {
  head;
  names;

  nonshared lastAttached;
  nonshared prototypes;

  nonshared constructor(structs = {}) {
    const names = Object.keys(structs);
    this.names = new SharedFixedArray(names.length);
    for (const [i, name] of names.entries()) {
      this.names[i] = name;
    }
    this.prepare(structs);
  }

  nonshared prepare(structs) {
    const prototypes = new Map([...this.names].map(name => [name, null]));

    const entries = [];

    for (const [name, constructor] of Object.entries(structs)) {
      if (!prototypes.has(name)) {
        throw new Error(`Undeclared struct name ${name}`);
      }

      prototypes.set(name, constructor.prototype)
      entries.push([name, new constructor()]);
    }

    this.prototypes = prototypes;

    for (const [name, examplar] of entries) {
      this.register(name, examplar);
    }
  }
  
  nonshared register(name, examplar) {
    if (!this.prototypes.has(name)) {
      throw new Error(`Undeclared struct name ${name}`);
    }
    const entry = new StructRegistryEntry()
    entry.name = name;
    entry.examplar = examplar;
    entry.next = this.head;

    while (true) {
      const oldHead = Atomics.compareExchange(this, 'head', entry.next, entry)
      if (oldHead === entry.next) {
        break;
      } else {
        entry.next = oldHead;
      }
    }

    updateRegistrations(this)
  }
}

function updateRegistrations(structRegistry) {
  const head = structRegistry.head;
  let entry = head;
  while (entry !== structRegistry.lastAttached) {
    const behavior = structRegistry.prototypes.get(entry.name);
    if (behavior) {
      attachBehavior(entry.examplar, behavior);
    }
    entry = entry.next;
  }
  structRegistry.lastAttached = head;
}
```

[18:07:29.0306] <Mathieu Hofman>
`updateRegistrations` would have to be triggered anytime there is some unattached struct, or eagerly for every message received. I'm not sure how you trigger it in the sync case

[18:08:15.0399] <Mathieu Hofman>
anyway I need to head out, hopefully that pseudo code conveys how I thought of the StructRegistry that Ron suggested

[06:40:53.0339] <Mathieu Hofman>
Thinking more about it, one way to have all threads process the types of any other thread is to
- block completion of registering a new thread's examplar until all other existing threads connected to the registry have signaled they have attached behaviors to the new examplar
- somehow be able to have existing threads process new examplars while they're currently executing

There doesn't seem to be a good way to explain in terms of initialization and messaging the kind of preemption required by introducing a new thread's types to other connected threads that are potentially in busy loops. Maybe it demonstrates that "attach behavior" is not sufficient, and it likely means the registration mechanism has to be language specified instead, which kinda saddens me.

[07:18:03.0665] <Mathieu Hofman>
 * Thinking more about it, one way to have all threads process the types of any other thread is to

- block completion of registering a new thread's examplar until all other existing threads connected to the registry have signaled they have attached behaviors to the new examplar
- somehow be able to have existing threads process new examplars while they're currently executing

There doesn't seem to be a good way to explain in terms of initialization and messaging the kind of preemption required by introducing a new thread's types to other connected threads that are potentially in busy loops. Maybe it demonstrates that "attach behavior" is not sufficient, and it likely means the registry mechanism has to be language specified instead, which kinda saddens me.

[07:44:24.0185] <rbuckton>
What if we only support wiring up exemplars between A and B that *only* have a matching key in M? The shared registry would just track the type identities of each registered exemplar in one place during preload, so you wouldn't need to process new exemplars:

```js
//
// main.js
//
import { Foo, Bar, Baz } from "./structs.js";
const structs = new StructRegistry({ Foo, Bar, Baz });
const data = new (new SharedStructType(["mut", "cond", "ready", "value"]))();
data.mut = new Atomics.Mutex();
data.cond = new Atomics.Condition();
data.ready = false;
const A = new Worker("A.js", { preload: "preloadA.js", structs, workerData: data });
const B = new Worker("B.js", { preload: "preloadB.js", structs, workerData: data });

//
// preloadA.js
//
import { Foo, Bar, Quxx } from "./structs.js";
import { prepareWorker } from "worker_threads";
prepareWorker({ structs: { Foo, Bar, Quxx } });

//
// preloadB.js
//
import { Foo, Baz, Quxx } from "./structs.js";
import { prepareWorker } from "worker_threads";
prepareWorker({ structs: { Foo, Baz, Quxx } });

//
// A.js
//
import { Foo, Bar, Baz, Quxx } from "./structs.js";
import { workerData } from "worker_threads";

Atomics.Mutex.lock(workerData.mut, () => {
  function waitForB() {
    while (!workerData.ready) Atomics.Condition.wait(workerData.cond, workerData.mut);
  }

  function sendToB(value) {
    workerData.value = value;
    workerData.ready = false;
    Atomics.Condition.notify(workerData.cond);
    waitForB();
  }

  function receiveFromB() {
    waitForB();
    return workerData.value;
  }

  waitForB();

  // send our `Foo`
  sendToB(new Foo());

  // Check whether the `Foo` sent by B shares the same prototype as our `Foo`.
  // This works because both A and B have registered a `Foo` entry that maps to `Foo` in the main thread.
  console.log(receiveFromB() instanceof Foo); // prints: true

  // send our `Bar`
  sendToB(new Bar());

  // Check whether the `Bar` sent by B shares the same prototype as our `Bar`.
  // This does not work because preloadB.js did not register `Bar`.
  console.log(receiveFromB() instanceof Bar); // prints: false

  // send our `Baz`
  sendToB(new Baz());

  // Check whether the `Baz` sent by B shares the same prototype as our `Baz`.
  // This does not work because preloadA.js did not register `Baz`.
  console.log(receiveFromB() instanceof Baz); // prints: false

  // send our `Quxx`
  sendToB(new Quxx());

  // Check whether the `Quxx` sent by B shares the same prototype as our `Quxx`.
  // This does not work because main.js did not register `Quxx`.
  console.log(receiveFromB() instanceof Quxx); // prints: false
});

// B.js
import { Foo, Bar, Baz, Quxx } from "./structs.js";
import { workerData } from "worker_threads";

Atomics.Mutex.lock(workerData.mut, () => {
  function waitForA() {
    while (workerData.ready) Atomics.Condition.wait(workerData.cond, workerData.mut);
  }

  function sendToA(value) {
    workerData.value = value;
    workerData.ready = true;
    Atomics.Condition.notify(workerData.cond);
    waitForA();
  }

  function receiveFromA() {
    waitForA();
    return workerData.value;
  }

  // signal to A that we're ready
  sendToA(undefined);

  // Check whether the `Foo` sent by A shares the same prototype as our `Foo`.
  // This works because both A and B have registered a `Foo` entry that maps to `Foo` in the main thread.
  console.log(receiveFromA() instanceof Foo); // prints: true

  // send our `Foo`
  sendToA(new Foo());

  // Check whether the `Bar` sent by A shares the same prototype as our `Bar`.
  // This does not work because preloadB.js did not register `Bar`.
  console.log(receiveFromA() instanceof Bar); // prints: false
  
  // send our `Bar`
  sendToA(new Bar());

  // Check whether the `Baz` sent by A shares the same prototype as our `Baz`.
  // This does not work because preloadA.js did not register `Baz`.
  console.log(receiveFromA() instanceof Baz); // prints: false

  // send our `Baz`
  sendToA(new Baz());

  // Check whether the `Quxx` sent by B shares the same prototype as our `Quxx`.
  // This does not work because main.js did not register `Quxx`.
  console.log(receiveFromA() instanceof Quxx); // prints: false

  // send our `Quxx`
  sendToA(new Quxx());
});
```

[07:45:59.0529] <rbuckton>
When A and B receive something they don't share a mapping for, you just get data and no behavior.

[07:46:36.0524] <rbuckton>
In that way its still useful for read/write and for sending it along to another thread that might be able to interpret it.

[07:53:23.0266] <rbuckton>
In the same vein, if `main.js` starts two workers that don't share the same registry, they can't wire up behavior at all.

[09:03:27.0877] <Mathieu Hofman>
I was assuming only matching keys in the registry in the first place, but I don't think that solves the problem. For example:
- M creates the registry
- M creates A with the shared registry. A can block during prepare until it has attached behaviors for M's examplars, and M can block until A has shared its examplars, and M has attached behavior
- M shares a container struct with A
- M subsequently creates B with the same shared registry. B can block during prepare until it has attached behaviors for both M and A's examplars, and M can block until B has shared its examplars, and M has attached behavior
- M shares the previously created container with B (possibly in the init params of the worker)
- B adds some shared structs it creates to the container
- A attempts to read from the container

How do we make sure that A has had the opportunity to process B's examplars to attach behavior to B's types before A encounters the B struct types in the shared container. A may be doing a busy loop we cannot preempt. I can probably imagine patching all atomics operations to interleave the attachment check, but that feels gross.

Or maybe there's something simply I'm overlooking

[10:52:59.0543] <rbuckton>
I don't think we need to block until behavior is attached to exemplars until we do `[[GetPrototypeOf]]`, at which time we can look up the matching exemplars from the registry. By the time A communicates with B, or either communicates with M, their registries would already be connected.

[10:56:23.0176] <Mathieu Hofman>
Right, that's what I mean, it requires the concept of the registry to be known to the spec so that `[[GetPrototypeOf]]` can do necessary lookup. I was still trying to explain the registry in terms of simpler attach behavior semantics, but that doesn't seem to be possible

[10:57:53.0108] <rbuckton>
Even for attachBehavior to work there has to be some behind-the-scenes work in the spec to generate a prototype based on the type identity of a shared struct type.

[12:09:22.0291] <rbuckton>
shu: yesterday we were discussing marking methods as `nonshared`, are you anticipating these methods would be attached to the instance as `nonshared` fields, or to an agent-local `[[Prototype]]`? 

[13:26:52.0591] <Mathieu Hofman>
> <@rbuckton:matrix.org> Even for attachBehavior to work there has to be some behind-the-scenes work in the spec to generate a prototype based on the type identity of a shared struct type.

sure, but while that's also technically an internal registry, it's from an internal and non-forgeable type identity to a local behavior object. Your proposed registry is mapping from a string, which to prevent introducing a realm / agent wide communication channel has to be connection specific, or the registry state cannot be observable by the program in any way, neither of which I am convinced about being the case yet.

[13:28:40.0931] <rbuckton>
Even the `on("message", ...)` + `attachBehavior` mechanism uses a string key, it's just that the string key you used was `"registerPoint"`.

[13:29:44.0697] <rbuckton>
An in earlier discussions with shu he'd suggested something like "you send an array of exemplars", in which case the key you use is an integer. What the key is doesn't matter.

[13:30:28.0391] <rbuckton>
Everything I'm suggesting is basically just a layer of abstraction above the same capabilities you're proposing.

[13:32:05.0583] <rbuckton>
The initiating thread needs to pass a message containing one or more exemplars to a child thread, keyed in some way as to be interpreted as a way to identify which exemplar is an example of which known thing we want to associate it with.

[13:32:09.0403] <shu>
rbuckton: the former, though there's nothing precluding an agent-local [[Prototype]] either

[13:32:25.0120] <shu>
it is slightly more difficult to implement the latter so that's not what the dev trial does

[13:32:47.0516] <shu>
you should probably be able to express it both ways

[13:33:03.0510] <rbuckton>
Does this process even work if I have to attach agent local values for every method every time I receive a new instance of an existing struct type?

[13:33:19.0511] <shu>
sorry i think i misread

[13:34:06.0040] <shu>
the two choices are:

1. a shared struct instance's [[Prototype]] is a shared field and holds a shared struct, with `nonshared` fields, into which you assign methods
2. a shared struct instance's [[Prototype]] is a `nonshared` field and points to a per-agent local struct

[13:34:42.0244] <shu>
i think you want `nonshared` fields regardless

[13:34:58.0624] <shu>
and maybe (2) as well

[13:35:03.0425] <shu>
but that one's less clear to me

[13:35:08.0496] <shu>
i am prototyping (1) in the dev trial

[13:35:29.0032] <shu>
in either case you don't have to attach methods for every new instance

[13:36:49.0217] <Mathieu Hofman>
> <@rbuckton:matrix.org> Everything I'm suggesting is basically just a layer of abstraction above the same capabilities you're proposing.

Right but that is clearly and explicitly scoped to the connection. I'm struggling to think of a way to specify the registry that remains fully connection oriented.

[13:37:21.0799] <rbuckton>
(1) works, I suppose. What's important is that for a given struct type, I only need to establish the `[[Prototype]]` relationship once in a given thread, not once every time a new instance is observed.

[13:38:01.0463] <shu>
(1) has some advantages, like, `instanceof` just works with the usual semantics

[13:38:10.0389] <shu>
since all instances have the same prototype object

[13:38:54.0254] <rbuckton>
What I suggested *is* connection oriented. The main thread doesn't have a global registry shared across all workers. It has a _specific_ registry you hand to individual workers on creation. The child thread associated with that worker will always be able to refer to its parent, thus the registry will always be reachable.

[13:42:17.0420] <rbuckton>
Proxies are extremely frustrating, by the way. its very difficult to actually build a membrane with them due to some of the invariants.

[13:42:56.0261] <rbuckton>
I'm trying to model some of what we've been discussing using the current origin trial + some proxies and shims

[14:03:07.0261] <rbuckton>
shu: Do you expect the `nonshared` fields to be fixed per-instance as well/

[14:03:08.0965] <rbuckton>
 * shu: Do you expect the `nonshared` fields to be fixed per-instance as well?

[14:03:35.0024] <rbuckton>
as in, predefined with `{ configurable: false }` like shared fields are

[14:12:44.0962] <shu>
rbuckton: the fields themselves, yes

[14:13:04.0204] <shu>
the fixed layout constraint applies to all fields

[16:25:23.0731] <Mathieu Hofman>
> <@rbuckton:matrix.org> What I suggested *is* connection oriented. The main thread doesn't have a global registry shared across all workers. It has a _specific_ registry you hand to individual workers on creation. The child thread associated with that worker will always be able to refer to its parent, thus the registry will always be reachable.

What I'm wondering about is the relation between types and registries. A thread / agent is able to create registries and pass/associate them to workers it creates. That means there is really a many-to-many relationship between agents and registries. When a type is received from a postMessage, it's logical to lookup in the registry associated to that connection for a behavior mapping. However when a type is read from a value of another shared struct, how is the agent deciding where to look up for an associated behavior? Do each types keep an association to which connection they originated from, so that further types encountered through them resolve using the same registry? What happens if a type associated to one registry is shared over a connection using another registry? Or for that matter, to what registry is a type locally defined associated to?

[16:35:48.0480] <Mathieu Hofman>
To put it in another term, what happens in the following case:
- M defines Point and Rect structs
- M creates registry RA, used with worker A
- M creates registry RB, used with worker B
- Both A and B define their own Point and Rect, and prepare the registry they received from M with those definitions
- M creates rect1 and shares it with A and B
- A sets rect1.topLeft to a Point it creates
- B sets rect1.bottomRight to a Point it creates

Questions:
- M should be able to find a behavior for both rect1.topLeft and rect1.bottomRight, but what spec logic should it follow that accomplishes that?
- Should B be able to find a behavior for rect1.topLeft? (corollary, should A be able to find a behavior for rect1.bottomRight ?)



2023-09-20
[18:01:08.0855] <rbuckton>
- When A handshakes with M:
  - M is able to establish that a PointA should have a PointM prototype and it will apply to every PointA it receives, from anywhere, within the scope of M's Agent.
  - A is able to establish that a PointM should have a PointA prototype and it will apply to every PointM it receives, from anywhere, within the scope of A's Agent.
- When B handshakes with M:
  - M is able to establish that a PointB should have a PointM prototype and it will apply to every PointB it receives, from anywhere, within the scope of M's Agent.
  - B is able to establish that a PointM should have a PointB prototype and it will apply to every PointM it receives, from anywhere, within the scope of B's Agent.

As such:
- M will be able to find behavior for both rect1.topLeft and rect1.topRight, because the handshake between M-A and M-B established that.
- B will not be able to find a behavior for rect1.topLeft because registries RA and RB are independent.
- A will not be able to find a behavior for rect1.bottomRight because registries RA and RB are independent.

[18:03:11.0500] <rbuckton>
However, if you use the same registry RAB with A and B:
- B is able to establish that a PointA should have a PointB prototype because the registry correlates both PointA and PointB with PointM.
- A is able to establish that a PointB should have a PointA prototype because the registry correlates both PointA and PointB with PointM.

[18:06:29.0576] <rbuckton>
If such a prototype is initialized lazily in `[[GetPrototypeOf]]`, by the time B can receive a PointA, or that A can receive a PointB, both agents will have completed their handshake with M, so all information is known. This is another reason why my proposal uses a preload script. The preload script performs the worker side of the handshake before any other data can be shared between the worker and M, so you cannot have a stray PointA sent to B, or PointB sent to A, prior to a completed handshake on both sides.

[18:13:19.0398] <rbuckton>
Now, we could theoretically have a global registry instead, with the `structs: {}` map only used to correlate PointM and PointA when A is established. Workers will always be part of a tree that points back to some root agent, so there's always a way to collect these things. If the handshake establishes the relationship without the ability to pass messages, would that be sufficient to address concerns about a global registry?

[18:16:52.0891] <rbuckton>
Especially if the worker can't actually observe the exemplar during handshake, since the handshake process is handled by the runtime. We wouldn't even need communicate the actual exemplars through the handshake process, just the type identities of the exemplars. 

[18:21:15.0759] <rbuckton>
Though there is the caveat that M could try to pass off a PointA as an exemplar to B's Rect, but we could probably just make that an error, i.e. the exemplars you send during the handshake must have been created by a type created in M's Agent.

[18:21:33.0339] <rbuckton>
 * Though there is the caveat that M could try to pass off a PointA as an exemplar to B's Rect, but we could probably just make that an error, i.e. the exemplars M sends during the handshake must have been created by a type created in M's Agent.

[18:21:47.0742] <rbuckton>
 * Though there is the caveat that M could try to pass off a PointA as an exemplar to B's Rect, but we could probably just make that an error, i.e. the exemplars M sends during the handshake must have been created by a type created in M's Agent

[18:22:54.0815] <rbuckton>
and the same thing goes for A (or B) spinning up a Worker (A2) during handshake and passing off one A2's exemplar as one of its own.

[18:23:03.0400] <rbuckton>
 * and the same thing goes for A (or B) spinning up a Worker (A2) during handshake and passing off one A2's exemplars as one of its own.

